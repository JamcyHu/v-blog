{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{410:function(e,_,n){\"use strict\";n.r(_);var v=n(56),r=Object(v.a)({},(function(){var e=this,_=e.$createElement,n=e._self._c||_;return n(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[n(\"h1\",{attrs:{id:\"mysql\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql\"}},[e._v(\"#\")]),e._v(\" Mysql\")]),e._v(\" \"),n(\"h2\",{attrs:{id:\"sql语句\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#sql语句\"}},[e._v(\"#\")]),e._v(\" SQL语句\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"使用group-by-情况\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#使用group-by-情况\"}},[e._v(\"#\")]),e._v(\" 使用group by 情况\")]),e._v(\" \"),n(\"p\",[e._v(\"分情况，1、当聚集函数和非聚集函数出现在一起时，需要将非聚集函数进行group by\\n2、当只做聚集函数查询时候，就不需要进行分组了。\\nselect c_id,sum(s_score) from score where c_id='02';（虽然select中聚集函数和非聚集函数都有，但where中c_id等于具体值，只有一组，c_id已经无需分组）\")]),e._v(\" \"),n(\"p\",[e._v(\"使用字段A分组，可以聚合字段B函数\")]),e._v(\" \"),n(\"p\",[e._v(\"分组的意义在于对每一组数据进行聚合函数\\n如 group by a.sno having count(a.score)>=2;成绩表先按学号分组，都同一名学生中不同的课程成绩做聚合函数\")]),e._v(\" \"),n(\"p\",[e._v(\"子查询的话，建议使用在查询显示出来的列只需要使用一张表的（显示一张表中的信息，另一张表只能作为连接点）\")]),e._v(\" \"),n(\"p\",[e._v(\"内连接的话，建议使用查询显示出来的列需要使用到两张表中的多个列 （多表查询 适合用内连接）\")]),e._v(\" \"),n(\"p\",[e._v(\"如按分数降序排列的学生信息（若用s_id连接点，只能看学生信息无法看分数降序）\")]),e._v(\" \"),n(\"p\",[e._v(\"多表连接是将多表当成1张表，可以使用聚合函数\\n-- 25. 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩\\nselect a.sno, b.sname, avg(a.score)\\nfrom sc as a inner join student as b on a.sno=b.sno\\ngroup by a.sno having avg(a.score)>=85;\"),n(\"br\"),e._v(\"\\n注：聚合函数（a表字段） 不是a表聚合函数（字段）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"执行顺序\\n1、最先执行from tab；2、where语句是对条件加以限定；3、分组语句【group by…… having】；4、聚合函数；5、select语句；6、order by排序语句。\")])]),e._v(\" \"),n(\"p\",[e._v(\"--- 28.查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩\\nselect a.sno, b.sname, avg(a.score) from sc as a\\ninner join student as b on a.sno=b.sno\\nwhere a.score<60 group by a.sno having count(a.score)>=2;\\n如果\")]),e._v(\" \"),n(\"p\",[e._v(\"内外连接选择看需不需要显示NUll数据\")]),e._v(\" \"),n(\"p\",[e._v('-- 34. 查询\" 01 \"课程比\" 02 \"课程成绩高的学生的信息及课程分数\\n/* 思路：1.在sc表中选出临时表b（\" 01 \"课程），临时表c（\" 02 \"课程）;\\n2.ab表相交条件：学生号相同且a表成绩>b表成绩\\n3.再与student表相交 '),n(\"em\",[e._v(\"/\\nselect a.\")]),e._v(\", b.score as '01', c.score as '02'\\nfrom student as a\\ninner join (select * from sc where cno='01') as b on a.sno=b.sno\\ninner join (select * from sc where cno='02') as c on b.sno=c.sno and b.score>c.score;\")]),e._v(\" \"),n(\"p\",[e._v(\"-窗口函数\\n--37. 按各科成绩进行排序，并显示排名，Score 重复时保留名次空缺\\nselect *, rank() over (partition by cno order by score desc) as ranking\\nfrom sc; 113\")]),e._v(\" \"),n(\"p\",[e._v(\"dense_rank() 重复时合并名次112\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"定义\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#定义\"}},[e._v(\"#\")]),e._v(\" 定义\")]),e._v(\" \"),n(\"p\",[e._v(\"开放源代码的关系型数据库管理系统\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mysql存储引擎区别\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql存储引擎区别\"}},[e._v(\"#\")]),e._v(\" MySQL存储引擎区别\")]),e._v(\" \"),n(\"table\",[n(\"thead\",[n(\"tr\",[n(\"th\",[e._v(\"表头\")]),e._v(\" \"),n(\"th\",[e._v(\"InnoDB\")]),e._v(\" \"),n(\"th\",[e._v(\"MYISAM\")])])]),e._v(\" \"),n(\"tbody\",[n(\"tr\",[n(\"td\",[e._v(\"外键\")]),e._v(\" \"),n(\"td\",[e._v(\"支持\")]),e._v(\" \"),n(\"td\")]),e._v(\" \"),n(\"tr\",[n(\"td\",[e._v(\"锁\")]),e._v(\" \"),n(\"td\",[e._v(\"表锁和行锁\")]),e._v(\" \"),n(\"td\",[e._v(\"表锁\")])]),e._v(\" \"),n(\"tr\",[n(\"td\",[e._v(\"可恢复性\")]),e._v(\" \"),n(\"td\",[e._v(\"由事务日志恢复\")]),e._v(\" \"),n(\"td\",[e._v(\"无日志\")])]),e._v(\" \"),n(\"tr\",[n(\"td\",[e._v(\"索引与表结构\")]),e._v(\" \"),n(\"td\",[e._v(\"聚簇，数据与索引集中存储，.ibd和.frm\")]),e._v(\" \"),n(\"td\",[e._v(\"数据.MYD，索引.MYI\")])]),e._v(\" \"),n(\"tr\",[n(\"td\",[e._v(\"查询性能\")]),e._v(\" \"),n(\"td\"),e._v(\" \"),n(\"td\",[e._v(\"一般快\")])])])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"三大范式\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#三大范式\"}},[e._v(\"#\")]),e._v(\" 三大范式：\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"第一：每列保持原子性，字段不可分解\")]),e._v(\" \"),n(\"li\",[e._v(\"第二：表中每列都和主键相关\")]),e._v(\" \"),n(\"li\",[e._v(\"第三：表中每列都和主键列直接相关\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"数据类型\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据类型\"}},[e._v(\"#\")]),e._v(\" 数据类型\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"整数\")]),e._v(\" \"),n(\"li\",[e._v(\"浮点数\")])]),e._v(\" \"),n(\"p\",[e._v(\"DECIMAL为浮点数，使用字符串存储，能精确到小数\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"日期\")])]),e._v(\" \"),n(\"p\",[e._v(\"常用的有year、time、date、datatime(1000年-9999年，秒，8位，时区无关)、timestamp（1970-2038年，秒，4位，时区相关）\\n应用场景：尽量使用timestamp,更高的空间效率\")]),e._v(\" \"),n(\"h2\",{attrs:{id:\"索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引\"}},[e._v(\"#\")]),e._v(\" 索引\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"定义-2\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#定义-2\"}},[e._v(\"#\")]),e._v(\" 定义：\")]),e._v(\" \"),n(\"p\",[e._v(\"对数据库表的一列或多列的值进行排序的一种结构\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引优缺点\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引优缺点\"}},[e._v(\"#\")]),e._v(\" 索引优缺点\")]),e._v(\" \"),n(\"p\",[e._v(\"优点：\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"加快数据的检索速度\")]),e._v(\" \"),n(\"li\",[e._v(\"将随机I/O变成顺序I/O（B+树的叶子节点连接在一起）\")]),e._v(\" \"),n(\"li\",[e._v(\"加速表与表之间的连接\")])]),e._v(\" \"),n(\"p\",[e._v(\"缺点：\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"索引占用物理空间(空间)\")]),e._v(\" \"),n(\"li\",[e._v(\"创建和维护索引都需要时间(时间)\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引的数据结构\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引的数据结构\"}},[e._v(\"#\")]),e._v(\" 索引的数据结构\")]),e._v(\" \"),n(\"p\",[e._v(\"索引的数据结构主要是B+树和哈希表，对应的索引分别为B+树索引(InnoDB引擎的默认索引类型)和哈希索引（InnoDB）\\nB+树：所有的记录节点都是按照键值的大小顺序放在叶子节点上（有序性，效率高，支持排序和范围查询）.\")]),e._v(\" \"),n(\"p\",[e._v(\"哈希：对每行数据的索引列哈希计算，哈希值为key，指向数据行的指针作为哈希表value,适合精确查找O(1)\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"b-hash索引区别\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#b-hash索引区别\"}},[e._v(\"#\")]),e._v(\" B+,hash索引区别\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"哈希一般用精确的等值查找，B+树除了精确的等值查找外还有其他查找（大多数情况选用）\")]),e._v(\" \"),n(\"li\",[e._v(\"哈希不支持排序，哈希表无序\")]),e._v(\" \"),n(\"li\",[e._v(\"哈希不支持范围查找\")]),e._v(\" \"),n(\"li\",[e._v(\"哈希不支持模糊查询及多列索引的最左前缀匹配\")]),e._v(\" \"),n(\"li\",[e._v(\"哈希有冲突不稳定，B+树稳定（每次都从根节点到叶子节点）\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引种类-一个索引可有多个种类\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引种类-一个索引可有多个种类\"}},[e._v(\"#\")]),e._v(\" 索引种类（一个索引可有多个种类）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"主键索引：数据列不能重复和NULL，一个表只能有一个主键索引\")]),e._v(\" \"),n(\"li\",[e._v(\"组合索引：多个列值组成的索引\")]),e._v(\" \"),n(\"li\",[e._v(\"唯一索引：数据列不能重复，可以NULL，索引值唯一\")]),e._v(\" \"),n(\"li\",[e._v(\"全文索引：对文本内容搜索\")]),e._v(\" \"),n(\"li\",[e._v(\"普通索引：基本的索引类型，可为NULL\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"b树和b-树区别\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#b树和b-树区别\"}},[e._v(\"#\")]),e._v(\" B树和B+树区别\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"B+树叶子节点相连，方便顺序检索\")]),e._v(\" \"),n(\"li\",[e._v(\"B树内部节点和叶子节点都放键值，B+树内部节点只有键没值，叶子节点放键和值\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"不选b树的原因\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#不选b树的原因\"}},[e._v(\"#\")]),e._v(\" 不选B树的原因\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"B+树空间利用率更高，B+树内部节点只存储键，树高度变低，减少I/O次数，检索更快\")]),e._v(\" \"),n(\"li\",[e._v(\"B+叶子节点连接在一起，范围查找，顺序查找方便\")]),e._v(\" \"),n(\"li\",[e._v(\"B+树更稳定，查询从根节点到叶子节点，B树适合随机检索，B+树适合随机检索和顺序检索\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"聚簇索引-非聚簇索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#聚簇索引-非聚簇索引\"}},[e._v(\"#\")]),e._v(\" 聚簇索引，非聚簇索引\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"聚簇索引：数据和结构一起存储，索引结构的叶子节点保留数据行\")]),e._v(\" \"),n(\"li\",[e._v(\"非聚簇索引：数据和索引分开存储，索引叶子检点存储的是指向数据行的地址\")])]),e._v(\" \"),n(\"p\",[e._v(\"InnoDB：主聚辅非聚\\nMyISAM：主非聚辅非聚\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"非聚簇索引不一定回表-涉及索引覆盖\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#非聚簇索引不一定回表-涉及索引覆盖\"}},[e._v(\"#\")]),e._v(\" 非聚簇索引不一定回表，涉及索引覆盖\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"当select 主键,xx where xx=,走辅助索引能查数据，这就是索引覆盖\")]),e._v(\" \"),n(\"li\",[e._v(\"select 主键，xx,xx1 where xx=，需要建立xx和xx1的联合索引\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引设计原则\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引设计原则\"}},[e._v(\"#\")]),e._v(\" 索引设计原则\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"适合索引列在where后出行的列或连接句子中指定的列，而不是select后的列\")]),e._v(\" \"),n(\"li\",[e._v(\"索引列基数大效果好，即区分度高的列\")]),e._v(\" \"),n(\"li\",[e._v(\"尽量用短索引(磁盘I/O少，缓存能存更多键值)\")]),e._v(\" \"),n(\"li\",[e._v(\"尽量使用最左前缀\")]),e._v(\" \"),n(\"li\",[e._v(\"不要过度索引，创建维护需要时间空间\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引的使用场景\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引的使用场景\"}},[e._v(\"#\")]),e._v(\" 索引的使用场景\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引优化\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引优化\"}},[e._v(\"#\")]),e._v(\" 索引优化\")]),e._v(\" \"),n(\"p\",[e._v(\"将不符合要求的索引优化成符合索引设计原则和应用场景的索引\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"索引的设计原则\")]),e._v(\" \"),n(\"li\",[e._v(\"索引不能是表达式一部分和函数的参数，如where a+1=2\")]),e._v(\" \"),n(\"li\",[e._v(\"将区分度高的索引放在前面\")]),e._v(\" \"),n(\"li\",[e._v(\"少使用select *\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"创建-删除索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#创建-删除索引\"}},[e._v(\"#\")]),e._v(\" 创建/删除索引\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"经典sql语句\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#经典sql语句\"}},[e._v(\"#\")]),e._v(\" 经典sql语句\")]),e._v(\" \"),n(\"p\",[e._v(\"Student(S#,Sname,Sage,Ssex) 学生表\")]),e._v(\" \"),n(\"p\",[e._v(\"Course(C#,Cname,T#) 课程表\")]),e._v(\" \"),n(\"p\",[e._v(\"SC(S#,C#,score) 成绩表\")]),e._v(\" \"),n(\"p\",[e._v(\"Teacher(T#,Tname) 教师表\")]),e._v(\" \"),n(\"h2\",{attrs:{id:\"mysql优化\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql优化\"}},[e._v(\"#\")]),e._v(\" Mysql优化\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"系统如何与mysql交互\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#系统如何与mysql交互\"}},[e._v(\"#\")]),e._v(\" 系统如何与Mysql交互\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"Java系统通过Mysql驱动(建立网络连接，执行sql语句)实现与数据库交互\\n注:不同语言驱动也不同\")]),e._v(\" \"),n(\"li\",[e._v(\"建立数据库连接池(供多线程使用，Tomcat和数据库服务器都有)访问数据库\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mysql架构设计-执行sql\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql架构设计-执行sql\"}},[e._v(\"#\")]),e._v(\" MySQL架构设计（执行SQL）\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条SQL语句，那么大家先思考一个问题，\\n谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？  ---\\x3e线程获取sql语句，交予sql接口通过查询解析器解析sql，找查询优化器(选择最优的查询路径)，执行器调用存储引擎接口（执行sql语句，存储引擎和内存、磁盘交互）\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"innodb存储引擎架构设计\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#innodb存储引擎架构设计\"}},[e._v(\"#\")]),e._v(\" InnoDB存储引擎架构设计\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"缓冲池：缓存数据（加载磁盘数据时同时对数据加锁）\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"Redo Log Buffer:系统宕机，避免数据丢失（缓冲池中）\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"undo日志文件：可以使更新数据回滚(磁盘中的)\")])]),e._v(\" \"),n(\"li\"),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"redo日志文件（是InnoDB存储引擎特有）：提交事务的时候将redo日志写入磁盘，三种刷屏策略innodb_flush_log_at_trx_commit，0不刷、1刷  2延时刷（先放os cache）\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"binlog：重做日志（mysql server的日志文件，提交事务的时候，同时会写入binlog，sync_binlog参数，0延时刷（先放os cache），1刷）\\n当我们把binlog写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的binlog文件名称和这次\\n更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标记（如redo log刚刷磁盘宕机，commit标记，判定事务不成功，）。\")])])]),e._v(\" \"),n(\"p\",[e._v(\"MySQL有一个后台的IO线程，会在之后某个时间里，\"),n(\"strong\",[e._v(\"随机的把内存buffer pool中的修改后的脏数据给刷回到磁盘\")]),e._v(\"上的数据文件里（事务提交后的数据，后面详解时有4中刷redo log）\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"生产环境数据库机器配置\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产环境数据库机器配置\"}},[e._v(\"#\")]),e._v(\" 生产环境数据库机器配置\")]),e._v(\" \"),n(\"p\",[e._v(\"Java应用系统部署的时候常选用的机器配置大致是2核4G和4核8G的较多一些，数据库部\\n署的时候常选用的机器配置最低在8核16G以上，正常在16核32G\")]),e._v(\" \"),n(\"p\",[e._v(\"大量的高并发线上系统的生产经验观察下来而言，一般Java应用系统部署在4核8G的机器上，每秒钟抗下500左右\\n的并发访问量，差不多是比较合适的，当然这个也不一定。因为你得考虑一下，假设你每个请求花费1s可以处理完，那么你一\\n台机器每秒也许只可以处理100个请求，但是如果你每个请求只要花费100ms就可以处理完，那么你一台机器每秒也许就可以\\n处理几百个请求。一台机器能抗下每秒多少请求，往往是跟你每个请求处理耗费多长时间是关联的\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"高并发场景机器选择：通常推荐的数据库至少是选用8核16G以的机器，甚至是16核32G的机器更加合适一\\n些。主要耗费时间的是Java系统和数据库之间的网络通信。MySQL数据库需要对内存和磁盘文件进行大量的IO操作，所以数据库往往是负载最高的。因为数据库需要\\n执行大量的磁盘IO操作，他的每个请求都比较耗时一些，所以机器的配置自然需要高一些了。一般8核16G的机器部署的MySQL数据库，每秒抗个一两千并发请求是没问题的。对于16核32G的机器部署的MySQL数据库而言，每秒抗个两三千，甚至三四千的并发请求也都是可以的，那么数据库的CPU、磁盘、IO、内存的负载瞬间都会飙升到很高，数据库也是可能会扛不住宕机的。\\n内部资源禁止\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"生产环境数据如何性能测试\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产环境数据如何性能测试\"}},[e._v(\"#\")]),e._v(\" 生产环境数据如何性能测试\")]),e._v(\" \"),n(\"p\",[e._v(\"基于一些工具模拟一个系统每秒发出1000，2000，3000个请求到数据库上去，观察一下他的CPU负载、磁盘IO负载、网络\\nIO负载、内存复杂，然后数据库能否每秒处理掉这1000个请求，还是每秒只能处理500个请求。\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库的压测和他上面的Java系统的压测，其实是两回事儿，首先你得知道你的数\\n据库最大能抗多大压力，然后你再去看你的Java系统能抗多大压力。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"压测数据库，最终是想看看这个数据库在现有的机器配置之下，每秒可以抗下多\\n少个请求呢？这个每秒抗下多少个请求，其实是有专业术语的，分别是QPS和TPS。\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"QPS:一次请求\\n就是一条SQL语句，也就是说这个数据库每秒可以处理多少个SQL语句。\\n资源禁止\")]),e._v(\" \"),n(\"li\",[e._v(\"TPS：数据库每秒会处理多少次事务提交或者回滚。（多条SQL语句）\\n如：对于这个交易系统，他拆分为了很多服务，一笔交易的\\n完成需要多个服务协作完成，也就是说一次交易请求需要调用多个服务才能完成。\\n那么你觉得对于每个服务而言，他每秒处理的请求数量是QPS还是TPS呢？对于整个交易系统而言，他每秒钟处理的交易笔数是TPS。\")])]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"IO相关的压测性能指标\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"IOPS：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机\\nIO读写请求。\")]),e._v(\" \"),n(\"li\",[e._v(\"吞吐量：这个指的是机器的磁盘存储每秒可以读写多少字节的数据量\")])]),e._v(\" \"),n(\"p\",[e._v(\"注：一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一\\n般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那\\n么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。\\n内部资源禁止外传\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"3\"}},[n(\"li\",[n(\"p\",[e._v(\"latency：这个指标说的是往磁盘里写入一条数据的延迟。\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"CPU负载：与QPS相关\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"网络负载：与QPS相关\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"内存负载\\n数据库压测工具，就是sysbench，压测步骤\\nsysbench中不停的增加线程的数量，比如使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。\\n如：使用了10个线程去压测数据库，如果你的机器性能很\\n高，然后你觉得10个线程没法压测出来数据库真实的最高负载能力，你其实可以在sysbench中不停的增加线程的数量，比如\\n使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。\")])])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"压测时常用linux常用指令\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#压测时常用linux常用指令\"}},[e._v(\"#\")]),e._v(\" 压测时常用Linux常用指令\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"执行top命令后\\ntop - 15:52:00 up 42:35, 1 user, load average: 0.15, 0.05, 0.01 （up运行时间，CPU在1分钟、5分钟、15分钟内的负载情况，指核数）\")])]),e._v(\" \"),n(\"p\",[e._v(\"Mem: 33554432k total, 20971520k used, 12268339 free, 307200k buffers（内存）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"dstat（IO读写数据量）\")]),e._v(\" \"),n(\"li\",[e._v(\"dstat -r（磁盘随机读取写入次数）\")]),e._v(\" \"),n(\"li\",[e._v(\"dstat -n(网卡流量)\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"数据库部署监控系统与为数据库的监控系统部署可视化报表系统\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据库部署监控系统与为数据库的监控系统部署可视化报表系统\"}},[e._v(\"#\")]),e._v(\" 数据库部署监控系统与为数据库的监控系统部署可视化报表系统\")]),e._v(\" \"),n(\"p\",[e._v(\"搭建一下生产环境数据库的可视化监控平台，我们会基于Prometheus+Grafana来搭建。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"详细buffer-pool\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#详细buffer-pool\"}},[e._v(\"#\")]),e._v(\" 详细Buffer Pool\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/sql.PNG\",alt:\"sql执行\"}}),e._v(\"\\n对数据库执行增删改操作的时候，实际上主要都是针对内存里的Buffer Pool中的数据进行的，也就是你实际上主要是对数据库的内存里的数据结构进行了增删改\")]),e._v(\" \"),n(\"p\",[e._v(\"配置：\\n[server]\\ninnodb_buffer_pool_size = 2147483648\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库的核心数据模型就是表+字段+行\")]),e._v(\" \"),n(\"p\",[e._v(\"Buffer pool:内存数据结构（非一行一行数据放置，将很多行数据放在一个数据页中）默认128MB\")]),e._v(\" \"),n(\"p\",[e._v(\"磁盘数据页与Buffer Pool缓存页如何对应：Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。\")]),e._v(\" \"),n(\"p\",[e._v(\"缓存页中的描述信息：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂\\n八的东西。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/bufferpool.PNG\",alt:\"buffer pool\"}})]),e._v(\" \"),n(\"p\",[e._v(\"注：Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字\\n节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130\\n多MB的样子，因为他里面还要存放每个缓存页的描述数据。Buffer Pool划分完全部的缓存页和描述数据块之后，还剩一点点的内存，这一点\\n点的内存放不下任何一个缓存页了，所以这点内存就只能放着不能用，这就是内存碎片。数据库在Buffer Pool中划分缓存页的时候，会让所有的缓存页和描述数据块都紧密的挨在一起，这样尽可能减\\n少内存浪费，就可以尽可能的减少内存碎片的产生了。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"free链表-磁盘读取数据页到buffer-pool\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#free链表-磁盘读取数据页到buffer-pool\"}},[e._v(\"#\")]),e._v(\" free链表（磁盘读取数据页到Buffer Pool）\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区\\n域，作为Buffer Pool的内存区域。数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在\\nBuffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据（空页）。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"Buffer Pool中哪些缓存页是空闲的状态\\nfree链表：双向链表数据结构，每个节点就是一个空闲的缓存页的描述数据块的地址。只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个free链表中。\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/free.PNG\",alt:\"free\"}})])]),e._v(\" \"),n(\"p\",[e._v(\"free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面就存放了free链表的头节点\\n的地址，尾节点的地址，还有free链表里当前有多少个节点。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"如何看数据页是否被缓存\\n数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个key，然后缓存页的地址作为value。当你要使用一个数据页的时候，通过“表空间号+数据页号”作为key去这个哈希表里查一下，如果没有就读取数据页，如果\\n已经有了，就说明数据页已经被缓存了。\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"写sql的时候-只知道表-行的概念-但是在mysql内部操作的时候-是表空间-数据页的概念。区别与联系\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#写sql的时候-只知道表-行的概念-但是在mysql内部操作的时候-是表空间-数据页的概念。区别与联系\"}},[e._v(\"#\")]),e._v(\" 写SQL的时候，只知道表+行的概念，但是在MySQL内部操作的时候，是表空间+数据页的概念。区别与联系\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"flush链表-更新buffer-pool数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#flush链表-更新buffer-pool数据\"}},[e._v(\"#\")]),e._v(\" flush链表(更新Buffer Pool数据)\")]),e._v(\" \"),n(\"p\",[e._v(\"脏数据和脏页：缓存更新后未刷入硬盘的数据和数据页\")]),e._v(\" \"),n(\"p\",[e._v(\"不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到Buffer Pool里去的，可能根本没修改过！\")]),e._v(\" \"),n(\"p\",[e._v(\"flush链表：通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/flush.PNG\",alt:\"flush\"}})]),e._v(\" \"),n(\"p\",[e._v(\"描述数据页结构：\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/node.PNG\",alt:\"node\"}})]),e._v(\" \"),n(\"h4\",{attrs:{id:\"lru算法-buffer-pool缓存页不够-淘汰缓存\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#lru算法-buffer-pool缓存页不够-淘汰缓存\"}},[e._v(\"#\")]),e._v(\" LRU算法(Buffer pool缓存页不够，淘汰缓存)\")]),e._v(\" \"),n(\"p\",[e._v(\"淘汰缓存页：把一个缓存页里被修改过的数据，给他刷到磁盘上的数据页里去，然后这个缓存页就可以清空了，让他重新变成一个空闲的缓存页。\")]),e._v(\" \"),n(\"p\",[e._v(\"LRU链表（Least Recently Used）：判断哪些缓存页不常用的\")]),e._v(\" \"),n(\"p\",[e._v(\"LRU链表机制：只要是刚从磁盘上加载数据到缓存页里去，这个缓存页就放入LRU链表的头部，后续如果\\n对任何一个缓存页访问了，也把缓存页从LRU链表中移动到头部去。当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此\\n时你就直接在LRU链表的尾部找到一个缓存页，他一定是最近最少被访问的那个缓存页！\")]),e._v(\" \"),n(\"p\",[e._v(\"注:表、列和行，都是逻辑概念，我们只知道数据库里有一个表，表里有几个字段，有多少行，但是这些表里的数据，在\\n数据库的磁盘上如何存储的，你知道吗？我们是不关注的，所以他们都是逻辑上的概念。\\n表空间、数据页，这些东西，都是物理上的概念，实际上在物理层面，你的表里的数据都放在一个表空间中，表空间\\n是由一堆磁盘上的数据文件组成的，这些数据文件里都存放了你表里的数据，这些数据是由一个一个的数据页组织起\\n来的，这些都是物理层面的概念，这就是他们之间的区别。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"存在问题：\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[e._v(\"MySQL的预读机制（参数innodb_random_read_ahead默认OFF）：从磁盘上加载一个数据页的时候，他可\\n能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去！相邻的数据页被放在LRU链表前列，若不访问，会把LRU尾部的那些被频繁访问的缓存页刷入磁盘中。\\n注：触发MySQL预读机制：innodb_read_ahead_threshold默认56，顺序的访问了一个区里的多个\\n数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制；Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会\\n直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"全表扫描，没加任何一个where条件，会导致他直接一下子把这个表里所有的数据页，都从磁盘加载到Buffer Pool里去。LRU链表中排在前面的一大\\n串缓存页，都是全表扫描加载进来的缓存页。\")])])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"优化lru算法-冷热数据分离方案\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#优化lru算法-冷热数据分离方案\"}},[e._v(\"#\")]),e._v(\" 优化LRU算法(冷热数据分离方案)\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由\\ninnodb_old_blocks_pct参数控制的，他默认是37，也就是说冷数据占比37%。\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/lru.PNG\",alt:\"LRU\"}})])]),e._v(\" \"),n(\"p\",[e._v(\"机制：数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部\\ninnodb_old_blocks_time参数，默认值1000，也就是1000毫秒，一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链\\n表头部去。\")]),e._v(\" \"),n(\"p\",[e._v(\"解决了预读机制和全表扫描加载进来的缓存页，都在冷数据区。（如全表扫描的查询，此时你肯定是在1s内就把一大堆缓存页加载进来，然后就访问了这些缓存页一\\n下，通常这些操作1s内就结束了。\")]),e._v(\" \"),n(\"p\",[e._v(\"思考：开发的Java系统，如果在Redis里存放了很多缓存数据，那么此时会不会有类似冷热数据的问题？应该如何优化和解决呢？\")]),e._v(\" \"),n(\"p\",[e._v(\"故在设计缓存机制的时候，经常会考虑热数据的缓存预加载。（每天统计出来哪些商品被访问的次数最多，然后晚上的时候，系统启动一个定时作业，把这些热门商品的\\n数据，预加载到Redis里。）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"LRU链表热数据区极致优化（减少链表中的节点移动\\n部资）：只有在热数据区域的后3/4部分的缓存页被访问了，才\\n会给你移动到链表头部去。热数据区域的前面1/4的缓存页被访问，不会移动到链表头部去的。\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"lru链表淘汰刷盘\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#lru链表淘汰刷盘\"}},[e._v(\"#\")]),e._v(\" LRU链表淘汰刷盘\")]),e._v(\" \"),n(\"p\",[e._v(\"加载数据页，free链表移除，lru冷数据头部放入\")]),e._v(\" \"),n(\"p\",[e._v(\"修改缓存页，flush添加，lru冷数据移动热数据头部\")]),e._v(\" \"),n(\"p\",[e._v(\"查询数据页，lru冷数据移动热数据或热数据移动到头部或不移动（在1/4热数据）\")]),e._v(\" \"),n(\"p\",[e._v(\"数据页刷入硬盘，free添加，flush移除，lru移除\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"刷硬盘时机（缓存页不够，单纯脏数据）\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"冷数据尾部：后台线程定时刷，清空缓存页，加入free链表（不需要缓存页满）\")]),e._v(\" \"),n(\"li\",[e._v(\"flush链表：MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的，只要flush链表中的一波缓存页被刷入了磁盘，那么这些缓存页也会从flush链表和lru链表中移除，然后加入到free链表\\n中去！（lru链表的热数据区域里的很多缓存页可能也会被频繁的修改，难道他们永远都不刷入磁盘中了）\")]),e._v(\" \"),n(\"li\",[e._v(\"没空闲缓存页：即未到定时时间，如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页，刷入磁盘（如果频繁，crud是都要先刷一个缓存页到硬盘，再从磁盘上读取一个数据页到空闲的缓存页里来？这样岂不是每次CRUD操作都要执行两次磁盘IO？那么性能岂不是会极差？）\")])]),e._v(\" \"),n(\"p\",[e._v(\"-如何避免刷盘时间第三种：你的MySQL的内核参数，应该如何优化，优化哪些地方的行为\\n部资源禁\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"生产经验-buffer-pool配置\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产经验-buffer-pool配置\"}},[e._v(\"#\")]),e._v(\" 生产经验：Buffer Pool配置\")]),e._v(\" \"),n(\"p\",[e._v(\"Buffer Pool其实本质就是一大块内存数据结构，由一大堆的缓存页和描述数\\n据块组成的，然后加上了各种链表（free、flush、lru）\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL同时接收到了多个请求，他自然会用多个线程来处理这多个请求，每个线程会负责处理\\n一个请求，多个线程是不是应该会同时去访问Buffer Pool呢？就是同时去操作里面的缓存页，同时操作一个free链表、\\nflush链表、lru链表，是吗？多线程并发访问一个Buffer Pool，必然是要加锁的，性能问题\")]),e._v(\" \"),n(\"p\",[e._v(\"注：MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个BufferPool。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"优化：MySQL设置多个Buffer Pool来优化他的并发能力。\")])]),e._v(\" \"),n(\"p\",[e._v(\"如：buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小\\n就是2GB\")]),e._v(\" \"),n(\"p\",[e._v(\"[server]\\ninnodb_buffer_pool_size = 8589934592\\ninnodb_buffer_pool_instances = 4\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"通过chunk动态调整buffer-pool大小-动态扩展不需要数据拷贝问题\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#通过chunk动态调整buffer-pool大小-动态扩展不需要数据拷贝问题\"}},[e._v(\"#\")]),e._v(\" 通过chunk动态调整Buffer Pool大小（动态扩展不需要数据拷贝问题）\")]),e._v(\" \"),n(\"p\",[e._v(\"如：向操作系统申请一块新的16GB的连续内存，然后把现在的buffer pool中的所有缓存页、描述数据\\n块、各种链表，都拷贝到新的16GB的内存中去。这个过程是极为耗时的，性能很低下，是不可以接受的\")]),e._v(\" \"),n(\"p\",[e._v(\"每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套\\nfree、flush、lru这些链表\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/chunk.PNG\",alt:\"chunk\"}})]),e._v(\" \"),n(\"p\",[e._v(\"如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就\\n可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了,即不需要额外申请16GB的连续空间，不需要复制已有数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"多线程如何保证数据事务问题\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"高并发实际场景：Java系统访问数据库的并发程度来决定的，你高并发\\n访问数据库，缓存页必然使用的很快了！\\n然后你后台线程定时释放一批缓存页，这个过程也很难去优化，因为你要是释放的过于频繁了，那么后台线程执行磁\\n盘IO过于频繁，也会影响数据库的性能。\\n所以这里的关键点就在于，你的buffer pool有多大！如果你的数据库要抗高并发的访问，那么你的机器必然要配置很大的内存空间，起码是32GB以上的，甚至64GB或者\\n128GB。此时你就可以给你的buffer pool设置很大的内存空间，比如20GB，48GB，甚至80GB。buffer pool内存很大，所以空闲缓存页是很多很多的，即使你的空闲缓存页逐步的减少，也可能需要较长时\\n间才会发现缓存页用完了，此时才会出现一次crud操作执行的时候，先刷缓存页到磁盘，再读取数据页到缓存页来，\\n这种情况是不会出现的太频繁的！线上的MySQL在生产环境中，buffer pool的大小、buffer pool的数量，这都是要用心设置和优化的，因为多\\nMySQL的性能和并发能力，都会有较大的影响。\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"生产环境如何确定Buffer Pool大小：\")])])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"建议一个比较合理的、健康的比例，是给buffer pool设置你的机器内存的50%~60%左右，如内存32GB，Buffer Pool20GB\")]),e._v(\" \"),n(\"li\",[e._v(\"buffer pool总大小=(chunk大小 * buffer pool数量)的2倍数\")])]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"总结\\n我们再来做一点总结，就是说你的数据库在生产环境运行的时候，你必须根据机器的内存设置合理的buffer pool的大\\n小，然后设置buffer pool的数量，这样的话，可以尽可能的保证你的数据库的高性能和高并发能力。\\n然后在线上运行的时候，buffer pool是有多个的，每个buffer pool里多个chunk但是共用一套链表数据结构，然后执\\n行crud的时候，就会不停的加载磁盘上的数据页到缓存页里来，然后会查询和更新缓存页里的数据，同时维护一系列\\n的链表结构。\\n然后后台线程定时根据lru链表和flush链表，去把一批缓存页刷入磁盘释放掉这些缓存页，同时更新free链表。\\n如果执行crud的时候发现缓存页都满了，没法加载自己需要的数据页进缓存，此时就会把lru链表冷数据区域的缓存页\\n刷入磁盘，然后加载自己需要的数据页进来。\\n整个buffer pool的结构设计以及工作原理，就是上面我们总结的这套东西了，大家只要理解了这个，首先你对MySQL\\n执行crud的时候，是如何在内存里查询和更新数据的，你就彻底明白了。\\n接着我们后面继续探索undo log、redo log、事务机制、事务隔离、锁机制，这些东西，一点点就把MySQL他的数据\\n更新、事务、锁这些原理，全部搞清楚了，同时中间再配合穿插一些生产经验、实战案例。\\n4、SHOW ENGINE INNODB STATUS\\n当你的数据库启动之后，你随时可以通过上述命令，去查看当前innodb里的一些具体情况，执行SHOW ENGINE\\nINNODB STATUS就可以了。此时你可能会看到如下一系列的东西：\\nTotal memory allocated xxxx;\\nDictionary memory allocated xxx\\nBuffer pool size xxxx\\n内部资源禁止外传\\nFree buffers xxx\\nDatabase pages xxx\\nOld database pages xxxx\\nModified db pages xx\\nPending reads 0\\nPending writes: LRU 0, flush list 0, single page 0\\nPages made young xxxx, not young xxx\\nxx youngs/s, xx non-youngs/s\\nPages read xxxx, created xxx, written xxx\\nxx reads/s, xx creates/s, 1xx writes/s\\nBuffer pool hit rate xxx / 1000, young-making rate xxx / 1000 not xx / 1000\\nPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s\\nLRU len: xxxx, unzip_LRU len: xxx\\nI/O sum[xxx]:cur[xx], unzip sum[16xx:cur[0]\\n下面我们给大家解释一下这里的东西，主要讲解这里跟buffer pool相关的一些东西。\\n（1）Total memory allocated，这就是说buffer pool最终的总大小是多少\\n（2）Buffer pool size，这就是说buffer pool一共能容纳多少个缓存页\\n（3）Free buffers，这就是说free链表中一共有多少个空闲的缓存页是可用的\\n（4）Database pages和Old database pages，就是说lru链表中一共有多少个缓存页，以及冷数据区域里的缓存页\\n数量\\n（5）Modified db pages，这就是flush链表中的缓存页数量\\n（6）Pending reads和Pending writes，等待从磁盘上加载进缓存页的数量，还有就是即将从lru链表中刷入磁盘的数\\n量、即将从flush链表中刷入磁盘的数量\\n（7）Pages made young和not young，这就是说已经lru冷数据区域里访问之后转移到热数据区域的缓存页的数\\n量，以及在lru冷数据区域里1s内被访问了没进入热数据区域的缓存页的数量\\n（8）youngs/s和not youngs/s，这就是说每秒从冷数据区域进入热数据区域的缓存页的数量，以及每秒在冷数据区\\n域里被访问了但是不能进入热数据区域的缓存页的数量\\n内部资源禁止外传\\n（9）Pages read xxxx, created xxx, written xxx，xx reads/s, xx creates/s, 1xx writes/s，这里就是说已经读取、\\n创建和写入了多少个缓存页，以及每秒钟读取、创建和写入的缓存页数量\\n（10）Buffer pool hit rate xxx / 1000，这就是说每1000次访问，有多少次是直接命中了buffer pool里的缓存的\\n（11）young-making rate xxx / 1000 not xx / 1000，每1000次访问，有多少次访问让缓存页从冷数据区域移动到\\n了热数据区域，以及没移动的缓存页数量\\n（12）LRU len：这就是lru链表里的缓存页的数量\\n（13）I/O sum：最近50s读取磁盘页的总数\\n（14）I/O cur：现在正在读取磁盘页的数量\\n5、今日实践思考题\\n今天留给大家的作业，就是每个人都对自己线上在运行的数据库执行上述命令，然后分析一下数据库的buffer pool的\\n使用情况\\n这里要尤为关注的是free、lru、flush几个链表的数量的情况，然后就是lru链表的冷热数据转移的情况，然后你的缓存\\n页的读写情况，这些代表了你当前buffer pool的使用情况。\\n最关键的是两个东西，一个是你的buffer pool的千次访问缓存命中率，这个命中率越高，说明你大量的操作都是直接\\n基于缓存来执行的，性能越高。\\n第二个是你的磁盘IO的情况，这个磁盘IO越多，说明你数据库性能越差。\")])]),e._v(\" \"),n(\"h3\",{attrs:{id:\"探索undo-log、redo-log、事务机制、事务隔离、锁机制\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#探索undo-log、redo-log、事务机制、事务隔离、锁机制\"}},[e._v(\"#\")]),e._v(\" 探索undo log、redo log、事务机制、事务隔离、锁机制\")]),e._v(\" \"),n(\"p\",[e._v(\"部资源\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"写入数据库的一行数据在磁盘如何存储\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#写入数据库的一行数据在磁盘如何存储\"}},[e._v(\"#\")]),e._v(\" 写入数据库的一行数据在磁盘如何存储\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么不能直接更新磁盘上的数据，因为来一个请求就直接对磁盘文件进行随机读写，然后\\n更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"一行数据在磁盘上是如何存储的：\\n其实这里涉及到一个概念，就是行格式。我们可以对一个表指定他的行存储的格式是什么样的，比如我们这里用一个\\nCOMPACT格式。\\nCREATE TABLE table_name (columns) ROW_FORMAT=COMPACT\\nALTER TABLE table_name ROW_FORMAT=COMPACT\")])]),e._v(\" \"),n(\"p\",[e._v(\"如：CREATE TABLE customer (\\nname VARCHAR(10) NOT NULL,\\naddress VARCHAR(20),\\ngender CHAR(1),\\njob VARCHAR(30),\\nschool VARCHAR(50)\\n) ROW_FORMAT=COMPACT;\")]),e._v(\" \"),n(\"p\",[e._v(\"你可以在建表的时候，就指定一个行存储的格式，也可以后续修改行存储的格式。这里指定了一个COMPACT行存储\\n格式，在这种格式下，每一行数据他实际存储的时候，大概格式类似下面这样：\\n变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......\\n对于每一行数据，他其实存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据每一列\\n的具体的值，这就是所谓的行格式。除了COMPACT以外，还有其他几种行存储格式，基本都大同小异。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"一行数据的存储格式大致如下所示。\\n变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"引入变长字段的长度列表，解决一行数据的读取问题\")])])]),e._v(\" \"),n(\"p\",[e._v(\"假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1)\\nCHAR(1)，hello是VARCHAR(10)类型的变长字段的值，那么这个“hello”字段值的长度到底是多少？\\n我们看到“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息，首先就是变\\n长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：0x05 null值列表 数据头\\nhello a a。\")]),e._v(\" \"),n(\"p\",[e._v(\"实际存放在变长字段长度列表、NULL值列表，是逆序放的。（多变长字段列表）\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么MySQL不能用Java里面的序列化的那种方式？把很多行的数据做成一个大的对象，然后给他序列化一下写入到\\n磁盘文件里，从磁盘里读取的时候压根儿不用care什么行存储格式，直接反序列化一下，把数据就可以从磁盘文件里\\n拿回来了。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"一行数据多个NULL字段值磁盘存储（以二进制bit位逆序来存储,存储的是允许NULL的字段）\\n如：“jack NULL m NULL xx_school”,0x09 0x04 0101 头信息 column1=value1 column2=value2 ... columnN=valueN；实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位\\n就高位补0，所以实际存放看起来是如下的：0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN\")])]),e._v(\" \"),n(\"p\",[e._v(\"首先分析变长字段长度列表和NULL值列表读取出来，就可以完美的把你一行数据的值都读取出来了\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"40bit位的数据头及真实数据如何存储\\n数据头是用来描述这行数据的，一、二位预留位无意义，三delete_mask这行数据是否被删除（MYSQL删数据非立即磁盘删，先数据头置1），四min_rec_mask，五-八n_owned，九-二一heap_no当前这行数据在记录堆里的位置，二二=二四record_type这行数据的类型（0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据），二五-四十next_record指向他下一条数据的指针。\")])]),e._v(\" \"),n(\"p\",[e._v(\"= 实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示\\n的：\\n0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262\\n会在他的真实数据部分，加入一些隐藏字段，这个隐藏字段跟后续的一些内容是有关联的，大家先了解一下。\\n首先有一个DB_ROW_ID字段，这就是一个行的唯一标识，是他数据库内部给你搞的一个标识，不是你的主键ID字段。如果我\\n们没有指定主键和unique key唯一索引的时候，他就内部自动加一个ROW_ID作为主键。\\n部资源禁止外传\\n接着是一个DB_TRX_ID字段，这是跟事务相关的，他是说这是哪个事务更新的数据，这是事务ID，这个后续我们讲解到事务的\\n时候会跟大家说的。\\n最后是DB_ROLL_PTR字段，这是回滚指针，是用来进行事务回滚的，也是我们后续在讲解事务的时候再详细说。\")]),e._v(\" \"),n(\"p\",[e._v(\"0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）\\n00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR） 616161 636320 6262626262\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"行数据磁盘物理存储-行溢出-一个数据页放不下-把数据溢出放到其他数据页\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#行数据磁盘物理存储-行溢出-一个数据页放不下-把数据溢出放到其他数据页\"}},[e._v(\"#\")]),e._v(\" 行数据磁盘物理存储，行溢出(一个数据页放不下，把数据溢出放到其他数据页)\")]),e._v(\" \"),n(\"p\",[e._v(\"每一行数据都是放在一个数据页里的，这个数据页默认的大小是16KB，那么之前就有人在后台提过一个问题：万一 一行数据的大小超过了页的大小怎么办呢？\")]),e._v(\" \"),n(\"p\",[e._v(\"如：实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含他一部分数据，同时包含一个20个字节的指针，\\n指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/yichu.PNG\",alt:\"yichu\"}})]),e._v(\" \"),n(\"p\",[e._v(\"数据页的物理存储结构，然后是表空间的物理存储结构，最后是讲解这些数据以物理存储结构的方\\n式，在磁盘上存储的时候，是放在哪些磁盘文件里\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"磁盘数据页\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#磁盘数据页\"}},[e._v(\"#\")]),e._v(\" 磁盘数据页\")]),e._v(\" \"),n(\"p\",[e._v(\"一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多\\n个数据行、空闲空间、数据页目录、文件尾部，默认有16kb的大小\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/datapage.PNG\",alt:\"datapage\"}})]),e._v(\" \"),n(\"p\",[e._v(\"文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是\\n不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"表空间-物理概念\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#表空间-物理概念\"}},[e._v(\"#\")]),e._v(\" 表空间（物理概念）\")]),e._v(\" \"),n(\"p\",[e._v(\"平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件\\n，一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个数\\n据区的概念，英文就是extent，一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一\\n组。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"当我们需要执行crud\\n操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。\")])]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/tablespace.PNG\",alt:\"tablespace\"}})]),e._v(\" \"),n(\"p\",[e._v(\"注：第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比\\n如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。\\nIBUF_BITMAP数据页，里面存放的是这一组数据页的所有insert buffer的一些信息。\\nINODE数据页，这里也是存放了一些特殊的信息。\")]),e._v(\" \"),n(\"p\",[e._v(\"表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"总上介绍了MYSQL存储模型以及数据读写机制\")])]),e._v(\" \"),n(\"p\",[e._v(\"数据行里都有很多附加的信息，在数据页、数据区里，都\\n有很多附加的特殊信息。各种各样的特殊信息，就可以让我们在简简单单的磁盘文件里实现B+树索引、事务之类的非常复杂的机制。\")]),e._v(\" \"),n(\"p\",[e._v(\"思考：假设此时我们要插入一条数据，那么是选择磁盘文件里的哪个数据页加载到缓存页里去呢？\")]),e._v(\" \"),n(\"p\",[e._v(\"根据表找到表空间，定位到磁盘文件，从里面找一个extent组，找一个\\nextent，接着从里面找一个数据页出来！这个数据也可能是空的，也可能已经放了一些数据行了！\\n然后就可以把这个数据页从磁盘里完整加载出来，放入Buffer Pool的缓存页里了！\")]),e._v(\" \"),n(\"p\",[e._v(\"从磁盘文件里读取一个数据页，是怎么读取的啊？\\n其实这个很简单了，你可以想一下，磁盘文件里放的数据都是紧挨在一起的，类似于下面的那种样子。\\n0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds\\n0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds\")]),e._v(\" \"),n(\"p\",[e._v(\"么在读取一个数据页的时候，你就可以通过随机读写的方式来了，举个例子，我们下面有一个伪代码，大家看看。\\n就是设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。\\ndataFile.setStartPosition(25347)\\ndataFile.setEndPosition(28890)\\ndataPage = dataFile.read()\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"日志顺序读写以及数据文件随机读写的原理\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#日志顺序读写以及数据文件随机读写的原理\"}},[e._v(\"#\")]),e._v(\" 日志顺序读写以及数据文件随机读写的原理\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL数据库和底层的操作系统之间的交互原理\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"MySQL在实际工作时候的两种数据读写机制\")]),e._v(\"：\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"一种是对redo log、binlog这种日志进行的磁盘顺序读写\")]),e._v(\" \"),n(\"li\",[e._v(\"一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写（主要关注的性能指标是IOPS(底层存储系统每秒可以执行多少次磁盘读写操作)和响应延迟（磁盘每个读写操作耗时））\")])]),e._v(\" \"),n(\"p\",[e._v(\"生产环境的MySQL数据库每隔一两个月性能就会出现急剧抖动的案例\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"linux操作系统的存储系统原理剖析以及io调度优化原理\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#linux操作系统的存储系统原理剖析以及io调度优化原理\"}},[e._v(\"#\")]),e._v(\" Linux操作系统的存储系统原理剖析以及IO调度优化原理.\")]),e._v(\" \"),n(\"p\",[e._v(\"之所以需要操作系统，是因为我们不可能直接去操作CPU、内存、磁盘这些硬件，所以必须要用操作系统来管理CPU、内存、磁盘、网卡这些硬件设备。\")]),e._v(\" \"),n(\"p\",[e._v(\"我们只要打开windows操作系统的电脑，就可以随意编辑文件，上网，聊天，使用各种软件，这些软件运行的时候本\\n质底层都是在使用计算机的CPU、内存、磁盘和网卡，比如基于CPU执行你的文件编辑的操作，基于内存缓冲你对文\\n件的编辑，基于磁盘存储你在文件里输入的内容，基于网卡去进行网络通信，让你进行QQ聊天什么的。\\n至于说linux操作系统，其实也是类似的，只不过一般我们用linux操作系统，他是不给我们提供可视化界面的，只有命\\n令行的界面，我们需要输入各种各样的命令去执行文件编辑、系统部署和运行，本质linux操作系统在底层其实也是利\\n用CPU、内存、磁盘和网卡这些硬件在工作。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层\")])]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/linux.PNG\",alt:\"linux\"}})]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"原理：当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。\\n文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读\\n写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO\\n请求，，会把这个Block IO请求交给IO调度层(默认CFQ公平调度算法，建议调整为deadline IO调度算法，这也是一个生产环境的IO调度优化经验。)，IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终\\nMySQL可以得到本次IO读写操作的结果。\")])]),e._v(\" \"),n(\"p\",[e._v(\"deadline IO调度算法：任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。（数据库发起了多个SQL语句同时在执行IO操作,公平算法的话耗时少的sql在后面执行的话会等待耗时久的sql）\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"案例-数据库服务器使用的raid存储架构-存储硬件层面原理\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#案例-数据库服务器使用的raid存储架构-存储硬件层面原理\"}},[e._v(\"#\")]),e._v(\" 案例：数据库服务器使用的RAID存储架构（存储硬件层面原理）\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL数据库软件都是安装在一台linux服务器上的，然后启动MySQL的进程，就是启动了一个MySQL数据库\\nMySQL运行过程中，他需要使用CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供\\n的接口，依托于操作系统来使用和运行的，然后linux操作系统负责操作底层的硬件。\")]),e._v(\" \"),n(\"p\",[e._v(\"关系：\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/server.PNG\",alt:\"server\"}})]),e._v(\" \"),n(\"p\",[e._v(\"很多数据库部署在机器上的时候，存储都是搭建的RAID存储架构(磁盘冗余阵列)，解决问题：磁盘容量不够，多加几块，RAID用来管理机器\\n里的多块磁盘的一种磁盘阵列技术，往磁盘里读写数据的时候，他会告诉你应该在哪块磁盘上读写数据，还能实现数据冗余机制（可写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块\\n磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"服务器RAID存储架构的电池充放电原理：多块磁盘组成的RAID阵列有一个RAID卡（带缓存非使用主内存）把RAID的缓存模式设置为write back，所有写入到磁盘阵列的数据，先会缓存在RAID卡的缓\\n存里，后续慢慢再写入到磁盘阵列里去\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"RAID卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然掉电\\n了，无法接通电源了，RAID卡自己是基于锂电池（定时充放电）来供电运行的，然后他会赶紧把缓存里的数据写入到阵列中的磁盘上\")])])]),e._v(\" \"),n(\"p\",[e._v(\"问题：每隔30天~90天自动对锂电池充放电延长锂电池的寿命和校准电池容量,若不定时充放电则可能电量不够一次性把缓存中数据写回到磁盘中去，充放电时RAID的缓存级别会从write back变成write through直接写入磁盘，出现几十倍性能抖动\\n案例： 数据库是部署在高配置服务器上的，磁盘就是用的RAID\\n10的阵列技术，用了6块磁盘组成了RAID 10磁盘阵列架构（每2块磁盘组成一个RAID 1互为镜像的架构，存放的数据是冗余一样的，一共有3组RAID 1），\")]),e._v(\" \"),n(\"p\",[e._v(\"优化：\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"RAID卡把锂电池换成电容，电容是不用频繁充放电的，电容可以支持透明充放电，就是自动检查电量\")]),e._v(\" \"),n(\"li\",[e._v(\"写脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本手动触发充放电\")]),e._v(\" \"),n(\"li\",[e._v(\"锂电池充放电的时候不要把缓存级别从write back修改为write through（可以和策略2配合使用）\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"案例-too-many-connections\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#案例-too-many-connections\"}},[e._v(\"#\")]),e._v(\" 案例：Too many connections\")]),e._v(\" \"),n(\"p\",[e._v(\"数据库的连接池里已经有太多的连接了，不能再跟你建立新的连接\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/connection.PNG\",alt:\"connection\"}})]),e._v(\" \"),n(\"p\",[e._v(\"show variables like 'max_connections'\")]),e._v(\" \"),n(\"p\",[e._v(\"底层的linux操作系统把进程可以打开的文件句柄数限制为了1024了，导致MySQL最大连接数是214！linux的话是默认会限制你每个进程对机器资\\n源的使用的，包括可以打开的文件句柄的限制，可以打开的子进程数的限制，网络缓存的限制，最大可以锁定的内存\\n大小。linux操作系统设计的初衷，就是要尽量避免你某个进程一下子耗尽机器上的所有资源，所以他默认都是会做限制的。linux限制你一个进程的文件句柄太少的话，那么就会导致我们没办法创建大量的网络连接。\")]),e._v(\" \"),n(\"p\",[e._v(\"在生产环境部署了一个系统，比如数据库系统、消息中间件系统、存储系统、缓存系统之后，都需要\\n调整一下linux的一些内核参数，这个文件句柄的数量是一定要调整的，通常都得设置为65535。比如Kafka之类的消息中间件，在生产环境部署的时候，如果你不优化一些linux内核参数，会导致Kafka可能无法\\n创建足够的线程，此时也是无法运行的。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"解决：ulimit -HSn 65535\")])]),e._v(\" \"),n(\"p\",[e._v(\"检查最大文件句柄数是否被修改了\\ncat /etc/security/limits.conf\")]),e._v(\" \"),n(\"p\",[e._v(\"cat /etc/rc.local\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"redo日志对于事务提交后-数据绝对不会丢失的意义\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#redo日志对于事务提交后-数据绝对不会丢失的意义\"}},[e._v(\"#\")]),e._v(\" redo日志对于事务提交后，数据绝对不会丢失的意义\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"日志是事务相关\")])]),e._v(\" \"),n(\"p\",[e._v(\"更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。\\nredo log本质是保证事务提交之后，修改的数据绝对不会丢失的。\")]),e._v(\" \"),n(\"p\",[e._v(\"更新缓存页的时候，会更新free链表、flush链表、lru链\\n表，然后有专门的后台IO线程，不定时的根据flush链表、lru链表，会把你更新过的缓存页刷新回磁盘文件的数据页里\\n去\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/data.PNG\",alt:\"data\"}})]),e._v(\" \"),n(\"p\",[e._v(\"这个机制里最大的漏洞就在于，万一你一个事务里有增删改SQL更新了缓存页，然后事务提交了，结果万一你还没来得\\n及让IO线程把缓存页刷新到磁盘文件里，此时MySQL宕机了，然后内存数据丢失，你事务更新的数据就丢失了！也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里去，\\n缓存页刷新到磁盘文件里，是随机磁盘读写，性能是相当的差，故需要引入redo log机制\")]),e._v(\" \"),n(\"p\",[e._v(\"redo log:MySQL重启之后，把你之前事务更新过做的修改根据redo log在Buffer Pool里重做一遍就可以了，就可以恢复\\n出来当时你事务对缓存页做的修改，然后找时机再把缓存页刷入磁盘文件里去。\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么要redo log日志：缓存页刷入磁盘是随机写磁盘，性能是很差的；redo log写日志，是顺序写入磁盘文件，每次都是追加到磁盘文件末尾去，速度也是很快的\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"redo log里本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了\\n几个字节的值，具体修改的值是什么，他里面需要记录的就是表空间号+数据页号+偏移量+修改几个字节的值+具体的值\")])]),e._v(\" \"),n(\"p\",[e._v(\"redo log看起来大致的结构如下所示：日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据\")]),e._v(\" \"),n(\"p\",[e._v(\"MLOG_1BYTE类型的日志指的就是修改了1个字节的值，以此类推，还有修改了4个字节的值的日\\n志类型，修改了8个字节的值的日志类型。如果你要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某\\n个偏移量的位置插入或者修改了一大串的值。\")]),e._v(\" \"),n(\"p\",[e._v(\"大致就是一条redo log中依次排列上述的一些东西，这条redo log表达的语义就很明确了，他的类型是什么，类型就\\n告诉了你他这次增删改操作修改了多少字节的数据；\\n然后在哪个表空间里操作的，这个就是跟你SQL在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里\\n执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些呢。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"redo log写入磁盘过程：非一条条redo log写入，MySQL内有另外一个数据结构，叫做redo log block（512字节）来存放多个单行日志的（类似数据与数据页）\")])]),e._v(\" \"),n(\"p\",[e._v(\"-redo log buffer里的redo log block\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/block.PNG\",alt:\"block\"}}),e._v(\"\\n12字节的header头又分为了4个部分。\\n部资源禁止外传\\n包括4个字节的block no，就是块唯一编号；\\n2个字节的data length，就是block里写入了多少字节数据；\\n2个字节的first record group。这个是说每个事务都会有多个redo log，是一个redo log group，即一组redo\\nlog。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的；\\n4个字节的checkpoint on\")]),e._v(\" \"),n(\"p\",[e._v(\"写文件的时候，可以按照字节，一个字节一个字节的写入的，文件里存放的东西\\n就是很多很多字节，依次排开，然后其中可能512个字节组合起来，就固定代表了一个redo log block。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/512block.PNG\",alt:\"512block\"}})]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认的值就是16MB，其实已经够大了，毕\\n竟一个redo log block才512自己而已，每一条redo log其实也就几个字节到几十个字节罢了。\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"其实在我们平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个redo\\nlog，这多个redo log就是一组redo log，其实每次一组redo log都是先在别的地方暂存，然后都执行完了，再把一组redo\\nlog给写入到redo log buffer的block里去的。一组redo log太多，放两个block,少则，多个redo log,放一个block\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"redo log buﬀer里的redo log block刷入磁盘的时机\")])])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"redo log buﬀer的日志已经占据了redo log buﬀer总容量的一半了，也就是超过了8MB的redo log在缓冲里\")]),e._v(\" \"),n(\"li\",[e._v(\"一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只\\n有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事\\n务做的修改（常见）\")]),e._v(\" \"),n(\"li\",[e._v(\"后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buﬀer里的redo log block刷到磁盘\\n文件里去\")]),e._v(\" \"),n(\"li\",[e._v(\"MySQL关闭的时候，redo log block都会刷入到磁盘里去\")])]),e._v(\" \"),n(\"p\",[e._v(\"注：但是不管怎么说，主要是保证一个事务执行的时候，redo log都进入redo log buﬀer，提交事务的时\\n候，事务对应的redo log必须是刷入磁盘文件，接着才算是事务提交成功，否则事务提交就是失败，保\\n证这一点，就能确保事务提交之后，数据不会丢，有redo log在磁盘里就行了。\\n当然，绝对保证数据不丢，还得配置一个参数，提交事务把redo log刷入磁盘文件的os cache之后，还\\n得强行从os cache刷入物理磁盘。\")]),e._v(\" \"),n(\"p\",[e._v(\"redo log是有多个的，写满了一个就会写下一个redo log，而且可以限制redo log文件的数量，通\\n过innodb_log_ﬁle_size可以指定每个redo log文件的大小，默认是48MB，通过\\ninnodb_log_ﬁles_in_group可以指定日志文件的数量，默认就2个。\\n所以默认情况下，目录里就两个日志文件，分别为ib_logﬁle0和ib_logﬁle1，每个48MB，最多就这2个\\n日志文件，就是先写第一个，写满了写第二个。那么如果第二个也写满了呢？别担心，继续写第一个，\\n覆盖第一个日志文件里原来的redo log就可以了。\")]),e._v(\" \"),n(\"p\",[e._v(\"![redolog](/img/mysql/redo log.PNG)\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"问题：redologbuffer到redolog日志宕机怎么办\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"undo-log回滚日志-事务执行到一半回滚\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#undo-log回滚日志-事务执行到一半回滚\"}},[e._v(\"#\")]),e._v(\" undo log回滚日志（事务执行到一半回滚）\")]),e._v(\" \"),n(\"p\",[e._v(\"事务操作执行一半回滚事务，引入undo log\")]),e._v(\" \"),n(\"p\",[e._v(\"写undo log时机：1加载数据页 2事务提交后?????事务开启还是\"),n(\"strong\",[e._v(\"事务修改时\")]),e._v(\"？\\n从版本链来看，事务开启后只需修改当前数据行就能形成undo log版本链\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/undoredo.PNG\",alt:\"unre\"}})]),e._v(\" \"),n(\"p\",[e._v(\"insert语句（TRX_UNDO_INSERT_REC）undo log日志结构(没有主键，MySQL设置row_id作为隐藏字段，做主键)：\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/undo.PNG\",alt:\"undo\"}})]),e._v(\" \"),n(\"h4\",{attrs:{id:\"多个事务同时执行-mysql内核原理的角度\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#多个事务同时执行-mysql内核原理的角度\"}},[e._v(\"#\")]),e._v(\" 多个事务同时执行（MySQL内核原理的角度）\")]),e._v(\" \"),n(\"p\",[e._v(\"通常而言，我们都是在业务系统里会开启事务来执行增删改操作的，业务系统是执行一个一个的事务，每个事务里可能是一个或者多个增删改查的SQL语句\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/transactional.PNG\",alt:\"transcational\"}})]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"问题：\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"多个事务并发执行的时候，可能会同时对缓存页里的一行数据进行更新，这个冲突怎么处理？是否\\n要加锁？(脏写、脏读、不可重复读、幻读)\")]),e._v(\" \"),n(\"li\",[e._v(\"可能有的事务在对一行数据做更新，有的事务在查询这行数据，这里的冲突怎么处理？\")])]),e._v(\" \"),n(\"p\",[e._v(\"涉及机制：解决多个事务并发运行的时候，同时写和同时读写的一些并\\n发冲突的处理机制，包括了MySQL事务的隔离级别、MVCC多版本隔离、锁机制（用于解决脏读，脏写，不可重复读，幻读）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"问题1：\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"多个事务同时更新一条数据（脏写），事务A先写不提交，事务B后写提交，事务A回滚。事务B看到的场景，就是自己明明更新了，结果值却没了，这就是脏写\")]),e._v(\" \"),n(\"li\",[e._v(\"事务A更新未提交，事务B读，事务A回滚（脏读），事务B读到脏数据。\")]),e._v(\" \"),n(\"li\",[e._v(\"事务A查数据1未提交，事务B更新数据1提交事务，事务A读取不到原来值（一行数据）（不重复读）\")]),e._v(\" \"),n(\"li\",[e._v(\"查询到了之前查询没看到过的数据（数据行数增多或减少）（幻读）\")])]),e._v(\" \"),n(\"p\",[e._v(\"注：脏读脏写前提是能读到未提交事务数据，不可重读前提是读取不到未提交事务的数据\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"事务隔离级别\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#事务隔离级别\"}},[e._v(\"#\")]),e._v(\" 事务隔离级别\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"read uncommitted（读未提交）,可读取到事务未提交时修改的值\")]),e._v(\" \"),n(\"li\",[e._v(\"read committed（读已提交），可读取到事务提交时修改的值\")]),e._v(\" \"),n(\"li\",[e._v(\"repeatable read（可重复读），自身事务开始后查询到值一直相同（默认）\")]),e._v(\" \"),n(\"li\",[e._v(\"serializable（串行化） ，多个事务串行，那数据库恨不能一秒并发就只有几十了，性能会极差的\")])]),e._v(\" \"),n(\"p\",[e._v(\"SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"MySQL如何支持隔离级别及Spring事务注解\")])]),e._v(\" \"),n(\"p\",[e._v(\"MySQL的RR级别的语义跟SQL标准的RR级别不同的，毕竟SQL标准里规定RR级别是可以发生幻读的，但是MySQL的RR级别避免了！\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL里执行的事务，默认情况下不会发生脏写、脏读、不可重复读和幻读的问题，总之，\"),n(\"strong\",[e._v(\"事务之间互相都完全不影响\")]),e._v(\"！\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"RR级别避免不可重复读和幻读(MySQL的MVCC机制(多版本并发控制隔离机制))\")])]),e._v(\" \"),n(\"p\",[e._v(\"@Transactional(isolation=Isolation.DEFAULT)，然后默认的就是DEFAULT值，这个就是MySQL默认支\\n持什么隔离级别就是什么隔离级别。spring的事务是对数据库的事务的封装,最后本质的实现还是在数据库\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mvcc-基于undo-log多版本链条-readview机制\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mvcc-基于undo-log多版本链条-readview机制\"}},[e._v(\"#\")]),e._v(\" MVCC（基于undo log多版本链条+ReadView机制）\")]),e._v(\" \"),n(\"p\",[e._v(\"默认的RR隔离级别，就是基于这套机制来实现的，依托这套机制实现了RR级别，除了避免脏写、脏读、不可重复\\n读，还能避免幻读问题。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"undo log多版本链条（事务开启只需要修改数据无需提交就能有undo log版本链???）\")])]),e._v(\" \"),n(\"p\",[e._v(\"每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer，这个trx_id就\\n是最近一次更新这条数据的事务id，roll_pointer就是指向你了你更新这个事务之前生成的undo log回滚日志\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/mvcc.PNG\",alt:\"mvcc\"}}),e._v(\"\\n先不管多个事务并发执行是如何执行的，起码先搞清楚一点，\\n就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段txr_id和roll_pointer，同时\\n之前多个数据快照对应的undo log，会通过roll_pinter指针串联起来，形成一个重要的版本链！\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"ReadView机制(基于undo log多版本链条实现)\\n执行一个事务的时候，就给你生成一个ReadView\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"一个是m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的；\")]),e._v(\" \"),n(\"li\",[e._v(\"一个是min_trx_id，就是m_ids里最小的值；\")]),e._v(\" \"),n(\"li\",[e._v(\"一个是max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id；（由mysql生成，如已有事务70，无论是否提交，max_trx_id都是71）\")]),e._v(\" \"),n(\"li\",[e._v(\"一个是creator_trx_id，就是你  这个事务的id\")])]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"生成readview时机\\nRC隔离级别：每次读取数据前，都生成一个readview；\\nRR隔离级别：在第一次读取数据前，生成一个readview；\")])]),e._v(\" \"),n(\"p\",[e._v(\"undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/readview.PNG\",alt:\"readview\"}})]),e._v(\" \"),n(\"p\",[e._v(\"多个事务并发执行的时候，事务B更新的值，通过这套\\nReadView+undo log日志链条的机制，就可以保证事务A不会读到并发执行的事务B更新的值，只会读\\n到之前最早的值。保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。\")]),e._v(\" \"),n(\"p\",[e._v(\"如事务A中readview中，判断当前数据undo log中数据行的\\ntxr_id小于readview中min_trx_id，事务A开启前，当前数据行已提交，事务A可操作此行数据，\\n事务B修改后，当前数据行已改变，\\n事务A再操作，txr_id大于readview中min_trx_id，小于max_trx_id，说明事务AB可能就同时开启，txr_id是否再事务AReadView的m_ids列表，如果有可是开启，事务A不能操作此数据行，需要找到txr_id小于readviewmin_trx_id的数据行，\\n若txr_id==事务readvie w中的creator_trx_id说明是当前事务修改的，\\ntxr_id大于事务readview中的creator_trx_id，说明事务A开启后有个事务更新了数据，自己不能看到，只能顺着版本链条看小于或等于的\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"rc隔离级别与rr隔离级别-基于readview机制实现\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#rc隔离级别与rr隔离级别-基于readview机制实现\"}},[e._v(\"#\")]),e._v(\" rc隔离级别与rr隔离级别（基于ReadView机制实现）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"生成readview时机\\nRC隔离级别：每次读取数据前，都生成一个readview；\\nRR隔离级别：在第一次读取数据前，生成一个readview；\")])]),e._v(\" \"),n(\"p\",[e._v(\"总结：\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"undo log中trx_id小于min_trx_id事务能查询\\n2.undo log中trx_id处于min_trx_id、max_trx_id之间，且ReadView的m_ids活跃事务列表中没有trx_id事务可查询\")])]),e._v(\" \"),n(\"p\",[e._v(\"当rc时，事务A每次读取用不同readview可能导致ims事务列表变化，读取不到原来同时开启的事务已提交的事务，情况2可以重复读\")]),e._v(\" \"),n(\"p\",[e._v(\"当RR时，readview不变，即使原来同时开启的事务已提交的事务，事务A中readview的Ims列表也不变，事务A还是读取不到已提交的事务B\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL的RR级别的语义跟SQL标准的RR级别不同的,RR隔离级别下也能避免幻读，也是readview机制\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"锁机制-解决的就是多个事务同时更新一行数据-此时必须要有一个加锁的机制\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#锁机制-解决的就是多个事务同时更新一行数据-此时必须要有一个加锁的机制\"}},[e._v(\"#\")]),e._v(\" 锁机制（解决的就是多个事务同时更新一行数据，此时必须要有一个加锁的机制）\")]),e._v(\" \"),n(\"p\",[e._v(\"在特定\\n\"),n(\"strong\",[e._v(\"脏读、不可重复读、幻读，都是别人在更新数据的时候，你怎么读的问题，基于undo log版本链条以及ReadView实现的mvcc机制（其他事务写，一个事务读的问题）\")]),e._v(\" \"),n(\"strong\",[e._v(\"脏写，锁机制（多个事务同时写）\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"一个事务来了要更新这行数据，这个时候他会先琢磨一下，看看这行数据此时有没有人加锁\")]),e._v(\" \"),n(\"li\",[e._v(\"数据没人加锁，事务就会创建一个锁，里面包含了自己的trx_id和等待状态，然后把锁跟这行数据关联在一起。\")]),e._v(\" \"),n(\"li\",[e._v(\"更新一行数据必须把他所在的数据页从磁盘文件里读取到缓存页里来才能更新的，所以说，此时这行数据和关联的锁数据结构，都是在内存里的\")]),e._v(\" \"),n(\"li\",[e._v(\"事务B要更新数据，也也会生成一个锁数据结构，里面有他的trx_id，还有自己的等待状态，再排队等待\")]),e._v(\" \"),n(\"li\",[e._v(\"事务A这个时候更新完了数据，就会把自己的锁给释放掉了。\"),n(\"strong\",[e._v(\"锁一旦释放了，他就会去找\")]),e._v(\"，此时还有没有别人也对这行数据加锁了呢？他会发现事务B也加锁了，事务B的锁里的等待状态修改为false，然后唤醒事务B继续执行，此时事务B就获\\n取到锁了\")])]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/synchronize1.PNG\",alt:\"synchronize1\"}}),e._v(\" \"),n(\"img\",{attrs:{src:\"/img/mysql/synchronize2.PNG\",alt:\"synchronize2\"}})]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"多个事务加什么锁\\nX锁，也就是Exclude独占锁，当有一个事务加了独占锁之后，此时其他事务再要更新这行数据，\\n都是要加独占锁的，但是只能生成独占锁在后面等待。\")])]),e._v(\" \"),n(\"p\",[e._v(\"默认情况下，有人在更新数据的时候，然后你要去读取这行数据，直接默认就是开启mvcc机制的。 读写不互斥，MySQL设计mvcc机制就是为了解决这个问题，避免频繁加锁互斥。\")]),e._v(\" \"),n(\"p\",[e._v(\"万一要是你在执行查询操作的时候，就是想要加锁呢，MySQL首先支持一种共享锁，就是S锁，这个共享锁的语法如下：select * from table\\nlock in share mode，你在一个查询语句后面加上lock in share mode，意思就是查询的时候对一行数\\n据加共享锁。如果此时有别的事务在更新这行数据，已经加了独占锁了，此时你的共享锁能加吗？\\n当然不行了，共享锁和独占锁是互斥的！此时你这个查询就只能等着了。\")]),e._v(\" \"),n(\"p\",[e._v(\"更新数据的时候必然加独占锁，独占锁和独占锁是互斥的，此时别\\n人不能更新；但是此时你要查询，默认是不加锁的，走mvcc机制读快照版本，但是你查询是可以手动\\n加共享锁的(少见)，共享锁和独占锁是互斥的，但是共享锁和共享锁是不互斥的，如下规律。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/synchronize.PNG\",alt:\"synchronize\"}})]),e._v(\" \"),n(\"p\",[e._v(\"不是太建议在数据库粒度去通过行锁实现复杂的业务锁机制，而\\n更加建议通过redis、zookeeper来用分布式锁实现复杂业务下的锁机制（如商城系统中的锁逻辑）\")]),e._v(\" \"),n(\"p\",[e._v(\"多个事务并发更新数据的时候，都是要在行级别加独占锁的，这就是行锁，独占锁都是互斥的，所以\\n不可能发生脏写问题，一个事务提交了才会释放自己的独占锁，唤醒下一个事务执行。此时去读取别的事务在更新的数据，有两种可能：\\n第一种可能是基于mvcc机制进行事务隔离，读取快照版本，这是比较常见的；\\n第二种可能是查询的同时基于特殊语法去加独占锁或者共享锁。\")]),e._v(\" \"),n(\"p\",[e._v(\"如果你查询的时候加独占锁，那么跟其他更新数据的事务加的独占锁都是互斥的；如果你查询的时候加\\n共享锁，那么跟其他查询加的共享锁是不互斥的，但是跟其他事务更新数据就加的独占锁是互斥的，跟\\n其他查询加的独占锁也是互斥的。\")]),e._v(\" \"),n(\"p\",[e._v(\"一个数据页在磁盘文件里就是一段数据，可能是二进制或者别的特殊格式的数据，然后数据页里包含两个指针，一个指针指向自己上一个数据页的物理地址，一个指针指向自己下一个数据页的物理地址\\n类似：DataPage: xx=xx, xx=xx, linked_list_pre_pointer=15367, linked_list_next_pointer=34126 ||\\nDataPage: xx=xx, xx=xx, linked_list_pre_pointer=23789, linked_list_next_pointer=46589 ||\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"没索引-数据库根据查询语句搜索数据\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#没索引-数据库根据查询语句搜索数据\"}},[e._v(\"#\")]),e._v(\" 没索引，数据库根据查询语句搜索数据\")]),e._v(\" \"),n(\"p\",[e._v(\"数据页之间是组成双向链表的，然后数据页内部的数据行是组成单向链表的，而且数据行是根据主键从小到大排序的。\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"主键：每个数据页里都会有一个页目录，里面根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的，所以实际上每个数据页的目录里，就是这个页里每个主键跟所在槽位的映射关系\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/pagemain.PNG\",alt:\"pagemain\"}})]),e._v(\" \"),n(\"li\",[e._v(\"非主键：根据数据页内部的单向链表来遍历查找， 再数据页的双向链表去找下一个数据页，然后读取到buﬀer pool的缓存页里，往复\")])]),e._v(\" \"),n(\"p\",[e._v(\"其实上述操作过程，就是全表扫描\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"不断向表中插入数据-物理存储如何页分裂-表里是如何出现一个又一个的数据页\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#不断向表中插入数据-物理存储如何页分裂-表里是如何出现一个又一个的数据页\"}},[e._v(\"#\")]),e._v(\" 不断向表中插入数据，物理存储如何页分裂（表里是如何出现一个又一个的数据页）\")]),e._v(\" \"),n(\"p\",[e._v(\"刚开始第一行是个起始行，他的行类型是2，就是最小的一行，然后他有一个指针指向了下一行数据，每一行数据都有自己每个字段的值，然后每一行通过一个指针不停的指向下一行数据，普通的数据行的类型都是0，最后一行是一个类型为3的，就是代表最大的一行。\")]),e._v(\" \"),n(\"p\",[e._v(\"索引运作的一个核心基础就是要求你后一个数据页的主键值都大于前面一个数据页的主键值，但是如果你的主键是自增的，那还可以保证这一点，因为你新插入后一个数据页的主键值一定都大于前一个数据页的主键值。\")]),e._v(\" \"),n(\"p\",[e._v(\"若第一数据页某条数据主键10，第二数据页某条数据主键8，有问题，需要出现一个页分裂，在增加一个新\\n的数据页的时候，实际上会把前一个数据页里主键值较大的，挪动到新的数据页里来，然后把你新插入\\n的主键值较小的数据挪动到上一个数据页里去，保证新数据页里的主键值一定都比上一个数据页里的主\\n键值大。\\n同时在页分裂的时候，会维护你的上层索引数据结构，在上层索引页里维护你的索引条目，不同的数据\\n页和最小主键值。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/pagesplit.PNG\",alt:\"pagesplit\"}})]),e._v(\" \"),n(\"p\",[e._v(\"这个聚簇索引默认是按照主键来组织的，所以你在增删改数据的时候，一方面会更新数据页，一方面其\\n实会给你自动维护B+树结构的聚簇索引，给新增和更新索引页，这个聚簇索引是默认就会给你建立的。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"基于主键索引设计及根据主键索引查询\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#基于主键索引设计及根据主键索引查询\"}},[e._v(\"#\")]),e._v(\" 基于主键索引设计及根据主键索引查询\")]),e._v(\" \"),n(\"p\",[e._v(\"阻止一些全表扫描情况发生\")]),e._v(\" \"),n(\"p\",[e._v(\"需要针对主键设计一个索引了，针对主键的索引实际上就是主键目录，这个主键目录\\n呢，就是把每个数据页的页号，还有数据页里最小的主键值放在一起，组成一个索引的目录\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue.PNG\",alt:\"indexcatalogue\"}})]),e._v(\" \"),n(\"p\",[e._v(\"假设数据页在磁盘文件里的位置也就是oﬀset偏移量，你也是可以知道的，此时就可以直接通\\n过随机读的方式定位到磁盘文件的某个oﬀset偏移量的位置，然后就可以读取连续的 一大坨数据页了！\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"索引-主键目录-的页物理存储结构-b-树实现\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引-主键目录-的页物理存储结构-b-树实现\"}},[e._v(\"#\")]),e._v(\" 索引（主键目录）的页物理存储结构（B+树实现）\")]),e._v(\" \"),n(\"p\",[e._v(\"表里的数据可能很多很多，比如有几百万，几千万，甚至单表几亿条数据都是\\n有可能的，所以此时你可能有大量的数据页，然后你的主键目录里就要存储大量的数据页和最小主键\\n值，这怎么行呢？（实际上是采取了一种把\"),n(\"strong\",[e._v(\"索引数据\")]),e._v(\"存储在数据页里的方式来做的，即表的索引也是放在页里的，即有很多索引页）\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"演化过程：\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[e._v(\"表里数据变多，通过索引将主键目录中的数据以索引的形式存储在索引页中\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue1.PNG\",alt:\"indexcatalogue1\"}})])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"通过索引页拆分，先定位数据所在索引页，再定位数据\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue2.PNG\",alt:\"indexcatalogue2\"}})])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"若底层索引存放下层索引页号太多，再次分裂\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue3.PNG\",alt:\"indexcatalogue3\"}})])])]),e._v(\" \"),n(\"p\",[e._v(\"最终变成一棵索引B+树，属于数据结构里的一种树形数据结构\")]),e._v(\" \"),n(\"p\",[e._v(\"以最简单最基础的主键索引来举例，当你为一个表的主键建立起来索引之后，其实这个主键的索\\n引就是一颗\"),n(\"strong\",[e._v(\"B+树\")]),e._v(\"，然后当你要根据主键来查数据的时候，直接就是从B+树的顶层开始二分查找，一层\\n一层往下定位，最终一直\"),n(\"strong\",[e._v(\"定位到一个数据页\")]),e._v(\"里，在\"),n(\"strong\",[e._v(\"数据页内部的目录\")]),e._v(\"里二分查找，找到那条数据。\\n这就是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是很多页组成的一\\n颗B+树。\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"这颗B+树里，最底层的一层就是数据页，数据页也就是B+树里的叶子节点\")]),e._v(\"\\n如果一颗大的B+树索引数据结构里，叶子节点就是数据页自己本身，那么此时我们就可以称这颗\\nB+树索引为聚簇索引\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"插入数据如何维护不同索引b-树\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#插入数据如何维护不同索引b-树\"}},[e._v(\"#\")]),e._v(\" 插入数据如何维护不同索引B+树\")]),e._v(\" \"),n(\"p\",[e._v(\"数据页越来越多，那么根页指向的索引页也会不停分裂，分裂出更多的索引\\n页，当你下层的索引页数量太多的时候，会导致你的根页指向的索引页太多了，此时根页继续分裂成多\\n个索引页，根页再次往上提上去去一个层级。\")]),e._v(\" \"),n(\"p\",[e._v(\"我们要根据其他字段的索引来搜索，那么只能基于其他字段的索引\\nB+树快速查找到那个值所对应的主键，接着再次做回表查询，基于主键在聚簇索引的B+树里，重新从\\n根节点开始查找那个主键值，找到主键值对应的完整数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"好处显而易见了，你可以直接根据某个字段的索引B+树来查找数据，不需要全表搜索，性能提升是很高\\n的。\\n但是坏处呢？索引当然有缺点了，主要是两个缺点，一个是空间上的，一个是时间上的。\\n空间上而言，你要是给很多字段创建很多的索引，那你必须会有很多棵索引B+树，每一棵B+树都要占\\n用很多的磁盘空间啊！所以你要是搞的索引太多了，是很耗费磁盘空间的。\\n其次，你要是搞了很多索引，那么你在进行增删改查的时候，每次都需要维护各个索引的数据有序性，\\n因为每个索引B+树都要求页内是按照值大小排序的，页之间也是有序的，下一个页的所有值必须大于上\\n一个页的所有值！\")]),e._v(\" \"),n(\"p\",[e._v(\"索引并非越多越好，一个表里搞的索引太多了，很可能就会导致你的增删改的速度就比较差了，也许查询速度确\\n实是可以提高，但是增删改就会受到影响，因此通常来说，我们是不建议一个表里搞的索引太多的！\")]),e._v(\" \"),n(\"p\",[e._v(\"二级索引如name字段的索引B+树，所\\n以在name字段的索引B+树里，叶子节点的数据页里仅仅放主键和name字段的值，至于排序规则之类\\n的，都是跟以前说的一样的\")]),e._v(\" \"),n(\"p\",[e._v(\"其实name字段的索引B+树里的索引页中，其实除了存放页号和最小name字段\\n值以外，每个索引页里还会存放那个最小name字段值对应的主键值\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/secondnode.PNG\",alt:\"secondnode\"}})]),e._v(\" \"),n(\"h4\",{attrs:{id:\"联合索引查询原理及全值匹配规则\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#联合索引查询原理及全值匹配规则\"}},[e._v(\"#\")]),e._v(\" 联合索引查询原理及全值匹配规则\")]),e._v(\" \"),n(\"p\",[e._v(\"一个表是存储学生成绩的，这个表当然有id了，这个id是一个自增主键，\\n默认就会基于他做一个聚簇索引，我们可以针对学生班级、学生姓名和科目名称建立一个联合索引。\\nselect * from student_score where class_name='1班' and student_name='张小强' and\\nsubject_name='数学'\")]),e._v(\" \"),n(\"p\",[e._v(\"索引页(多个数据页最小值记录)二分法找到对应数据页（指针），数据页内部本身也是一个单向链表也是二分法先按1班这个值来找，你会发现几条数据都是1班，此时就可以按照张小强这个\\n姓名来二分查找，此时会发现多条数据都是张小强，接着就按照科目名称数学来二分查找。，根据主键id回表查询，去聚簇索引中找到对应数据行返回。\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/conindex.PNG\",alt:\"conindex\"}})]),e._v(\" \"),n(\"h4\",{attrs:{id:\"常见索引使用规则\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#常见索引使用规则\"}},[e._v(\"#\")]),e._v(\" 常见索引使用规则\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"等值匹配规则，where语句中的几个字段名称和联合索引的字段完全一样，而且\\n都是基于等号的等值匹配，那百分百会用上我们的索引，即使你where语句里\\n写的字段的顺序和联合索引里的字段顺序不一致，也没关系，MySQL会自动优化为按联合索引的字段顺\\n序去找。\")]),e._v(\" \"),n(\"li\",[e._v(\"最左侧列匹配，只要根据\\n联合索引最左侧的部分字段来查就能走索引查询\")]),e._v(\" \"),n(\"li\",[e._v(\"最左前缀匹配原则，即如果你要用like语法来查，比如select * from student_score\\nwhere class_name like '1%'，查找所有1打头的班级的分数，那么也是可以用到索引的。\")]),e._v(\" \"),n(\"li\",[e._v(\"范围查找规则，如用select * from student_score where\\nclass_name>'1班' and class_name<'5班'这样的语句来范围查找某几个班级的分数。（索引的最下层的数据页都是按顺序组成双向链表的）\")]),e._v(\" \"),n(\"li\",[e._v(\"等值匹配+范围匹配的规则，如用select * from student_score where\\nclass_name='1班' and student_name>'' and subject_name<''，那么此时你首先可以用class_name在\\n索引里精准定位到一波数据，接着这波数据里的student_name都是按照顺序排列的，所以\\nstudent_name>''也会基于索引来查找，但是接下来的subject_name<''是不能用索引的。\")])]),e._v(\" \"),n(\"p\",[e._v(\"综上所述，一般我们如果写SQL语句，都是用联合索引的最左侧的多个字段来进行等值匹配+范围\\n搜索，或者是基于最左侧的部分字段来进行最左前缀模糊匹配，或者基于最左侧字段来进行范围搜索，\\n这就要写符合规则的SQL语句，才能用上我们建立好的联合索引！\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"sql排序如何用上索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#sql排序如何用上索引\"}},[e._v(\"#\")]),e._v(\" sql排序如何用上索引\")]),e._v(\" \"),n(\"p\",[e._v(\"问题：假设你有一个select * from table where xxx=xxx order by xxx这样\\n的一个SQL语句，似乎应该是基于where语句通过索引快速筛选出来一波数据，接着放到内存里，或者\\n放在一个临时磁盘文件里，然后通过排序算法按照某个字段走一个排序，最后把排序好的数据返回。万一你要排序的数据量比较大的话，还不能用内存来排序，如果基\\n于磁盘文件来排序，那在MySQL里有一个术语，叫做ﬁlesort，这速度就比较慢了。\")]),e._v(\" \"),n(\"p\",[e._v(\"在这种情况下，假设我们建立了一个INDEX(xx1,xx2,xx3)这样的一个联合索引，这个时\\n候默认情况下在索引树里本身就是依次按照xx1,xx2,xx3三个字段的值去排序的，那么此时你再运行\\nselect * from table order by xx1,xx2,xx3 limit 100这样的SQL语句，你觉得还需要在什么临时磁盘文\\n件里排序吗？\")]),e._v(\" \"),n(\"p\",[e._v(\"在你的SQL语句里，应该尽量最好是按照联合索引的字段顺序去进行order by排序，这样就可\\n以直接利用联合索引树里的数据有序性，到索引树里直接按照字段值的顺序去获取你需要的数据了。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"有一些限定规则，因为联合索引里的字段值在索引树里都是从小到大依次排列的 ，所以你在\\norder by里要不然就是每个字段后面什么都不加，直接就是order by xx1,xx2,xx3，要不然就都加DESC\\n降序排列，就是order by xx1 DESC,xx2 DESC,xx3 DESC。\")])]),e._v(\" \"),n(\"h4\",{attrs:{id:\"sql分组如何用上索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#sql分组如何用上索引\"}},[e._v(\"#\")]),e._v(\" sql分组如何用上索引\")]),e._v(\" \"),n(\"p\",[e._v(\"有时候我们会想要做一个group by把数据分组接着用count sum之类的聚合函数\\n做一个聚合统计。\")]),e._v(\" \"),n(\"p\",[e._v(\"问题：假设你要是走一个类似select count(*) from table group by xx的SQL语句，似乎看起来必须把你所\\n有的数据放到一个临时磁盘文件里还有加上部分内存，去搞一个分组，按照指定字段的值分成一组一组\\n的，接着对每一组都执行一个聚合函数，这个性能也是极差的，因为毕竟涉及大量的磁盘交互。\")]),e._v(\" \"),n(\"p\",[e._v(\"在我们的索引树里默认都是按照指定的一些字段都排序好的，其实字段值相同的数据都是在一起\\n的，假设要是走索引去执行分组后再聚合，那性能一定是比临时磁盘文件去执行好多了。\")]),e._v(\" \"),n(\"p\",[e._v(\"本质都是在group by和order by之后的字段顺序和联合索引中的从最左侧开始的字段顺序一致，然后就可以充分利用索引树\\n里已经完成排序的特性，快速的根据排序好的数据执行后续操作了。\")]),e._v(\" \"),n(\"p\",[e._v(\"毕竟只要你所有的查询语句都可以利用索引来执行，那么速度和性能通常都不会太慢。如果查询还是有\\n问题，那就要深度理解查询的执行计划和执行原理了，然后基于执行计划来进行深度SQL调优。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"回表查询-缺点-及覆盖索引\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#回表查询-缺点-及覆盖索引\"}},[e._v(\"#\")]),e._v(\" 回表查询（缺点）及覆盖索引\")]),e._v(\" \"),n(\"p\",[e._v(\"一般我们自己建的索引不管是单列索引还是联合索引，其实一个索引就对应着一颗独立的索引B+树\")]),e._v(\" \"),n(\"p\",[e._v(\"回表问题：有的时候MySQL的执行引擎甚至可能会认为，你要是类似select * from table order by xx1,xx2,xx3的\\n语句，相当于是得把联合索引和聚簇索引，两个索引的所有数据都扫描一遍了，那还不如就不走联合索\\n引了，直接全表扫描得了，这样还就扫描一个索引而已。\")]),e._v(\" \"),n(\"p\",[e._v(\"覆盖索引是一种基于索引查询的方式罢了。\\n针对类似select xx1,xx2,xx3 from table order by xx1,xx2,xx3这样的 语句，这种情况\\n下，你仅仅需要联合索引里的几个字段的值，那么其实就只要扫描联合索引的索引树就可以了，不需要\\n回表去聚簇索引里找其他字段了。\")]),e._v(\" \"),n(\"p\",[e._v(\"写sql时：\\n(1)你会用到联合索引，但是是否可能\\n会导致大量的回表到聚簇索引，如果需要回表到聚簇索引的次数太多了，可能就直接给你做成全表扫描\\n不走联合索引了；\\n(2)在SQL里指定你仅仅需要的几个字段，不要搞一个select *把所有字段都拿出来，\\n甚至最好是直接走覆盖索引的方式，不要去回表到聚簇索引。即使真的要回表到聚簇索引，那你也尽可能用limit、where之类的语句限定一下回表到聚簇索引的次\\n数，就从联合索引里筛选少数数据，然后再回表到聚簇索引里去，这样性能也会好一些\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"设计索引-考虑因素\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#设计索引-考虑因素\"}},[e._v(\"#\")]),e._v(\" 设计索引（考虑因素）\")]),e._v(\" \"),n(\"p\",[e._v(\"以一个电商平台的商品系统、交易系统以及营销系统的表结构设计以及索引设计作为案例背景，来告诉大家\\n在实际的系统设计中，应该如何设计表结构以及索引。\")]),e._v(\" \"),n(\"p\",[e._v(\"案例将会包含商品表、商品详情表、订单表、物流表、退款表、购物车表、营销活动表等多个表的设计\")]),e._v(\" \"),n(\"p\",[e._v(\"在电商场景下去学习表结构的设计，以及针对具体的业务场景如何设计索引\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"针对业务需求建立好一张表的结构之后，就知道这个表有哪些字段，每个字段是什么类型\\n的，会包含哪些数据\")]),e._v(\" \"),n(\"li\",[e._v(\"设计表的索引，这个设计索引的时候，我们要考虑第一\\n点，就是未来我们对表进行查询的时候，大概会如何来进行查询（刚设计完表结构如果不知道未来会怎么查询表可以先进行第三步）\")]),e._v(\" \"),n(\"li\",[e._v(\"可以进入系统开发的环节，也就是说根据需求文档逐步逐步的把你的Java业务代码给写好，\\n在写代码的过程中，现在一般我们都是用MyBatis作为数据持久层的框架的，你肯定会写很多的\\nMyBatis的DAO和Mapper以及SQL吧\")])]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"索引设计考虑因素\")]),e._v(\"：（1）索引设计原则就来了，针对你的SQL语句里的where条件、order by条件以及group by条件去设计索引\\n（设计一个或者两三个联合索引，每一个联合索引都尽量去包含上你的where、order by、\\ngroup by里的字段，接着你就要仔细审查每个SQL语句，是不是每个where、order by、group by后面\\n跟的字段顺序，都是某个联合索引的最左侧字段开始的部分字段；如你有一个联合索引是INDEX(a,b,c)，此时你一看发现有三个SQL，包含了where a=? and b=?，\\norder by a,b，group by a这些部分，那么此时where、order by、group by后续跟的字段都是联合索\\n引的最左侧开始的部分字段，这就可以了，说明你的每个SQL语句都会用上你的索引了）\")]),e._v(\" \"),n(\"p\",[e._v(\"（2）字段基数问题及前缀索引问题(一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出B+树快速二分查找的优势来。\\n字段的类型比较小的列来设计索引，比如说什么tinyint之类的，因为他的字\\n段类型比较小，说明这个字段自己本身的值占用磁盘空间小，此时你在搜索的时候性能也会比较好一点。\\n万一要是你真的有那种varchar(255)的字段，可能里面的值太大了，你觉得都放索引树里太\\n占据磁盘空间了，此时你仔细考虑了一下，发现完全可以换一种策略，也就是仅仅针对这个\\nvarchar(255)字段的前20个字符建立索引，就是说，对这个字段里的每个值的前20个字符放在索引树里\\n而已。)\\n（3）where function(a) = xx，索引里的字段a套了一个函数，无法使用索引\\n（4）设计索引别太多，建议两三个联合索引就应该覆盖掉表的全部查询。（插入数据有主键更新聚簇索引树，数据中包含索引各个字段值，联合索引B+树也要更新，不停的增删改数据，就会不停的更新你的索引）\\n（5)主键一直自增，别用UUID之类(聚簇索引不会频繁的分裂，主键值都是有序的，就会自然的新增一个页而已)\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"实际mysql索引设计\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#实际mysql索引设计\"}},[e._v(\"#\")]),e._v(\" 实际Mysql索引设计\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"社交APP索引设计\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"APP中的好友推荐，筛选的时候，是针对社交APP的哪个表进行查询\")])]),e._v(\" \"),n(\"p\",[e._v(\"用户信息表（大致会包含你的地区（你在哪个省份、哪个城市，这个很关键，否则不在一个城市，可能线上聊的好，\\n线下见面的机会都没有），性别，年龄，身高，体重，兴趣爱好，性格特点，还有照片，当然肯定还有\\n最近一次在线时间（否则半年都不上线APP了，你把他搜出来干什么呢？））\")]),e._v(\" \"),n(\"p\",[e._v(\"学习索引使用规则的时候，我们都知道，你在where条件里\\n必须是使用联合索引里最左侧开始的连续多个字段进行筛选，然后排序的时候也必须是用联合索引里的\\n最左侧开始的多个连续字段进行排序。\")]),e._v(\" \"),n(\"p\",[e._v(\"如SQL需要按照年龄进行范围筛选，同时需要按照用户的评分进行排序，类似下面\\n的SQL：select xx from user_info where age between 20 and 25 order by score，问题在类似这种SQL里，你的 \"),n(\"strong\",[e._v(\"where筛选和order by排序实际上大部分情况下是没法都用到索引的\")]),e._v(\" ，不能同时兼顾两者\")]),e._v(\" \"),n(\"p\",[e._v(\"若一个联合索引index(age,score)where条件可以用索引首选筛选，排序score无法走索引，若设计两个单独索引，在sql里假设基于age索引筛选，无法利用再利用score索引筛选。\")]),e._v(\" \"),n(\"p\",[e._v(\"问题本质是：让where语句先基于联合索引筛选，再将筛选数据加载到内存或临时磁盘文件进行指定条件的排序，最后用Limit语句拿到某页数据/////让order by语句按照你的索引顺序查找，找的过程基于where里条件筛选出来指定的数据，再根据limit语句拿出来一页数据\")]),e._v(\" \"),n(\"p\",[e._v(\"一般选用第一种，\"),n(\"strong\",[e._v(\"基于索引进行where筛选可以最快速度筛选出少部分数据\")]),e._v(\"，若数据量不大，后续排序和分页成本往往不会很大\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"2\"}},[n(\"li\",[e._v(\"针对where条件设计索引，用户在搜索潜在好友，一般用上哪些条件\\n首先应该在联合索引里包含省份、城市、性别，这三个字段！（潜在好友的需求分析）\")])]),e._v(\" \"),n(\"p\",[e._v(\"问题：按规则基数太低的字段最好别放到索引中，若给这三个字段单独建立联合索引，只能把这几个字段放在where条件的最后，\\n那么最后每次查询都必须要先用联合索引查询出来一部分数据，接着数据加载到内存里去，再根据\\nwhere条件最后的省份、城市和性别几个字段进行过滤筛选，每次查询都得多这么一个步骤。\")]),e._v(\" \"),n(\"p\",[e._v(\"推荐是是\"),n(\"strong\",[e._v(\"将需求必须的字段放在联合索引最左侧\")]),e._v(\"(即使字段基数小)，和其他字段组合联合索引后，大部分查询都可以直接同构索引数树就可以把where条件指定的数据筛选出来。\")]),e._v(\" \"),n(\"p\",[e._v(\"案例，我们已经分析到了可以把基数较低但是频繁查询（几\\n乎每次查询都会指定）的省份、城市和性别几个字段放到联合索引的最左侧去，此时就可以让每次查询\\n时指定的省份、城市和性别，都直接从索引树里进行筛选。\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"3\"}},[n(\"li\",[e._v(\"联合索引已经设计为了（province, city, sex），把省份、城市和性别三个几乎每次查询都会加的条件放入了联合索引的最左侧\")])]),e._v(\" \"),n(\"p\",[e._v(\"问题:（1）假设查询的时候，不指定性别，就指定了省份，城\\n市，还有加了一个年龄，也就是说where province=xx and city=xx and age between xx and xx，age不在联合索引中，无法通过age去在索引中筛选\")]),e._v(\" \"),n(\"p\",[e._v(\"若将索引设计成index（province, city, sex, age）,不符合最左侧连续多个字段的原则,但其实可以将sql语句变成where province=xx and city=xx and sex in\\n('female', 'male') and age >=xx and age<=xx，这样整个where语句里的条件全部都在索引树进行筛选和搜索\")]),e._v(\" \"),n(\"p\",[e._v(\"（2）假设我们在查询语句里还有一些频繁使用的条件，通常都是兴趣爱好和性格特点，这个兴趣爱好\\n和性格特点，往往都是有固定的一些枚举值的针对这样的一些频繁使用的包含枚举值范围的一些字段，也完全可以加入到联合索引里去，可以设\\n计成（province, city, sex, hobby, character, age）这样的一个联合索引，此时假设出现了这样一个查\\n询，按照省份、城市、性格和年龄进行搜索，此时SQL怎么写，还是用之前的那个策略和思路，就是写成where province=xx and city=xx and sex in(xx, xx) and\\nhobby in (xx, xx, xx, xx) and character=xx and age>=xx and age<=xx\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"即即使不需要按性别和爱好进行筛选，sql语句中可以对两个字段用in语句，将他们所有的枚举值放进去，让province，city，character和age四个真正要筛选的字段用上索引\")])]),e._v(\" \"),n(\"p\",[e._v(\"（3）age字段为什么一定在联合索引最后面\\n索引使用规则中，假设你where语句里有等值匹配，还有范围匹配，\\n此时必须是先让联合索引最左侧开始的多个字段使用等值匹配，接着最后一个字段是范围匹配\")]),e._v(\" \"),n(\"p\",[e._v(\"若在设计索引时将age放到中间，只有age及联合索引前面的字段能用上索引\")]),e._v(\" \"),n(\"p\",[e._v(\"总结：让最频繁查询的一些条件都放到索引里去，然后在查询的时候如果有些字段是不使\\n用的，可以用in (所有枚举值)的方式去写，这样可以让所有查询条件都用上你的索引，同时对范围查询\\n的age字段必须放在最后一个，这样保证范围查询也能用上索引\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"4\"}},[n(\"li\",[e._v(\"假设在查询的时候还有一个条件，是要根据用户最近登录时间在7天之内来进行筛选，筛选最近7天登录过APP的用户，那么实际上可能你的用户表里有这么一个字段，latest_login_time\")])]),e._v(\" \"),n(\"p\",[e._v(\"问题：（1）在where条件里加入这么一个latest_login_time <= 7天内语句，肯定这个是没法用上索引了。因为你这里必然会用一些计算或者是函数，才能进行一些时间的比对\")]),e._v(\" \"),n(\"p\",[e._v(\"索引设计成这样：（province, city, sex, hobby, character, age,\\nlatest_login_time），然后你的where语句写成这样：where xx xxx and age>=xx and age<=xxx and\\nlatest_login_time>=xx，虽然age和latest_login_time都在联合索引里，但是按照规则，只有age范围查\\n询可以用到索引，latest_login_time始终是用不到索引\")]),e._v(\" \"),n(\"p\",[e._v(\"技巧：设计表的时候，就必须考虑到这个问题，此时你完全可以设计\\n一个字段为：does_login_in_latest_7_days，也就是说，这个人是否在最近7天内登录过APP（将一个时间字段转换为一个枚举值的字段）\")]),e._v(\" \"),n(\"p\",[e._v(\"设计为（province, city, sex, hobby, character,does_login_in_latest_7_days, age），搜索时where条件带上character,does_login_in_latest_7_days=1\")]),e._v(\" \"),n(\"p\",[e._v(\"实际上一般来说，假设你要是where语句里通过上述联合索引就可以过滤掉大部分的数据，就保留小部\\n分数据下来基于磁盘文件进行order by语句的排序，最后基于limit进行分页，那么一般性能还是比较高\\n的。\")]),e._v(\" \"),n(\"p\",[e._v(\"（2）你要是就仅仅使用联合索引里一些基数特别小的字段来筛选，如基于性别来筛选，比如一下子筛选出所有的女性，可能有上百万用户数据，接着还要磁盘文件进\\n行排序再分页？那这个性能可能就会极为的差劲\")]),e._v(\" \"),n(\"p\",[e._v(\"可针对基数很低字段加上\"),n(\"strong\",[e._v(\"排序字段单独额外设计一个辅助索引\")]),e._v(\"，专门用\\n于解决where条件里都是基数低的字段，然后还要排序后分页的问题，比如说就可以设计一个联合索引为：（sex, score），\"),n(\"strong\",[e._v(\"低基数字段筛选+评分排序\")])]),e._v(\" \"),n(\"p\",[e._v(\"select xx from user_info where sex='female' order by score limit xx,xx,若使用上面多个联合索引无法走索引查询，使用辅助索引（sex, score）\")]),e._v(\" \"),n(\"p\",[e._v(\"先对where条件里的sex='female'在索引树里筛选到这部分数据，接\\n着在sex='female'的数据里，这些数据实际上都是排列在一起的，因为在索引里，会按照sex和score两\\n个字段去进行排序，所以sex='female'的数据都是在一块儿的。\\n然后找到这部分数据之后，接着就可以确定，这部分数据肯定是按照score字段进行排序的，此时就可\\n以按照score字段值的顺序，去读取你的limit语句指定的数据分页出来就可以了\")]),e._v(\" \"),n(\"p\",[e._v(\"针对sex低基数的字段的筛选和基于评分排序的语句，整体运行的效率是非常高的，完\\n全可以基于辅助索引来实现。\")]),e._v(\" \"),n(\"p\",[e._v(\"总结：以此类推，完全可以通过对查询场景的分析，用（province, city, sex, hobby, character,\\ndoes_login_in_latest_7_days, age）这样的联合索引去抗下复杂的where条件筛选的查询，此时走索\\n引筛选速度很快，筛选出的数据量较少，接着进行排序和limit分页。\")]),e._v(\" \"),n(\"p\",[e._v(\"同时针对一些低基数字段筛选+评分排序的查询场景，可以设计类似（sex, score）的辅助索引来应对，\\n让他快速定位到一大片低基数字段对应的数据，然后按照索引顺序去走limit语句获取指定分页的数据，\\n速度同样会很快。\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"核心重点就是，尽量利用一两个复杂的多字段联合索引，抗下你80%以上的 查询，然后用一两个辅助索引抗下剩余20%的非典型查询，保证你99%以上的查询都能充分利用索引，就能保证你的查询速度和性能\")])]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"MySQL的查询语句的执行计划分析以及SQL优化\")]),e._v(\"\\nSQL优化技巧中包含了我们之前讲的设计索引以及让SQL用上索引，但是SQL优化还有很多\\n其他的东西。\")]),e._v(\" \"),n(\"p\",[e._v(\"基础的以及日常的SQL优化就是设计好索引，让一般不太复杂的普通查询都用上索引，但是针\\n对复杂表结构和大数据量的上百行复杂SQL的优化，必须得建立在你先懂这个复杂SQL是怎么执行的\")]),e._v(\" \"),n(\"p\",[e._v(\"那么多的数据表，每个表都有一个聚簇索引，聚簇索引的叶子就是那个表的真实数据，同时每个表\\n还设计了一些二级索引，那么上百行的复杂SQL跑起来的时候到底是如何使用各个索引，如何读取数据\\n的？\")]),e._v(\" \"),n(\"p\",[e._v(\"SQL语句（不管是简单还是复杂），在实际的MySQL底层，针对磁盘上的大量数据表、聚簇索引和\\n二级索引，如何检索查询，如何筛选过滤，如何使用函数，如何进行排序，如何进行分组，到底怎么能\\n把你想要的东西查出来，这个过程就是一个很重要的东西：\"),n(\"strong\",[e._v(\"执行计划\")]),e._v(\"！\")]),e._v(\" \"),n(\"p\",[e._v(\"优化复杂sql流程：\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"每次你提交一个SQL给MySQL，他内核里的查询优化器，都会针对这个SQL语句的语义去生\\n成一个执行计划，这个执行计划就代表了，他会怎么查各个表，用哪些索引，如何做排序和分组，看懂\\n这个执行计划，你就学会了真正的SQL优化的一半了\")]),e._v(\" \"),n(\"li\",[e._v(\"看懂执行计划之后，还能根据他的实际情况去想各种办法改写你的SQL语句，改良你的索引设计，\\n进而优化SQL语句的执行计划，最终让SQL语句的性能得到提升，这个就是所谓的SQL调优\")])]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"单表查询查询（执行计划）\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"执行计划之数据访问方式\\n（1） const，那是什么？对，肯定是通过主键或者唯一索引的访问，速度超高。\")])]),e._v(\" \"),n(\"p\",[e._v(\"select * from table where id=x，或者select * from table where\\nname=x的语句，直接就可以通过聚簇索引或者二级索引+聚簇索引回源，轻松查到你要的数据，这种\\n根据索引直接可以快速查找数据的过程，在执行计划里称之为const，意思就是性能超高的常量级的。（二级索引必须是唯一索引才是属于const方式）\")]),e._v(\" \"),n(\"p\",[e._v(\"（2） ref, 普通的二级索引呢？就是个普通的KEY索引，这个时候如果你写一个select * from\\ntable where name=x的语句，name是个普通二级索引，不是唯一索引，那么此时这种查询速度也是很\\n快的，他在执行计划里叫做ref。\")]),e._v(\" \"),n(\"p\",[e._v(\"普通的二级索引呢？就是个普通的KEY索引，这个时候如果你写一个select * from\\ntable where name=x的语句，name是个普通二级索引，不是唯一索引，那么此时这种查询速度也是很\\n快的，他在执行计划里叫做ref(例外：如果name is null，即使name是主键或唯一索引，还是只能走ref方式，如果你是针对一个二级索引同时比较了一个值还有限定了IS NULL，类似于select *\\nfrom table where name=x and name IS NULL，那么此时在执行计划里就叫做\"),n(\"strong\",[e._v(\"ref_or_null\")]),e._v(\"，因为同时\\n有索引等值比较和NULL值查询)\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"ref是什么意思？对，就是用了普通的索引，或者用主键/唯一索引搞了一个IS NULL/ISNOT NULL。\")])]),e._v(\" \"),n(\"p\",[e._v(\"（3）SQL是select * from table where age>=x and age <=x，假设age就是一个普通索引，此时\\n就必然利用索引来进行范围筛选，一旦利用索引做了范围筛选，那么这种方式就是range\")]),e._v(\" \"),n(\"p\",[e._v(\"以上都是基于索引查询，一般问题不大，除非通过所以查出数据量太多，比如范围筛选，查出的数据量太多\")]),e._v(\" \"),n(\"p\",[e._v(\"（4）index,完整的字段联合索引是KEY(x1,x2,x3),selectx1,x2,x3 from table where x2=xxx，可以走索引，\\n针对这个SQL，会直接遍历KEY(x1,x2,x3)索引树的叶子节点的那些页，一个接一个的遍历，然\\n后找到 x2=xxx 的那个数据，就把里面的x1，x2，x3三个字段的值直接提取出来就可以了！\\n针对这种只要遍历二级索引就可以拿到你想要的数据，而不需要回源到聚簇索引的访问方式，就叫做index访问方式！\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"不通过索引树的根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描\")]),e._v(\"，这种速度还是比较慢的，大家尽量还是别出现这种情况。\")]),e._v(\" \"),n(\"p\",[e._v(\"5.all全表扫描，SQL语句：select * from table where x1=xx or x2>=xx，这个SQL语句要查一个表，用\\n了x1和x2两个字段\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"单表sql语句情况举例分析\")])]),e._v(\" \"),n(\"p\",[e._v(\"(1)sql语句联合索引中只有一个二级索引：select * from table where x1=xx or x2>=xx\\n万一要是你建的索引是两个呢？比如(x1,x3)，(x2,x4)，你建了两个联合索引，此时你这个SQL只能\\n选择其中一个索引去用，此时会选择哪个呢？这里MySQL负责生成执行计划的查询优化器，一般会选择\\n在索引里扫描行数比较少的那个条件。ref\\n（2）sql语句中多个字段是二级索引：select * from table where x1=xx and x2=xx，然后x1和x2两个字段分别都有一\\n个索引，查询优化器生成一个执行计划，执行计划里，就先对x1字段的索引树\\n进行查找，查出一波数据，接着对x2的索引树查出一波数据，然后对两波数据，按照主键值做一个交\\n集。接着回表到聚簇索引去查完整数据就可以了。\")]),e._v(\" \"),n(\"p\",[e._v(\"其实你只要记住，在执行SQL语句的时候，有可能是\\n会同时查多个索引树取个交集，再回表到聚簇索引的，这个可能性是有的。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[n(\"p\",[e._v(\"深入多表管理的sql语句如何执行（平时开发多是多表关联语句）\\nMySQL的多表关联查询SQL语句是如何执行的\")])]),e._v(\" \"),n(\"li\",[n(\"p\",[e._v(\"select * from t1,t2 where t1.x1=xxx and t1.x2=t2.x2 and t2.x3=xxx，针对两个表进行查询了，而且会把两个\\n表的数据给关联起来，没有限定什么多表连接条件，那么可能会搞出一个笛卡尔积的东西。\")])])]),e._v(\" \"),n(\"p\",[e._v(\"where t1.x1=xxx and t1.x2=t2.x2 and t2.x3=xxx，SQL执行的过程可能是这样的，首先根据t1.x1=xxx这个筛选条件，去t1表里查出来一批数据，\\n此时可能是const、ref，也可能是index或者all，都有可能，具体看你的索引如何建的，他会挑一种执\\n行计划访问方式。假设从t1表里按照t1.x1=xxx条件筛选出2条数据，接着对这两条数据，根据每条数据的x2字段的\\n值，以及t2.x3=xxx这个条件，去t2表里找x2字段值和x3字段值都匹配的数据\\n部资源仅限自己 www.pplsunny.t\")]),e._v(\" \"),n(\"p\",[e._v(\"此时就把t1表里x2字段为265的那个数据跟t2表里t2.x2=265和t2.x3=xxx的两条数据，关联起来，就可\\n以了，t1表里另外一条数据也是如法炮制而已，这就是多表关联最最基本的原理。\")]),e._v(\" \"),n(\"p\",[e._v(\"可能是\"),n(\"strong\",[e._v(\"先从一个表里查一波数据，这个表叫做“驱动表”，再根据这波数据去另外一个表里查一波数据进行关联，另外一个表叫做“被驱动表”\")])]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"假设我们有一个员工表，还有一个产品销售业绩表，员工表里包含了id（主键）、name（姓名）、\\ndepartment（部门），产品销售业绩表里包含了id（主键）、employee_id（员工id）、产品名称\\n（product_name）、销售业绩（saled_amount）。\")])]),e._v(\" \"),n(\"p\",[e._v(\"select e.name,e.department,ps.product_name,ps.saled_amount from employee e,product_saled\\npa where e.id=pa.employee_id，走\"),n(\"strong\",[e._v(\"内连接\")]),e._v(\"，原理是从员工表里走全表扫描，找出每个员工，然\\n后针对每个员工的id去业绩表里找 employee_id 跟员工id相等的数据，可能每个员工的id在业绩表里都\\n会找到多条数据，因为他可能有多个产品的销售业绩。\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"2\"}},[n(\"li\",[e._v(\"问题：员工表里有一个人是新员工，入职到现在一个单子都没开过，也就没有\\n任何的销售业绩，那么此时还是\"),n(\"strong\",[e._v(\"希望能够查出来这个员工的数据\")]),e._v(\"，只不过他的销售业绩那块可以给个\\nNULL就行了，表示他没任何业绩。\")])]),e._v(\" \"),n(\"p\",[e._v(\"需要用到外连接，SELECT\\ne.name,\\ne.department,\\nps.product_name,\\nps.saled_amount\\nFROM employee e LEFT OUTER JOIN product_saled pa\\nON e.id=pa.employee_id，可以查出王五的业绩为NULL\")]),e._v(\" \"),n(\"p\",[e._v(\"**最基础的关联执行原理：嵌套循环关联\")]),e._v(\" \"),n(\"p\",[e._v(\"两表查询：假设有两个表要一起执行关联，此时会先在一个驱动表里根据他的where筛选条件找出一波\\n数据，比如说找出10条数据吧，接着呢，就对这10条数据走一个循环，用每条数据都到另外一个被驱动表里去根据ON连接条件和\\nWHERE里的被驱动表筛选条件去查找数据，找出来的数据就进行关联。\\n依次类推，假设驱动表里找出来10条数据，那么就要\"),n(\"strong\",[e._v(\"到被驱动表里去查询10次\")])]),e._v(\" \"),n(\"p\",[e._v(\"三个表进行关联呢？那就更夸张了，你从表1里查出来10条数据，接着去表2里查10次，假\\n设每次都查出来3条数据，然后关联起来，此时你会得到一个30条数据的结果集，接着再用这批数据去\\n表3里去继续查询30次！\")]),e._v(\" \"),n(\"p\",[e._v(\"问题：（1）驱动表查出数据后，对每条数据循环一次去被驱动表查数据，被驱动表索引建立问题，不能每次都走全表扫描\\n（2）驱动表的索引问题，不能每次都走全表扫描\")]),e._v(\" \"),n(\"p\",[e._v(\"多表关联很慢可能就是上面两个问题，通常而言，\"),n(\"strong\",[e._v(\"针对多表查询的语句，我们要尽量给两个表都加上索引\")]),e._v(\"，索引要确保从驱动表里查询也是通过索引去查找，接着对被驱动表查询也通过索引去查找。如果能做到这一点，你的多表关联语\\n句性能就会很高！\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"msyql如何根据成本选择执行计划\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#msyql如何根据成本选择执行计划\"}},[e._v(\"#\")]),e._v(\" msyql如何根据成本选择执行计划\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL是如何对一个查询语句的多个执行\\n计划评估他的成本的？如何根据成本评估选择一个成本最低的执行计划，保证最佳的查询速度？当你能透彻理解了\\nexplain看SQL执行计划之后，那么任何SQL语句的调优都不在话下。\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL里的成本是什么意思，简单来说，跑一个SQL语句，一般成本是两块，首先是那\\n些数据如果在磁盘里，你要不要从磁盘里把数据读出来？这个从磁盘读数据到内存就是IO成本，而且\\nMySQL里都是一页一页读的，读一页的成本的约定为1.0。\\n然后呢，还有一个成本，那就是说你拿到数据之后，是不是要对数据做一些运算？比如验证他是否符合\\n搜索条件了，或者是搞一些排序分组之类的事，这些都是耗费CPU资源的，属于CPU成本，一般约定读\\n取和检测一条数据是否符合条件的成本是0.2.\")]),e._v(\" \"),n(\"p\",[e._v('（1）全表扫描成本计算成本：show table status like \"表名\"')]),e._v(\" \"),n(\"p\",[e._v(\"rows就是表里的记录数，data_length就是表的聚簇索引的字节数大小，此时用data_length除以1024\\n就是kb为单位的大小，然后再除以16kb（默认一页的大小），就是有多少页，此时知道数据页的数量\\n和rows记录数，就可以计算全表扫描的成本了。\\nIO成本就是：数据页数量 * 1.0 + 微调值，CPU成本就是：行记录数 * 0.2 + 微调值，他们俩相加，就是\\n一个总的成本值，比如你有数据页100个，记录数有2万条，此时总成本值大致就是100 + 4000 =\\n4100，在这个左右。\")]),e._v(\" \"),n(\"p\",[e._v(\"（2）走二级索引成本：在二级索引里根据条件查一波数据的IO成本，比如说name值在25~100，\\n一般一个范围区间就粗暴的认为等同于一个数据页，所以此时可能一般根据二级索引查询的时候，这个\\nIO成本都会预估的很小，可能就是1 * 1.0 = 1，或者是n * 1.0 = n，基本就是个位数这个级别。仅仅是通过IO读取了二级索引的数据页而已，二级索引数据页到内存里以后，还得根据搜索条件去拿出来一波数据，\\n比如估算可能会查到100条数据，此时从二级索引里查询数据的CPU成本就是100 * 0.2+ 微调值，总之就是20左右而已。\")]),e._v(\" \"),n(\"p\",[e._v(\"拿到100条数据之后，就得回表到聚簇索引里去查询完整数据，此时先估算回表到聚簇索引的IO\\n成本，这里比较粗暴的直接默认1条数据就得回表到聚簇索引查询一个数据页，所以100条数据就是100\\n个数据页的IO成本，也就是100 * 1.0 + 微调值，大致是100左右。\\n把上面的所有成本都加起来，就是1 + 20 + 100 + 20 = 141，这就是使用一个索引进行查询的成本的计\\n算方法，\")]),e._v(\" \"),n(\"p\",[e._v(\"所以一般就会针对全表扫描和各个索引的成本，都进行\\n估算，然后比较一下，选择一个成本最低的执行计划。\")]),e._v(\" \"),n(\"p\",[e._v(\"内连接用from后表作为主表，EXPLAIN select * from student a  join score b on b.s_id=a.s_id and b.s_score=80  and a.s_sex='男';\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/explain.PNG\",alt:\"explain\"}}),e._v(\"\\n外连接时左外连接需要查出左表的所有数据，故是type为ALL以左表做驱动表，右外连接以右表做驱动表，EXPLAIN select * from student a rigth join score b on b.s_id=a.s_id and b.s_score=80  and a.s_sex='男';\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/explain2.PNG\",alt:\"explain2\"}}),e._v(\"？？？？？？？？？？\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mysql如何基于各种规则优化执行计划\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql如何基于各种规则优化执行计划\"}},[e._v(\"#\")]),e._v(\" mysql如何基于各种规则优化执行计划\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL在执行一些相对较为复杂的SQL语句的时候对查询进行\"),n(\"strong\",[e._v(\"重写\")]),e._v(\"来优化具体的执行计划\")]),e._v(\" \"),n(\"p\",[e._v(\"如常量代换x = y and y = k and k = 3这样的SQL，都会给你优化成x = 3 and y = 3 and k = 3\")]),e._v(\" \"),n(\"p\",[e._v(\"如select * from t1 join t2 on t1.x1=t2.x1 and t1.id=1，把SQL替换为：\\nselect t1表中id=1的那行数据的各个字段的常量值, t2.* from t1 join t2 on t1表里x1字段的常量值=t2.x1\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"子查询是如何执行的及其执行计划如何优化\\n（1）select * from t1 where x1 = (select x1 from t2 where id=xxx)，sql执行时会被拆分为两个步骤：第一个步骤先执行子查询，也就\\n是：select x1 from t2 where id=xxx，直接根据主键定位出一条数据的x1字段的值。接着再执行select\")])]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"from t1 where x1=子查询的结果值，如果排序、分组聚合的时候，可能有的时候会直接用上索引，有的时候用不上索引就会基于内存\\n或者临时磁盘文件执行。\")])]),e._v(\" \"),n(\"p\",[e._v(\"（2）select * from t1 where x1 = (select x1 from t2 where t1.x2=t2.x2),子查询中表t1需要遍历自己的每一条数据取出x字段，去找出t2表某条数据x1字段值，再放到外层判断是否=t1表x1字段\")]),e._v(\" \"),n(\"p\",[e._v(\"（3）IN语句结合子查询的一个优化手段，select * from t1 where x1 in (select x2 from t2 where x3=xxx)\")]),e._v(\" \"),n(\"p\",[e._v(\"执行计划并不是子查询查一波结果，然后判断t1表哪些数据的x1值在这个结果集里。效率太低下。\")]),e._v(\" \"),n(\"p\",[e._v(\"执行计划会被优化为，先执行子查询，也就是select x2 from t2 where\\nx3=xxx这条SQL语句，把查出来的数据都写入一个临时表里，也可以叫做物化表，意思就是说，把这个\\n中间结果集进行物化。\")]),e._v(\" \"),n(\"p\",[e._v(\"这个物化表可能会基于memory存储引擎来通过内存存放，如果结果集太大，则可能采用普通的b+树聚\\n簇索引的方式放在磁盘里。但是无论如何，这个物化表都会建立索引，所以大家要清楚，\"),n(\"strong\",[e._v(\"这波中间结果数据写入物化表是有索引的。\")])]),e._v(\" \"),n(\"p\",[e._v(\"此时是不是全表扫描t1表，对每条数据的x1值都去物化表里根据索引快速查找一下\\n是否在这个物化表里？如果是的话，那么就符合条件了。\")]),e._v(\" \"),n(\"p\",[e._v(\"但是这里还有一个优化的点，那就是他可以反过来思考。\\n也就是说，假设t1表的数据量是10万条，而物化表的数据量只有500条，那么此时完全可以改成全表扫\\n描物化表，对每个数据值都到t1表里根据x1这个字段的索引进行查找，查找物化表的这个值是否在t1表\\n的x1索引树里，如果在的话，那么就符合条件了。\")]),e._v(\" \"),n(\"p\",[e._v(\"（4）semi join半连接，\\nselect * from t1 where x1 in (select x2 from t2 where x3=xxx)，此时其实可能会在底层把他转化为一个半连接，有点类似于下面的样子：\\nselect t1.* from t1 semi join t2 on t1.x1=t2.x2 and t2.x3=xxx\")]),e._v(\" \"),n(\"p\",[e._v(\"上面的semi join的语义，是和IN语句+子查询的语义完全一样的，他的意思就是说，\\n对于t1表而言，只要在t2表里有符合t1.x1=t2.x2和t2.x3=xxx两个条件的数据就可以了，就可以把t1表\\n的数据筛选出来了。\")]),e._v(\" \"),n(\"p\",[e._v(\"在互联网公司里，我们比较崇尚的是尽量写简单的SQL，复杂的逻\\n辑用Java系统来实现就可以了，SQL能单表查询就不要多表关联，能多表关联就尽量别写子查询，能写\\n几十行SQL就别写几百行的SQL，多考虑用Java代码在内存里实现一些数据就的复杂计算逻辑，而不是\\n都放SQL里做。\")]),e._v(\" \"),n(\"p\",[e._v(\"正式进入执行计划研究环节了，这是后续能搞定\\nSQL调优的最后一个难题攻关了，只要大家可以看明白各种SQL语句的执行计划以及真实SQL执行过程\\n中各个环节的耗时，找出SQL语句执行慢的原因，那么后续就可以针对性的进行SQL调优。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"深入explain命令-获取sql执行计划-】\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#深入explain命令-获取sql执行计划-】\"}},[e._v(\"#\")]),e._v(\" 深入explain命令（获取sql执行计划）】\")]),e._v(\" \"),n(\"p\",[e._v(\"如：explain select * from table\")]),e._v(\" \"),n(\"p\",[e._v(\"id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | ﬁltered |tables used |\\nExtra\\n|+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+|\\n1  | SIMPLE      | NULL  | NULL       | NULL | NULL          | NULL| NULL    | NULL| NULL | NULL    |    No\")]),e._v(\" \"),n(\"p\",[e._v(\"id执行计划唯一id（sql语句中有子查询则有2个id）\")]),e._v(\" \"),n(\"p\",[e._v(\"select_type执行计划对应的查询类型\")]),e._v(\" \"),n(\"p\",[e._v(\"partitions表分区\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"type\")]),e._v(\"，关键，针对当前这个表的访问方法，这个之前我们都讲过很多，比如说const、ref、\\nrange、index、all之类的，分别代表了使用聚簇索引、二级索引、全表扫描之类的访问方式。\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"possible_keys\")]),e._v(\"针对一个表进行查询的时候有哪些潜在可以使用的索引，这也很关键，他是跟type结合起来的，意思就是说你type确定访问方式了，那么到底\\n有哪些索引是可供选择，可以使用的呢，这都会放这里。\"),n(\"strong\",[e._v(\"key，就是在possible_keys里实际选择的那个\\n索引\")]),e._v(\"，而key_len就是索引的长度。\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"ref\")]),e._v(\"，当你的查询方式是索引等值匹配的时候，比如const、ref、\\neq_ref、ref_or_null这些方式的时候，此时执行计划的ref字段告诉你的就是：你跟索引列等值匹配的是\\n什么？是等值匹配一个常量值？还是等值匹配另外一个字段的值？rows，是预估通过索引或者别的方式访问这个表的时候，大概可能会读取多少条数据。ﬁltered，\\n就是经过搜索条件过滤之后的剩余数据的百分比。extra是一些额外的信息，不是太重要。\")]),e._v(\" \"),n(\"p\",[e._v(\"一般如果单表查询或者是多表连接查询，其实他们的select_type都是SIMPLE，\")]),e._v(\" \"),n(\"p\",[e._v(\"举例\\n（1）子查询EXPLAIN SELECT * FROM t1 WHERE x1 IN (SELECT x1 FROM t2) OR x3 = 'xxxx'\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |\\nﬁltered | Extra |\\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\\n| 1 | PRIMARY | t1 | NULL | ALL | index_x3 | NULL | NULL | NULL | 3457 | 100.00 |\\nUsing where |\\n| 2 | SUBQUERY | t2 | NULL | index | index_x1 | index_x1 | 507 | NULL | 4687 | 100.00\\n| Using index |\\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\\n两个id，其次，第一条执行计划里，select_type是PRIMARY，不是SIMPLE了，说明第一个执行计划的查询类型\\n是主查询的意思，对主查询而言，他有一个where条件是x3='xxx'，所以他的possible_keys里包含了\\nindex_x3，就是x3字段的索引，但是他的key实际是NULL，而且type是ALL，所以说他最后没选择用x3\\n字段的索引，而是选择了全表扫描\\n这是为什么呢？其实很简单，可能他通过成本分析发现，使用x3字段的索引扫描xxx这个值，几乎就跟\\n全表扫描差不多，可能x3这个字段的值几乎都是xxx，所以最后就选择还不如直接全表扫描呢。\\n接着第二条执行计划，他的select_type是SUBQUERY，也就是子查询，子查询针对的是t2这个表，当然\\n子查询本身就是一个全表查询，但是对主查询而言，会使用x1 in 这个筛选条件，他这里type是index，\\n说明使用了扫描index_x1这个x1字段的二级索引的方式，直接扫描x1字段的二级索引，来跟子查询的结\\n果集做比对。\\n（2）union语句,EXPLAIN SELECT * FROM t1 UNION SELECT * FROM t2\\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |ﬁltered | Extra |\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\\n| 1 | PRIMARY | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 3457 | 100.00 | NULL |\\nNULL |\\n| 2 | UNION | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 4687 | 100.00 | NULL| NULL\\n|\\n|UNION RESULT |<union1,2> | NULL | ALL | NULL | NULL | NULL | NULL | NULL |Using temporary |\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\")]),e._v(\" \"),n(\"p\",[e._v(\"第三条执行计划union字句默认的作用是把两个结果集合并起来还会进行去重，所\\n以第三条执行计划干的是个去重的活儿。\")]),e._v(\" \"),n(\"p\",[e._v(\"table是<union 1,2>，这就是一个临时表的表名，而且你看他的extra里，有一个using\\ntemporary，也就是使用临时表的意思，他就是把结果集放到临时表里进行去重的，就这么个意思。当\\n然，如果你用的是union all，那么就不会进行去重了。\")]),e._v(\" \"),n(\"p\",[e._v(\"（3）EXPLAIN SELECT * FROM t1 WHERE x1 IN (SELECT x1 FROM t2 WHERE x1 = 'xxx' UNION SELECT x1 FROM t1 WHERE x1 = 'xxx');\\n一个外层查询，还有一个内层子查询，子查询里还有两个SELECT语句进行union操作\\n+----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+------\\n--------------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |\\nﬁltered | Extra |\\n+----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+--------\\n------------------+\\n| 1 | PRIMARY | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 3467 | 100.00 |Using where |\\n| 2 | DEPENDENT SUBQUERY | t2 | NULL | ref | index_x1 | index_x1 | 899 | const | 59 |100.00 | Using where; Using index |\\n| 3 | DEPENDENT UNION | t1 | NULL | ref | index_x1 | index_x1 | 899 | const | 45 |100.00 | Using where; Using index |\\n| NULL | UNION RESULT | <union2,3> | NULL | ALL | NULL | NULL | NULL | NULL |NULL | NULL | Using temporary |\\n+----+--------------------+------------+------------+------+---------------+----------+---------+-------+------+----------+--------\\n------------------+\")]),e._v(\" \"),n(\"p\",[e._v(\"第一个执行计划一看就是针对t1表查询的那个外层循环，select_type就是PRIMARY，因为这里涉及到了子查询，所以外层查询的select_type一定是PRIMARY了。\\n第二个执行计划是子查询里针对t2表的那个查询语句，他的select_type是DEPENDENT\\nSUBQUERY，第三个执行计划是子查询里针对t1表的另外一个查询语句，select_type是DEPENDENT\\nUNION，因为第三个执行计划是在执行union后的查询，第四个执行计划的select_type是UNION\\nRESULT，因为在执行子查询里两个结果集的合并以及去重。\")]),e._v(\" \"),n(\"p\",[e._v(\"（4）EXPLAIN SELECT * FROM (SELECT x1, count(*) as cnt FROM t1 GROUP BY x1) AS _t1 where cnt >10;\\nFROM子句后跟了一个子查询，在子查询里是根据x1字段进行分组然后进\\n行count聚合操作，也就是统计出来x1这个字段每个值的个数，然后在外层则是针对这个内层查询的结\\n果集进行查询通过where条件来进行过滤\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |\\nﬁltered | Extra |\\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\\n| 1 | PRIMARY |  | NULL | ALL | NULL | NULL | NULL | NULL | 3468 | 33.33 | Usingwhere |\\n| 2 | DERIVED | t1 | NULL | index | index_x1 | index_x1 | 899 | NULL | 3568 | 100.00 |Using index |\\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\")]),e._v(\" \"),n(\"p\",[e._v(\"上面的执行计划里，我们其实应该先看第二条执行计划，他说的是子查询里的那个语句的执行计划，他\\n的select_type是derived，意思就是说，针对子查询执行后的结果集会物化为一个内部临时表，然后外\\n层查询是针对这个临时的物化表执行的。\\n大家可以看到，他这里执行分组聚合的时候，是使用的index_x1这个索引来进行的，type是index，意\\n思就是直接扫描偶了index_x1这个索引树的所有叶子节点，把x1相同值的个数都统计出来就可以了。\\n然后外层查询是第一个执行计划，select_type是PRIMARY，针对的table是，就是一个子查询结果集物\\n化形成的临时表，他是直接针对这个物化临时表进行了全表扫描根据where条件进行筛选的。\")]),e._v(\" \"),n(\"p\",[e._v(\"（5）EXPLAIN SELECT * FROM t1 INNER JOIN t2 ON t1.id = t2.id\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+-------------+-------+------------+--------+---------------+---------+---------+-----------------+------+----------+-------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |ﬁltered | Extra |\\n+----+-------------+-------+------------+--------+---------------+---------+---------+-----------------+------+----------+-------+\\n| 1 | SIMPLE | t1 | NULL | ALL | PRIMARY | NULL | NULL | NULL | 3467 | 100.00 |NULL |\\n| 1 | SIMPLE | t2 | NULL | eq_ref | PRIMARY | PRIMARY | 10 | test_db.t1.id | 1 |100.00 | NULL |\\n+----+-------------+-------+------------+--------+---------------+---------+---------+-----------------+------+----------+-------+\\n发现针对t1表是一个全表扫描，这个是必然的，因为关联的时候会先查询一\\n个驱动表，这里就是t1，他没什么where筛选条件，自然只能是全表扫描查出来所有的数据了。\\n接着针对t2表的查询type是eq_ref，而且使用了PRIMARY主键。这个意思就是说，\"),n(\"strong\",[e._v(\"针对t1表全表扫描获取到的每条数据，都会去t2表里基于主键进行等值匹配\")]),e._v(\"，此时会在t2表的聚簇索引里根据主键值进行快\\n速查找，所以在连接查询时，针对被驱动表如果基于主键进行等值匹配，那么他的查询方式就是eq_ref\\n了。\\n如果要是正常基于某个二级索引进行等值匹配的时候，type就会是ref，而如果基于二级索引查询的\\n时候允许值为null，那么查询方式就会是ref_or_null\\n另外之前讲过，有一些特殊场景下针对单表查询可能会基于多个索引提取数据后进行合并，此时查询方\\n式会是index_merge这种。\\n而查询方式是range的话就是基于二级索引进行范围查询，查询方式是index的时候是直接扫描二级索引\\n的叶子节点，也就是扫描二级索引里的每条数据，最后如果是all的话就是全表扫描，也就是对聚簇索引\\n的叶子节点扫描每条数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"explain select * from student a left join  score b on a.s_id=b.s_id where b.s_score=80 and a.s_id=2;\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/plan.PNG\",alt:\"plan\"}})]),e._v(\" \"),n(\"p\",[e._v(\"左右外连接与内连接都是上图结果？？\")]),e._v(\" \"),n(\"p\",[e._v(\"（6）除了extra字段以外的其他内容，最多就是告诉你针\\n对你SQL里的每个表是如何查询的，用了哪个索引，查出来了多少数据，但是很多时候，往往针对一个\\n表可不是那么简单的。\")]),e._v(\" \"),n(\"p\",[e._v(\"EXPLAIN SELECT x1 FROM t1 WHERE x1 = 'xxx'\\n+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows |\\nﬁltered | Extra |\\n+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+\\n| 1 | SIMPLE | t1 | NULL | ref | index_x1 | index_x1 | 456 | const | 25 | 100.00 | Using\\nindex |\\n+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+\")]),e._v(\" \"),n(\"p\",[e._v(\"看看extra的信息，是Using index，这是什么意思呢？其实就是说这次查询，仅仅涉及到\\n了一个二级索引，不需要回表，因为他仅仅是查出来了x1这个字段，直接从index_x1索引里查就行了。\")]),e._v(\" \"),n(\"p\",[e._v(\"SELECT * FROM t1 WHERE x1 > 'xxx' AND x1 LIKE '%xxx'\\n此时他会先在二级索引index_x1里查找，查找出来的结果还会额外的跟x1 LIKE '%xxx'条件做比对，如\\n果满足条件的才会被筛选出来，这种情况下，extra显示的是Using index condition。\")]),e._v(\" \"),n(\"p\",[e._v(\"EXPLAIN SELECT * FROM t1 INNER JOIN t2 ON t1.x2 = t2.x2\\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------\\n---------------------------+\\n| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | ﬁltered\\n| Extra |\\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------\\n---------------------------+\\n| 1 | SIMPLE | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 4578 | 100.00 | NULL |\\n| 1 | SIMPLE | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 3472 | 1.00 | Using\\nwhere; Using join buﬀer (Block Nested Loop) |\\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------\\n---------------------------+\\n若t1,t2x1字段都没索引，都是全表扫描，对每条数据的x2字段的值，跑到t2表里去查对\\n应的数据，进行关联。\\n所以每次都得对t2表全表扫描一下，根\\n据extra提示的Using where，就是根据t1表每条数据的x2字段的值去t2表查找对应的数据了，然后此时\\n会用join buﬀer技术，在内存里做一些特殊优化，减少t2表的全表扫描次数。\")]),e._v(\" \"),n(\"p\",[e._v(\"（7）filtered中的属性Using ﬁlesort，Using\\ntemporary，是没法直接根据有序的索引去找数据的，只能把所有数据写\\n入一个临时的磁盘文件，基于排序算法在磁盘文件里按照x2字段的值完成排序，然后再按照LIMIT 10的\\n要求取出来头10条数据。最后给大家讲一下，如果我们用group by、union、distinct之类的语法的时候，万一你要是没法直接利\\n用索引来进行分组聚合，那么他会直接基于临时表来完成，也会有大量的磁盘操作，性能其实也是极低\\n的。\\n如EXPLAIN SELECT * FROM t1 ORDER BY x2 LIMIT 10\")]),e._v(\" \"),n(\"p\",[e._v(\"EXPLAIN SELECT x2, COUNT(*) AS amount FROM t1 GROUP BY x2，没索引，这个SQL里只能对全表数据放到临时表里做大量的磁盘文件操作，然后才能完成对x2字段的不同的值去\\n分组，分组完了以后对不同x2值的分组去做聚合操作，这个过程也是相当的耗时的，性能是极低的。\")]),e._v(\" \"),n(\"p\",[e._v(\"在SQL调优的时候，核心就是分析执行计划里哪些地方出现了全表扫描，\\n或者扫描数据过大，尽可能通过合理优化索引保证执行计划每个步骤都可以基于索引执行，避免扫描过\\n多的数据。\")]),e._v(\" \"),n(\"h2\",{attrs:{id:\"实战\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#实战\"}},[e._v(\"#\")]),e._v(\" 实战\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"千万级别用户场景下的运营系统sql调优\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#千万级别用户场景下的运营系统sql调优\"}},[e._v(\"#\")]),e._v(\" 千万级别用户场景下的运营系统sql调优\")]),e._v(\" \"),n(\"p\",[e._v(\"背景：这是一个互联网公司的系统，这个互联网公司的用户量是比较大\\n的，有\"),n(\"strong\",[e._v(\"百万级日活用户\")]),e._v(\"的一个量级。在这个互联网公司里，有一个系统是专门通过各种条件筛选出大量的用户，接着对那些用户去推送一些\\n消息的。用户是日活百万级的，注册用户是千万级的，而且如果还没有\\n进行分库分表的话，那么这个数据库里的用户表可能就一张，单表里是上千万的用户数据，大概是这么一个情况。\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"对运营系统筛选用户的SQL做一个简化，SELECT id, name FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx)\")])]),e._v(\" \"),n(\"p\",[e._v(\"一般存储用户数据的表会分为两张表，一个表用来存储用户的核心数据，比如id、name、昵称、手机号之类的信息，也就是上面SQL语句里的users表\\n另外一个表可能会存储用户的一些拓展信息，比如说家庭住址、兴趣爱好、最近一次登录时间之类的，就是上面的users_extent_info表\")]),e._v(\" \"),n(\"p\",[e._v(\"先子查询查最近登录id，外层查询用in可能会查出很多数据，在运行这类sql通常会先跑一个count函数SELECT COUNT(id) FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE\\nlatest_login_time < xxxxx)\")]),e._v(\" \"),n(\"p\",[e._v(\"然后内存里做一个小批量多批次读取数据的操作，比如判断如果在1000条以内，那么就一下子读取出\\n来，如果超过1000条，可以通过LIMIT语句，每次就从这个结果集里查1000条数据，查1000条就做一\\n次批量PUSH，再查下一波1000条。\")]),e._v(\" \"),n(\"p\",[e._v(\"下面的执行计划是当时我们为了调优，在测试环境的单表2万条数据场景下跑\\n出来的执行计划，即使是5万条数据，当时这个SQL都跑了十多秒，所以足够复现当时的生产问题了，\")]),e._v(\" \"),n(\"p\",[e._v(\"+----+-------------+-------+------------+-------+---------------+----------+---------+------+\\n| id | select_type | table | type | key | rows | ﬁltered | Extra |\\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+\\n| 1 | SIMPLE |  | ALL | NULL | NULL | 100.00 | NULL |\\n| 1 | SIMPLE | users | ALL | NULL | 49651 | 10.00 | Using where; Using join buﬀer(Block NestedLoop) |\\n| 2 | MATERIALIZED | users_extent_info | range | idx_login_time | 4561 | 100.00 | NULL |\\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+\")]),e._v(\" \"),n(\"p\",[e._v(\"执行计划第三行，针对users_extent_info表使用idx_login_time这个索引，做了range类型的索引范围扫描，查出来了4561条数据没有做其他的额外\\n筛选，所以ﬁltered是100%。MATERIALIZED使用临时物化表将4561条数据放到磁盘中，这个过程很慢，需要优化。\")]),e._v(\" \"),n(\"p\",[e._v(\"执行计划第二行针对users表做了一个全表扫描，扫出49651条数据，Extra字段用了Using join buﬀer，此处在执行join操作\")]),e._v(\" \"),n(\"p\",[e._v(\"执行计划第一行针对子查询的临时物化表做全表扫描\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么要对临时表全表扫描，让users表的每一条数据，都要去跟物化临时表里的数据进行join\")]),e._v(\" \"),n(\"p\",[e._v(\"不同MySQL版本执行计划可能是不一样的，甚至差别很大重点是看明白我们这里对这个SQL语句的执\\n行计划过程的一个分析。\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么这条sql会慢，首先他对子查询的结果做了一次物\\n化临时表，落地磁盘了，接着他还全表扫描了users表的所有数据，每一条数据居然跑到一个没有索引\\n的物化临时表里再做一次全表扫描找匹配数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"为什么会出现上述的一个全表扫描users表，然后跟物化临时表做join，join\\n的时候还要全表扫描物化临时表的过程，执行完上述SQL的EXPLAIN命令执行show warnings命令\\n/* select#1 */ select count( d2. users . user_id \"),n(\"code\",[e._v(\") AS COUNT(users.user_id)\")]),e._v(\"\\nfrom d2 . users users semi join xxxxxx，semi join这个关键字，\"),n(\"strong\",[e._v(\"生成执行计划的时候，自动就把一个普通的IN子句，“优化”成了基于semi join来进行IN+子查询的操作\")]),e._v(\"，\\n不需要把users表里的数据真的跟物化临时表里的数据join上。只要users表里的一条数据，在物\\n化临时表里可以找到匹配的数据，那么users表里的数据就会返回，这就叫做semi join，他是用来筛选的。\\n执行SET optimizer_switch='semijoin=oﬀ'，也就是关闭掉半连接优化，再执行explain命令，执行计划会改变，\\n\"),n(\"strong\",[e._v(\"有一个SUBQUERY的子查询，基于range方式去扫描索引搜索出4561条数据，接着有一个PRIMARY类型的主查询，直接是基于id这个PRIMARY主键聚簇索引去执行的搜索，然后再把这个SQL语句真实跑一下看看，发现性能一下子提升了几十倍，变成了100多毫秒！\")])]),e._v(\" \"),n(\"p\",[e._v(\"sql变慢的原因是mysql自动执行的semi join半连接优化,一旦禁止掉semi join自动优化，用正常的方式让他基于索引去执行，性能那是嗖嗖的。\")]),e._v(\" \"),n(\"p\",[e._v(\"在生产环境是不能随意更改这些设置的，所以后来我们想了一个办法，多种办法尝试去修改SQL\\n语句的写法，在不影响他语义的情况下，尽可能的去改变SQL语句的结构和格式，最终被我们尝试出了\\n一个写法，如下所示：\\nSELECT COUNT(id)\\nFROM users\\nWHERE ( id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time < xxxxx) OR id IN\\n(SELECT user_id FROM users_extent_info WHERE latest_login_time < -1))\")]),e._v(\" \"),n(\"p\",[e._v(\"在上述写法下，WHERE语句的OR后面的第二个条件，根本是不可能成立的，因为没有数据的\\nlatest_login_time是小于-1的，所以那是不会影响SQL语义的，但是我们发现改变了SQL的写法之后，\\n执行计划也随之改变。他并没有再进行semi join优化了，而是正常的用了子查询，主查询也是基于索引去执行的，这样我们在\\n线上上线了这个SQL语句，性能从几十秒一下子就变成几百毫秒了。\")]),e._v(\" \"),n(\"p\",[e._v(\"核心的，还是看懂SQL的执行计划，然后去分\\n析到底他为什么会那么慢，接着你就是要想办法避免他全表扫描之类的操作，一定要让他去用索引，用\\n索引是王道，是最重要的！\")]),e._v(\" \"),n(\"ol\",{attrs:{start:\"2\"}},[n(\"li\",[e._v(\"亿级数据量商品系统的SQL调优\\n问题：MySQL数据库在选择索引的时候，选择了一个不太合适的索引，导致了性能极差，引发了慢查询。\")])]),e._v(\" \"),n(\"p\",[e._v(\"场景：当时线上的商品系统出现的一个慢查询告警开始讲起，某一天晚上，我们突然收到了线上数据库的\\n频繁报警，这个报警的意思大致就是说，数据库突然涌现出了大量的慢查询，而且因为大量的慢查询，\\n导致每一个数据库连接执行一个慢查询都要耗费很久。必然会导致突然过来的很多查询需要让数据库开辟出来更多的连接，因此这个时候报警也\\n告诉我们，数据库的连接突然也暴增了，而且每个连接都打满，每个连接都要执行一个慢查询，慢查询还跑的特别慢。数据库的连接全部打满，没法开辟新的连接了，没法处理新的查询，很多查询发到数据库直接就阻塞超时了。\")]),e._v(\" \"),n(\"p\",[e._v(\"一个电商网站比较繁忙的时候，虽说商品数据是有多级缓存架构的，但是实际上在下单等过程中，还是会大量的请求商品系统的，\"),n(\"strong\",[e._v(\"所以晚高峰的时候，商品系统本身TPS大致是在每秒几千的。\")])]),e._v(\" \"),n(\"p\",[e._v(\"发现数据库的监控里显示，每分钟的慢查询超过了10w+！！！也就是说商品系统大量的查询都变成了慢查询！！！\")]),e._v(\" \"),n(\"p\",[e._v(\"慢查询都是什么语句，主要是下面这条语句，select * from products where category='xx' and sub_category='xx' order by id desc limit xx,xx\")]),e._v(\" \"),n(\"p\",[e._v(\"就是用户在电商网站上根据商品的品类以及子类在进行筛选，当然真实的SQL语句里，可能还包含其他的一些字段的筛选，比如什么品牌以及销售属性之类的，我们这里是做了一个简化，然后按id倒序排序，最后是分页，就这么一个语句。\")]),e._v(\" \"),n(\"p\",[e._v(\"这个语句执行的商品表里大致是1亿左右的数据量，这个量级已经稳定了很长时间了，主要也就是这么多商品，但是上面的那个语句居然一执行就是几十秒！一个连接要执行几十秒的SQL，数据库已是报废。\\n商品系统本身也大量的报警说查询数据库超时异常了！\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"需要耗时几十秒，结果导致了数据库的连接资源全部打满，商品系统无法运行，处于崩溃状态。\")])]),e._v(\" \"),n(\"p\",[e._v(\"KEY index_category(catetory,sub_category)，有索引为什么还会出现慢查询\")]),e._v(\" \"),n(\"p\",[e._v(\"一旦用上了品类的那个索引，那么按品类和子类去在索引里筛选，其实第一，筛选很快速，第二，筛出来的数据是不多的，按说这个语句应该执行的速度是很快的，即使表有亿级数据，但是执行时间也最多不应该超过1s。\")]),e._v(\" \"),n(\"p\",[e._v(\"这个sql跑了几十秒，说明他肯定没用我们建立的索引，看其执行计划\")]),e._v(\" \"),n(\"p\",[e._v(\"他的possible_keys里是有我们的index_category的，结果实际用的key不是这个索引，而\\n是PRIMARY！！而且Extra里清晰写了Using where,性能差原因本质上就是在主键的聚簇索引上进行扫描，一边扫描，一边还用了where条件里的两个字段去进行筛选，所以这么扫描的话，那必然就是会耗费几十秒了！\")]),e._v(\" \"),n(\"p\",[e._v(\"使用force index语法：select * from products force index(index_category) where category='xx' and sub_category='xx' order by id desc limit xx,xx，使用上述语法过后，强制让SQL语句使用了你指定的索引，此时再次执行这个SQL语句，会发现他仅仅耗费100多毫秒而已！\")]),e._v(\" \"),n(\"p\",[e._v(\"实战技巧，就是你如何去强制改变MySQL的执行计划，面试官问我，如果MySQL使用了错误的执行计划，应该怎么办？\")]),e._v(\" \"),n(\"p\",[e._v(\"还有其他问题：\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"为什么在这个案例中MySQL默认会选择对主键的聚簇索引进行扫描？\")]),e._v(\" \"),n(\"li\",[e._v(\"为什么没使用index_category这个二级索引进行扫描？\")]),e._v(\" \"),n(\"li\",[e._v(\"即使用了聚簇索引，为什么这个SQL以前没有问题，现在突然就有问题了？\")])]),e._v(\" \"),n(\"p\",[e._v(\"select * from products where category='xx' and sub_category='xx' order by id desc limit xx,xx。为什么要对聚簇索引进行扫描呢\\n对于MySQL来说，他有这么一个判断，他觉得如果要是从index_category二级索引里来查找到\\n符合where条件的一波数据，接着还得回表，回到聚簇索引里去。\")]),e._v(\" \"),n(\"p\",[e._v(\"但是在回表之前，他必然要做完order by id desc limit xx,xx这个操作，这个表是一个亿级数据量的大表，那么\\n对于他来说，index_category这个二级索引也是比较大的，比如从二级索引里假设搂出来了几万条数据，接着因为二级索引里是包含主键id值的，所以此时他就得\\n按照order by id desc这个排序语法，对这几万条数据基于临时磁盘文件进行ﬁlesort磁盘排序，排序完\\n了之后，再按照limit xx,xx语法，把指定位置的几条数据拿出来，假设就是limit 0,10，那么就是把10条\\n数据拿出来。再回到聚簇索引里去根据id查找，把这10条数据的完整字段都查出来，这就是\\nMySQL认为如果你使用index_category的话，可能会发生的一个情况。MYSQL担心从index_category二级索引里\\n查出来的数据太多了，还得在临时磁盘里排序，可能性能会很差，因此MySQL就把这种方式判定为一种\\n不太好的方式。\")]),e._v(\" \"),n(\"p\",[e._v(\"因此他才会选择换一种方式，也就是说，直接扫描主键的聚簇索引，因为聚簇索引都是按照id值有序\\n的，所以扫描的时候，直接按order by id desc这个倒序顺序扫描过去就可以了，然后因为他知道你是\\nlimit 0,10的，也就知道你仅仅只要拿到10条数据就行了。\")]),e._v(\" \"),n(\"p\",[e._v(\"他在按顺序扫描聚簇索引的时候，就会对每一条数据都采用Using where的方式，跟where\\ncategory='xx' and sub_category='xx'条件进行比对，符合条件的就直接放入结果集里去，最多就是放\\n10条数据进去就可以返回了。\\n此时MySQL认为，按顺序扫描聚簇索引，拿到10条符合where条件的数据，应该速度是很快的，很可能\\n比使用index_category二级索引那个方案更快，因此此时他就采用了扫描聚簇索引的这种方式！\")]),e._v(\" \"),n(\"p\",[e._v(\"问题：之前在线上系统而言，即使采用扫描聚簇索引的方案，其实这个SQL语句也确实一般都\\n运行不慢，最起码是不会超过1s的。\")]),e._v(\" \"),n(\"p\",[e._v(\"其实就是因为之前的时候，where category='xx' and sub_category='xx'这个条件通常\\n都是有返回值的，就是说根据条件里的取值，扫描聚簇索引的时候，通常都是很快就能找到符合条件的\\n值以及返回的，所以之前其实性能也没什么问题。后来可能是商品系统里的运营人员，在商品管理的时候加了几种商品分类和子类，但是这几种分类\\n和子类的组合其实没有对应的商品\")]),e._v(\" \"),n(\"p\",[e._v(\"那一天晚上，很多用户使用这种分类和子类去筛选商品，where category='新分类' and\\nsub_category='新子类'这个条件实际上是查不到任何数据的！底层在扫描聚簇索引的时候，扫来扫去都扫不到符合where条件的结果，一下子就把聚簇索引\\n全部扫了一遍，等于是上亿数据全表扫描了一遍，都没找到符合where category='新分类' and\\nsub_category='新子类'这个条件的数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"正是因为如此，才导致这个SQL语句频繁的出现几十秒的慢查询，进而导致MySQL连接资源打满，商\\n品系统崩溃！\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"数十亿数量级评论系统sql调优\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数十亿数量级评论系统sql调优\"}},[e._v(\"#\")]),e._v(\" 数十亿数量级评论系统sql调优\")]),e._v(\" \"),n(\"p\",[e._v(\"电商场景下非常普遍的商品评论系统的一个SQL\\n优化，这个商品评论系统的数据量非常大，拥有多达十亿量级的评论数据，所以当时对这个评论数据\\n库，我们是做了分库分表的，\"),n(\"strong\",[e._v(\"基本上分完库和表过后，单表的评论数据在百万级别。\")])]),e._v(\" \"),n(\"p\",[e._v(\"每一个商品的所有评论都是放在一个库的一张表里的，这样可以确保你作为用户在分页查询一个商品的\\n评论时，一般都是直接从一个库的一张表里执行分页查询语句就可以了\")]),e._v(\" \"),n(\"p\",[e._v(\"在电商网站里，有一些热门的商品，可能销量多达上百万，商品的评论可能多达几十万\\n条。所以这个时候，就会涉及到一个问题，针对一个商品几十万评论的深分页问题。\")]),e._v(\" \"),n(\"p\",[e._v(\"SELECT * FROM comments WHERE product_id ='xx' and is_good_comment='1' ORDER BY id desc\\nLIMIT 100000,20，要看第5001页评论，那么此时limit的oﬀset就会是(5001 - 1) * 20\")]),e._v(\" \"),n(\"p\",[e._v(\"评论表呢，最核心的索引就是一个，那就是index_product_id，所以对上述SQL语句，正常情况\\n下，肯定是会走这个索引的\")]),e._v(\" \"),n(\"p\",[e._v(\"对这个商品的每一条评论，都要进行一次回表操作，回到聚簇索引里，根据id二级索引找到那条数\\n据，取出来is_good_comment字段的值，接着对is_good_comment='1'条件做一个比对，筛选符合条\\n件的数据。假设这个商品的评论有几十万条，岂不是要做几十万次回表操作？虽然每次回表都是根据id在聚簇\\n索引里快速查找的，但还是架不住你每条数据都回表啊！！\")]),e._v(\" \"),n(\"p\",[e._v(\"有几十万次回表查询，还有十多万条数据的磁盘文件排序，所以当时发现，这条SQL语\\n句基本要跑个1秒~2秒。\")]),e._v(\" \"),n(\"p\",[e._v(\"第二个案例中基于商品品类去查商品表，是尽量避免对聚簇索引进行扫描，因为有可能找不到你指定的品类下的商品，出\\n现聚簇索引全表扫描的问题。\")]),e._v(\" \"),n(\"p\",[e._v(\"优化：SELECT * from comments a,\\n(SELECT id FROM comments WHERE product_id ='xx' and is_good_comment='1' ORDER BY id\\ndesc LIMIT 100000,20) b WHERE a.id=b.id\\n上面那个SQL语句的执行计划就会彻底改变他的执行方式，他通常会先执行括号里的子查询，子查询反\\n而会使用PRIMARY聚簇索引，按照聚簇索引的id值的倒序方向进行扫描，扫描过程中就把符合WHERE\\nproduct_id ='xx' and is_good_comment='1'条件的数据给筛选出来。\\n比如这里就筛选出了十万多条的数据，并不需要把符合条件的数据都找到，因为limit后跟的是\\n100000,20，理论上，只要有100000+20条符合条件的数据，而且是按照id有序的，此时就可以执行根\\n据limit 100000,20提取到5001页的这20条数据了。\")]),e._v(\" \"),n(\"p\",[e._v(\"针对我们的这个场景，反而是优化成这种方式来执行分页，他会更加合适一些，他只有一个扫描聚\\n簇索引筛选符合你分页所有数据的成本，你的分页深度越深，扫描数据越多，分页深度越浅，那扫描数\\n据就越少，然后再做一页20条数据的20次回表查询就可以了。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"千万级数据删除导致的慢查询优化\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#千万级数据删除导致的慢查询优化\"}},[e._v(\"#\")]),e._v(\" 千万级数据删除导致的慢查询优化\")]),e._v(\" \"),n(\"p\",[e._v(\"背景：当时有人删除了千万级的数据，结果导致了频繁的慢查询，当时是从线上收到大量的慢查询告警开始的，当我们收到大量的慢查询告警之后，就\\n去检查慢查询的SQL，结果发现不是什么特别的SQL，这些SQL语句主要都是针对一个表的，同时也比\\n较简单，而且基本都是单行查询，看起来似乎不应该会慢查询。\")]),e._v(\" \"),n(\"p\",[e._v(\"发现他在后台跑了一个定时任务，定时清理数据，结果清理的时候一下子清理了上千万的数据。开了一个事务，然后在一个事务里删除上千万数据，导致这个事务一直\\n在运行,长事务的运行会导致一个问题，那就是你删除的时候仅仅只是对数据加了一个删除标记，\\n事实上并没有彻底删除掉。此时你如果跟长事务同时运行的其他事务里在查询，他在查询的时候是可能\\n会把那上千万被标记为删除的数据都扫描一遍的。Read View机制,版本链条\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"永远不要在业务高峰期去运行那种删除大量数据的语句，因\\n为这可能导致一些正常的SQL都变慢查询，因为那些SQL也许会不断扫描你标记为删除的大量数据，好\\n不容易扫描到一批数据，结果发现是标记为删除的，于是继续扫描下去，导致了慢查询！\")])]),e._v(\" \"),n(\"p\",[e._v(\"直接kill那个正在删除千万级数据的长事务，所有SQL很快会恢复正常，\\n从此以后，对于大量数据清理全部放在凌晨去执行，那个时候就没什么人使用系统了，所以查询也很\\n少。\")]),e._v(\" \"),n(\"p\",[e._v(\"实际上个别特殊情况下，MySQL出现慢查询并不是SQL语句的问题，而是他自己\\n生产服务器的负载太高了，导致SQL语句执行很慢。如：MySQL服务器的磁盘IO负载特别高，也就是每秒执行大量的高负载的随机\\nIO，但是磁盘本身每秒能执行的随机IO是有限的。导致正常的SQL语句去磁盘上执行的时候，如果要跑一些随机IO，磁盘太繁忙了，本来快sql需要等待很久。\")]),e._v(\" \"),n(\"p\",[e._v(\"或网络负载很高，sql语句发送到mysql上，光等待跟mysql连接就很久或带宽打满，sql执行快，网络返回慢。或cpu负载高，去执行别的没时间执行sql。\")]),e._v(\" \"),n(\"p\",[e._v(\"慢查询本身不一定是SQL导致的，如果你觉得SQL不应该慢查询，结果他那个时间段跑这个SQL\\n就是慢，\"),n(\"strong\",[e._v(\"此时你应该排查一下当时MySQL服务器的负载，尤其看看磁盘、网络以及CPU的负载，是否正常\")])]),e._v(\" \"),n(\"p\",[e._v(\"如当某个离线作业瞬间大批量把数据往MySQL里灌入的时候，他一瞬间服务器磁盘、网络以及CPU的负载会超高。\")]),e._v(\" \"),n(\"p\",[e._v(\"今天我们先站在当时的角度，给大家分析我们的头两步排查手段，\"),n(\"strong\",[e._v(\"一个是检查SQL是否有问题，主要就是看他的执行计划，另外一个是检查MySQL服务器的负载，用MySQLproﬁlling工具去细致的分析SQL语句的执行过程和耗时。\")])]),e._v(\" \"),n(\"p\",[e._v(\"SQL调优的利器了，也就是proﬁling工具，这个工具可以对SQL语句的执行耗时进行非常深入和细致的分析\")]),e._v(\" \"),n(\"p\",[e._v(\"首先要打开这个proﬁling，使用set proﬁling=1这个命令，接着MySQL就会自动记录查询语句的proﬁling信息了。此时如果执行show proﬁles命令，就会给你列出各种查询语句的proﬁling信息，这里很关键的一点，就\\n是他会记录下来每个查询语句的query id，所以你要针对你需要分析的query找到对他的query id，我们当时就是针对慢查询的那个SQL语句找到了query id。然后就可以针对单个查询语句，看一下他的proﬁling具体信息，使用show proﬁle cpu, block io for\\nquery xx，这里的xx是数字，此时就可以看到具体的proﬁle信息了除了cpu以及block io以外，你还可以指定去看这个SQL语句执行时候的其他各项负载和耗时，具体使用方法，大家自行网上搜索就行了，并不难。\")]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mysql的主从架构-为什么要搭建主从\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql的主从架构-为什么要搭建主从\"}},[e._v(\"#\")]),e._v(\" MYSQL的主从架构(为什么要搭建主从)\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL真正的生产环境中，他一定不是一个\\n单机版的架构，因为单机版的MySQL一般仅能用于本地开发环境和测试环境，是绝对不可能运用于生产\\n环境的。\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL在生产环境中，必须要搭建一套\\n主从复制的架构，同时可以基于一些工具实现高可用架构\\n另外如果有需求，还需要基于一些中间件实现读写分离架构，最后就是如果数据量很大，还必须可以实现分库分表的架构。\")]),e._v(\" \"),n(\"p\",[e._v(\"主从复制架构，顾名思义，就是部署两台\\n服务器，每台服务器上都得有一个MySQL，其中一个MySQL是master（主节点），另外一个MySQL是\\nslave（从节点）。\")]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/master.PNG\",alt:\"master\"}})]),e._v(\" \"),n(\"p\",[e._v(\"主从架构意义\")]),e._v(\" \"),n(\"ol\",[n(\"li\",[e._v(\"高可用，MySQL就单机部署，一旦宕机，数据库完蛋，Java业务系统也完蛋。高可用架构怎么做呢？他的一个先决条件就是主从复制架构。你必须得让主节点可以复制数据到从\\n节点，保证主从数据是一致的，主节点宕机，Java业务系统连接到从节点去执行sql语句，写入数据和查询数据，因为主从数据是一致的，自然就实现了高可用\")])]),e._v(\" \"),n(\"p\",[e._v(\"问题：数据一致性，自动切换从节点提供服务\\n2.读写分离，Java业务系统可以往主节点写入数据，但是从从节点去查询数据，把读\\n写操作做一个分离，分离到两台MySQL服务器上去，一台服务器专门让你写入数据，然后复制数据到从节点，另外一台服务器专门让你查询数据，\")]),e._v(\" \"),n(\"p\",[e._v(\"搭建起来读写分离架构，就可以让每秒2500写请\\n求落到主节点那台服务器，2500读请求落到从节点那台服务器，用2台服务器来抗下你每秒5000的读写\\n请求，大部分Java业务系统都是读多写少，ySQL的主从复制架构，是支持一主多从的，所以此时你可以再在一台服务器上部署一个从\\n节点，去从主节点复制数据过来，此时你就有2个从节点了，可以抗住更多请求\\n\"),n(\"img\",{attrs:{src:\"/img/mysql/slave.PNG\",alt:\"slave\"}})]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"其实一般在项目中，高可用架构是必须做的，但是读写分离架构并不是必须的，因为对于大多数公\\n司来说，读请求QPS并没那么高，远远达不到每秒几千那么夸张，但是高可用你是必须得做的，因为你\\n必须保证主库宕机后，有另外一个从库可以接管提供服务，避免Java业务系统中断运行。\")])]),e._v(\" \"),n(\"p\",[e._v(\"从库其实还有很多其他的应用场景，比如你可以挂一个从库，专门用来跑一些报表SQL\\n语句，那种SQL语句往往是上百行之多，运行要好几秒，所以可以专门给他一个从库来跑。也可以是专\\n门部署一个从库，让你去进行数据同步之类的操作。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"Mysql实现主从复制原理：MySQL自己在执行增删改的时候会记录binlog日志，从库上有一个IO线程，这个IO线程会负责跟主库建立一个TCP连接，接着请求主库传输binlog日志\\n给自己，这个时候主库上有一个IO dump线程，就会负责通过这个TCP连接把binlog日志传输给从库的IO线程从库的IO线程会把读取到的binlog日志数据写入到自己本地的relay日志文件中去，然后从库上另外\\n有一个SQL线程会读取relay日志里的内容，进行日志重做，把所有在主库执行过的增删改操作，在从库\\n上做一遍，达到一个还原数据的过程\")])]),e._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:\"/img/mysql/relay.PNG\",alt:\"relay\"}})]),e._v(\" \"),n(\"h4\",{attrs:{id:\"mysql搭建主从架构流程\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql搭建主从架构流程\"}},[e._v(\"#\")]),e._v(\" Mysql搭建主从架构流程\")]),e._v(\" \"),n(\"p\",[e._v(\"大致来说，就是主库接受增删改操作，把增删改操作binlog写入本地文件，然后从库发送请求\\n来拉取binlog，接着在从库上重新执行一遍binlog的操作，就可以还原出一样的数据了。\")]),e._v(\" \"),n(\"p\",[e._v(\"搭建的时候肯定是需要两台机器的，一台机器放主库，一台机器放从库，至于主库和从库如何安装\\n和启动？这个就不在我们讲的范围了，随便网上一搜就大把的MySQL安装步骤，我们这里就讲解搭建主\\n从复制架构要做的一些配置。\")]),e._v(\" \"),n(\"p\",[e._v(\"方法（1）： 首先在主库上要创建一个用于主从复制的账号：\\ncreate user 'backup_user'@'192.168.31.%' identiﬁed by 'backup_123';\\ngrant replication slave on . to 'backup_user'@'192.168.31.%';\\nﬂush privileges;\")]),e._v(\" \"),n(\"p\",[e._v(\"假设你主库都跑了一段时间了，现在要挂一个从库，那从库总不能把你主库从\\n0开始的所有binlog都拉一遍吧！这是不对的，此时你就应该在凌晨的时候，在公司里直接让系统对外\\n不可用，说是维护状态，然后对主库和从库做一个数据备份和导入。\")]),e._v(\" \"),n(\"p\",[e._v(\"可以使用如下的mysqldump工具把主库在这个时刻的数据做一个全量备份，但是此时一定是不能允许\\n系统操作主库了，主库的数据此时是不能有变动的。\\n/usr/local/mysql/bin/mysqldump --single-transaction -uroot -proot --master-data=2 -A >backup.sql\")]),e._v(\" \"),n(\"p\",[e._v(\"mysqldump工具就在你的MySQL安装目录的bin目录下，然后用上述命令就可以对你主库所有的\\n数据都做一个备份，备份会以SQL语句的方式进入指定的backup.sql文件，只要执行这个backup.sql文\\n件，就可以恢复出来跟主库一样的数据。\")]),e._v(\" \"),n(\"p\",[e._v(\"上面命令里的--master-data=2，意思就是说备份SQL文件里，要记录一下此时主库的binlog文件和\\nposition号，这是为主从复制做准备的。\")]),e._v(\" \"),n(\"p\",[e._v(\"接着操作步骤转移到从库上去执行，在从库上执行如下命令，把backup.sql文件里的语句都执行一遍，\\n这就相当于把主库所有的数据都还原到从库上去了，主库上的所有database、table以及数据，在从库\\n里全部都有了。\")]),e._v(\" \"),n(\"p\",[e._v(\"接着在从库上执行下面的命令去指定从主库进行复制。\\nCHANGE MASTER TO MASTER_HOST='192.168.31.229',\\nMASTER_USER='backup_user',MASTER_PASSWORD='backup_123',MASTER_LOG_FILE='mysql-\\nbin.000015',MASTER_LOG_POS=1689;\")]),e._v(\" \"),n(\"p\",[e._v(\"接着就可以在主库插入一条数据，然后在从库查询这条数据，只要能够在从库查到这条数据，就说明主\\n从复制已经成功了。\\n这仅仅是最简单的一种主从复制，就是异步复制，就是之前讲过的那种原理，从库是异步拉取binlog来\\n同步的，所以肯定会出现短暂的主从不一致的问题的，比如你在主库刚插入数据，结果在从库立马查\\n询，可能是查不到的。\")]),e._v(\" \"),n(\"p\",[e._v(\"方法（2）：可以用mycat或者sharding-sphere之类的中间件，就可以实现你的系统写入主库，从从库去读取\\n了。\")]),e._v(\" \"),n(\"p\",[e._v(\"现在搭建出来的主从复制架构有一个问题，那就是之前那种搭建方式他默认是一种异步的复制方\\n式，也就是说，主库把日志写入binlog文件，接着自己就提交事务返回了，他也不管从库到底收到日志\\n没有。\")]),e._v(\" \"),n(\"p\",[e._v(\"一般来说搭建主从复制，都是采取半同步的复制方式的，这个半同步的意思，就是说，你主库写入\\n数据，日志进入binlog之后，起码得确保 binlog日志复制到从库了，你再告诉客户端说本次写入事务成\\n本了是不是？\\n这样起码你主库突然崩了，他之前写入成功的数据的binlog日志都是到从库了，从库切换为主库，数据\\n也不会丢的，这就是所谓的半同步的意思。\")]),e._v(\" \"),n(\"p\",[e._v(\"这个半同步复制，有两种方式，第一种叫做AFTER_COMMIT方式，他不是默认的，他的意思是说，主\\n库写入日志到binlog，等待binlog复制到从库了，主库就提交自己的本地事务，接着等待从库返回给自\\n己一个成功的响应，然后主库返回提交事务成功的响应给客户端。\")]),e._v(\" \"),n(\"p\",[e._v(\"另外一种是现在MySQL 5.7默认的方式，主库把日志写入binlog，并且复制给从库，然后开始等待从库\\n的响应，从库返回说成功给主库了，主库再提交事务，接着返回提交事务成功的响应给客户端。\")]),e._v(\" \"),n(\"p\",[e._v(\"这种方式可以保证你每个事务提交成功之前，binlog日志一定都复制到从库了，所以只要事\\n务提交成功，就可以认为数据在从库也有一份了，那么主库崩溃，已经提交的事务的数据绝对不会丢失\\n的。\")]),e._v(\" \"),n(\"p\",[e._v(\"搭建半同步复制也很简单，在之前搭建好异步复制的基础之上，安装一下半同步复制插件就可以了，先\\n在主库中安装半同步复制插件，同时还得开启半同步复制功能：\\ninstall plugin rpl_semi_sync_master soname 'semisync_master.so';\\nset global rpl_semi_sync_master_enabled=on;\\nshow plugins;\")]),e._v(\" \"),n(\"p\",[e._v(\"接着在从库也是安装这个插件以及开启半同步复制功能：\\ninstall plugin rpl_semi_sync_slave soname 'semisync_slave.so';\\nset global rpl_semi_sync_slave_enabled=on;\\nshow plugins;\\n接着要重启从库的IO线程：stop slave io_thread; start slave io_thread;\\n然后在主库上检查一下半同步复制是否正常运行：show global status like '%semi%';，如果看到了\\nRpl_semi_sync_master_status的状态是ON，那么就可以了。\")]),e._v(\" \"),n(\"p\",[n(\"strong\",[e._v(\"一般来说主从复制都建议做成半同步复制，因为这样配合高可用切换机制，就可以保证数据库有一个在线的从库热备份主库的数据了，而且主要主库宕机，从库立马切换为主库，数据不丢失，数据库还高可用。\")])]),e._v(\" \"),n(\"p\",[e._v(\"方法（3）：GTID搭建方式\")]),e._v(\" \"),n(\"p\",[e._v(\"首先在主库进行配置：\\ngtid_mode=on\\nenforce_gtid_consistency=on\\nlog_bin=on\\nserver_id=单独设置一个\\nbinlog_format=row\\n接着在从库进行配置：\\ngtid_mode=on\\nenforce_gtid_consistency=on\\nlog_slave_updates=1\\nserver_id=单独设置一个\")]),e._v(\" \"),n(\"p\",[e._v(\"接着按照之前讲解的步骤在主库创建好用于复制的账号之后，就可以跟之前一样进行操作了，比如在主\\n库dump出来一份数据，在从库里导入这份数据，利用mysqldump备份工具做的导出，备份文件里会\\n有SET @@GLOBAL.GTID_PURGED=***一类的字样，可以照着执行一下就可以了。\")]),e._v(\" \"),n(\"p\",[e._v(\"接着其余步骤都是跟之前类似的，最后执行一下show master status，可以看到executed_gtid_set，\\n里面记录的是执行过的GTID，接着执行一下SQL：select * from gtid_executed，可以查询到，对比一\\n下，就会发现对应上了。\\n那么此时就说明开始GTID复制了。\")]),e._v(\" \"),n(\"p\",[e._v(\"其实大家会发现无论是GTID复制，还是传统复制，都不难，很简单，往往这就是比较典型的MySQL主\\n从复制的搭建方式了，然后大家可以自行搜索一下MyCat中间件或者是Sharding-Sphere的官方文档，\\n其实也都不难，大家照着文档做，整合到Java代码里去，就可以做出来基于主从复制的读写分离的效果\\n了。\")]),e._v(\" \"),n(\"p\",[e._v(\"那些中间件都是支持读写分离模式的，可以仅仅往主库去写，从从库去读，这都没问题的。\\n如果落地到项目里，那么就完成了一个主从架构以及读写分离的架构了，此时按照我们之前所说的，如\\n果说你的数据库之前对一个库的读写请求每秒总共是2000，此时读写分离后，也许就对主库每秒写TPS\\n才几百，从库的读QPS是1000多。\")]),e._v(\" \"),n(\"p\",[e._v(\"那么万一你要是从库的读QPS越来越大，达到了每秒几千，此时你是不是会压力很大？没关系，这个时\\n候你可以给主库做更多的从库，搭建从库，给他挂到主库上去，每次都在凌晨搞，先让系统停机，对外\\n不使用，数据不更新。\")]),e._v(\" \"),n(\"p\",[e._v(\"接着对主库做个dump，导出数据，到从库导入数据，做一堆配置，然后让从库开始接着某个时间点开\\n始继续从主库复制就可以了，一旦搭建完毕，就等于给主库挂了一个新的从库上去，此时继续放开系统\\n的对外限制，继续使用就可以了，整个过程基本在1小时以内。\")]),e._v(\" \"),n(\"p\",[e._v(\"如果在凌晨比如2点停机1小时，基本对业务是没有影响的。\\n好，那么到此为止，主从复制这块就初步的算讲完了，下讲给大家介绍一下主从复制的延迟问题如何解\\n决。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"主从复制中数据延迟问题\")])]),e._v(\" \"),n(\"p\",[e._v(\"为什么会产生这个主从延迟的问题呢？也很简单，其实你主库是多线程并发写入的，这个大家都知\\n道的，所以主库写入数据的速度可能是很快的，但是从库是单个线程缓慢拉取数据的，所以才会导致从\\n库复制数据的速度是比较慢的。\")]),e._v(\" \"),n(\"p\",[e._v(\"主从之间到底延迟了多少时间呢？这个可以用一个工具来进行监控，比较推荐的是percona-\\ntoolkit工具集里的pt-heartbeat工具，他会在主库里创建一个heartbeat表，然后会有一个线程定时更\\n新这个表里的时间戳字段，从库上就有一个monitor线程会负责检查从库同步过来的heartbeat表里的\\n时间戳。把时间戳跟当前时间戳比较一下，其实就知道主从之间同步落后了多长时间了，关于这个工具的使用，\\n大家可以自行搜索一下\")]),e._v(\" \"),n(\"p\",[e._v(\"延迟情况：\\n（1）系统刚写入一条数据到主库，接着代码里立即就在从库里读取，可能此时从库复制有延迟，你会读不到刚\\n写入进去的数据！\\n（2）从库同步数据太慢\\n了，导致你从库读取的数据都是落后和过期的，也可能会导致你的系统产生一定的业务上的bug。\")]),e._v(\" \"),n(\"p\",[e._v(\"解决：尽可能缩小主从同步的延迟时间，那么怎么做呢？其实就是让从库也用多线程并行复制数据就可以了\")]),e._v(\" \"),n(\"p\",[e._v(\"MySQL 5.7就已经支持并行复制了，可以在从库里设置slave_parallel_workers>0，然后把\\nslave_parallel_type设置为LOGICAL_CLOCK，就ok了。\")]),e._v(\" \"),n(\"p\",[e._v(\"如果你觉得还是要求刚写入的数据你立马强制必须一定可以读到，在类似MyCat或者Sharding-Sphere之类的中间件里设置强制读写都从主库走，这样你写入主\\n库的数据，强制从主库里读取，一定立即可以读到的。\")]),e._v(\" \"),n(\"p\",[e._v(\"在落实读写分离架构的时候，要注意一下复制方式，是异步还是半同步？如\\n果说你对数据丢失并不是强要求不能丢失的话，可以用异步模式来复制，再配合一下从库的并行复制机制。要对MySQL做高可用保证数据绝对不丢失的话，建议还是用半同步机制比较好一些，同理最好\\n是配合从库的并行复制机制。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"数据库高可用（主库故障）\\n基于主从复制实现故障转移\")])]),e._v(\" \"),n(\"p\",[e._v(\"问题：从库宕机了影响并不是很大，因为大不了就是让所有的读流量都从主库去读就可以了，但是如\\n果主库宕机了呢？那就真的麻烦了，因为主库一旦宕机，你就没法写入数据了，从库毕竟是不允许写入\\n的，只允许读取。\")]),e._v(\" \"),n(\"p\",[e._v(\"可以在主库宕机之后，就立马把从库切换为主库呢，然后所有人都对从库切换为\\n的主库去写入和读取呢？如果能实现这样的一个效果，那数据库不就实现高可用了吗？没错，就这么简\\n单，这就是数据库的高可用架构。\")]),e._v(\" \"),n(\"p\",[e._v(\"一般生产环境里用于进行数据库高可用架构管理的工具是MHA，也就是Master High Availability\\nManager and Tools for MySQL，是日本人写的，用perl脚本写的一个工具，这个工具就是专门用于监\\n控主库的状态，如果感觉不对劲，可以把从库切换为主库。\")]),e._v(\" \"),n(\"p\",[e._v(\"这个MHA自己也是需要单独部署的，分为两种节点，一个是Manager节点，一个是Node节点，\\nManager节点一般是单独部署一台机器的，Node节点一般是部署在每台MySQL机器上的，因为Node\\n节点得通过解析各个MySQL的日志来进行一些操作。\")]),e._v(\" \"),n(\"p\",[e._v(\"Manager节点会通过探测集群里的Node节点去判断各个Node所在机器上的MySQL运行是否正常，如\\n果发现某个Master故障了，就直接把他的一个Slave提升为Master，然后让其他Slave都挂到新的\\nMaster上去，完全透明。\")]),e._v(\" \"),n(\"ul\",[n(\"li\",[e._v(\"搭建过程\\n原理简单，搭建复杂：大家最好是准备4台机器，其中一台机器装一个mysql作为master，另外两台机器都装mysql作\\n为slave，然后在每个机器上都得部署一个MHA的node节点，然后用单独的最后一台机器装MHA的\\nmaster节点，整体就这么一个结构。确保4台机器之间都是免密码互相通信的，不依靠密码可以直接ssh登录上去，因为这是MHA的perl脚本要用的。\")])]),e._v(\" \"),n(\"p\",[e._v(\"接着大家就应该部署一个MySQL master和两个MySQL slave，搭建的过程就按照之前讲解的就行了，\\n先装好MySQL，接着进行主从复制的搭建，全部按照之前的步骤走就行了，可以选择异步复制，当然也\\n可以是半同步复制的。\")]),e._v(\" \"),n(\"p\",[e._v(\"在三个数据库所在机器上安装MHA\\nnode节点的步骤，首先那必须要先安装Perl语言环境了，这就跟我们平时用Java开发，那你必须得先装\\n个JDK吧！\")]),e._v(\" \"),n(\"p\",[e._v(\"流程：（1）先可以用yum装一下Perl语言环境：yum install perl-DBD-MySQL\\n（2）从下述地址下载MHA node代码：https://github.com/yoshinorim/mha4mysql-node，接着就可\\n以把node的压缩包用WinSCP之类的工具上传到机器上去，接着解压缩node包就可以了，tar -zxvf\\nmha4mysql-node-0.57.tar.gz。\\n（3）安装perl-cpan软件包：\\ncd mha4mysql-node-0.57\\nyum -y install perl-CPAN*\\nperl Makeﬁle.PL\\nmake && make install\\n（4）暂时node的安装就可以了，记得3个部署MySQL的机器都要安装node，接着就是安装MHA\\n的manager节点，先安装需要的一些依赖包：\\nyum install -y perl-DBD-MySQL*\\nrpm -ivh perl-Params-Validate-0.92-3.el6.x86_64.rpm\\nrpm -ivh perl-Conﬁg-Tiny-2.12-1.el6.rfx.noarch.rpm\\nrpm -ivh perl-Log-Dispatch-2.26-1.el6.rf.noarch.rpm\\nrpm -ivh perl-Parallel-ForkManager-0.7.5-2.2.el6.rf.noarch.rpm\\n接着就可以安装manager节点了，先在下面的地址下载manager的压缩包：https://github.com/yoshi\\nnorim/mha4mysql-manager，然后上传到机器上去，按照下述步骤安装就可以了：\\ntar -zxvf mha4mysql-manager-0.57.tar.gz\\nperl Makeﬁle.PL\\nmake\\n资源仅限自己学习 ww.pplsunny.top\\nmake install\\n接着为MHA manager创建几个目录：/usr/local/mha，/etc/mha，然后进入到/etc/mha目录下，vi\\nmha.conf一下，编辑他的配合文件\\n[server default]\\nuser=zhss\\npassword=12345678\\nmanager_workdir=/usr/local/mha\\nmanager_log=/usr/local/mha/manager.log\\nremote_workdir=/usr/local/mha\\nssh_user=root\\nrepl_user=repl\\nrepl_password=repl\\nping_interval=1\\nmaster_ip_failover_script=/usr/local/scripts/master_ip_failover\\nmaster_ip_online_change_script=/usr/local/scripts/master_ip_online_change\\n[server1]\\nhostname=xx.xx.xx.xx\\nssh_port=22\\nmaster_binlog_dir=/data/mysqll\\ncondidate_master=1\\nport=3306\\n[server1]\\nhostname=xx.xx.xx.xx\\nssh_port=22\\nmaster_binlog_dir=/data/mysqll\\ncondidate_master=1\\nport=3306\\n[server1]\\nhostname=xx.xx.xx.xx\\nssh_port=22\")]),e._v(\" \"),n(\"p\",[e._v(\"master_binlog_dir=/data/mysqll\\ncondidate_master=1\\nport=3306\")])])}),[],!1,null,null,null);_.default=r.exports}}]);","extractedComments":[]}