{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{405:function(_,v,r){\"use strict\";r.r(v);var e=r(56),l=Object(e.a)({},(function(){var _=this,v=_.$createElement,r=_._self._c||v;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":_.$parent.slotKey}},[r(\"h1\",{attrs:{id:\"mysql\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql\"}},[_._v(\"#\")]),_._v(\" Mysql\")]),_._v(\" \"),r(\"h2\",{attrs:{id:\"sql语句\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#sql语句\"}},[_._v(\"#\")]),_._v(\" SQL语句\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"使用group-by-情况\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#使用group-by-情况\"}},[_._v(\"#\")]),_._v(\" 使用group by 情况\")]),_._v(\" \"),r(\"p\",[_._v(\"分情况，1、当聚集函数和非聚集函数出现在一起时，需要将非聚集函数进行group by\\n2、当只做聚集函数查询时候，就不需要进行分组了。\\nselect c_id,sum(s_score) from score where c_id='02';（虽然select中聚集函数和非聚集函数都有，但where中c_id等于具体值，只有一组，c_id已经无需分组）\")]),_._v(\" \"),r(\"p\",[_._v(\"使用字段A分组，可以聚合字段B函数\")]),_._v(\" \"),r(\"p\",[_._v(\"分组的意义在于对每一组数据进行聚合函数\\n如 group by a.sno having count(a.score)>=2;成绩表先按学号分组，都同一名学生中不同的课程成绩做聚合函数\")]),_._v(\" \"),r(\"p\",[_._v(\"子查询的话，建议使用在查询显示出来的列只需要使用一张表的（显示一张表中的信息，另一张表只能作为连接点）\")]),_._v(\" \"),r(\"p\",[_._v(\"内连接的话，建议使用查询显示出来的列需要使用到两张表中的多个列 （多表查询 适合用内连接）\")]),_._v(\" \"),r(\"p\",[_._v(\"如按分数降序排列的学生信息（若用s_id连接点，只能看学生信息无法看分数降序）\")]),_._v(\" \"),r(\"p\",[_._v(\"多表连接是将多表当成1张表，可以使用聚合函数\\n-- 25. 查询平均成绩大于等于 85 的所有学生的学号、姓名和平均成绩\\nselect a.sno, b.sname, avg(a.score)\\nfrom sc as a inner join student as b on a.sno=b.sno\\ngroup by a.sno having avg(a.score)>=85;\"),r(\"br\"),_._v(\"\\n注：聚合函数（a表字段） 不是a表聚合函数（字段）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"执行顺序\\n1、最先执行from tab；2、where语句是对条件加以限定；3、分组语句【group by…… having】；4、聚合函数；5、select语句；6、order by排序语句。\")])]),_._v(\" \"),r(\"p\",[_._v(\"--- 28.查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩\\nselect a.sno, b.sname, avg(a.score) from sc as a\\ninner join student as b on a.sno=b.sno\\nwhere a.score<60 group by a.sno having count(a.score)>=2;\\n如果\")]),_._v(\" \"),r(\"p\",[_._v(\"内外连接选择看需不需要显示NUll数据\")]),_._v(\" \"),r(\"p\",[_._v('-- 34. 查询\" 01 \"课程比\" 02 \"课程成绩高的学生的信息及课程分数\\n/* 思路：1.在sc表中选出临时表b（\" 01 \"课程），临时表c（\" 02 \"课程）;\\n2.ab表相交条件：学生号相同且a表成绩>b表成绩\\n3.再与student表相交 '),r(\"em\",[_._v(\"/\\nselect a.\")]),_._v(\", b.score as '01', c.score as '02'\\nfrom student as a\\ninner join (select * from sc where cno='01') as b on a.sno=b.sno\\ninner join (select * from sc where cno='02') as c on b.sno=c.sno and b.score>c.score;\")]),_._v(\" \"),r(\"p\",[_._v(\"-窗口函数\\n--37. 按各科成绩进行排序，并显示排名，Score 重复时保留名次空缺\\nselect *, rank() over (partition by cno order by score desc) as ranking\\nfrom sc; 113\")]),_._v(\" \"),r(\"p\",[_._v(\"dense_rank() 重复时合并名次112\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"定义\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#定义\"}},[_._v(\"#\")]),_._v(\" 定义\")]),_._v(\" \"),r(\"p\",[_._v(\"开放源代码的关系型数据库管理系统\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"mysql存储引擎区别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql存储引擎区别\"}},[_._v(\"#\")]),_._v(\" MySQL存储引擎区别\")]),_._v(\" \"),r(\"table\",[r(\"thead\",[r(\"tr\",[r(\"th\",[_._v(\"表头\")]),_._v(\" \"),r(\"th\",[_._v(\"InnoDB\")]),_._v(\" \"),r(\"th\",[_._v(\"MYISAM\")])])]),_._v(\" \"),r(\"tbody\",[r(\"tr\",[r(\"td\",[_._v(\"外键\")]),_._v(\" \"),r(\"td\",[_._v(\"支持\")]),_._v(\" \"),r(\"td\")]),_._v(\" \"),r(\"tr\",[r(\"td\",[_._v(\"锁\")]),_._v(\" \"),r(\"td\",[_._v(\"表锁和行锁\")]),_._v(\" \"),r(\"td\",[_._v(\"表锁\")])]),_._v(\" \"),r(\"tr\",[r(\"td\",[_._v(\"可恢复性\")]),_._v(\" \"),r(\"td\",[_._v(\"由事务日志恢复\")]),_._v(\" \"),r(\"td\",[_._v(\"无日志\")])]),_._v(\" \"),r(\"tr\",[r(\"td\",[_._v(\"索引与表结构\")]),_._v(\" \"),r(\"td\",[_._v(\"聚簇，数据与索引集中存储，.ibd和.frm\")]),_._v(\" \"),r(\"td\",[_._v(\"数据.MYD，索引.MYI\")])]),_._v(\" \"),r(\"tr\",[r(\"td\",[_._v(\"查询性能\")]),_._v(\" \"),r(\"td\"),_._v(\" \"),r(\"td\",[_._v(\"一般快\")])])])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"三大范式\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#三大范式\"}},[_._v(\"#\")]),_._v(\" 三大范式：\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"第一：每列保持原子性，字段不可分解\")]),_._v(\" \"),r(\"li\",[_._v(\"第二：表中每列都和主键相关\")]),_._v(\" \"),r(\"li\",[_._v(\"第三：表中每列都和主键列直接相关\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"数据类型\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据类型\"}},[_._v(\"#\")]),_._v(\" 数据类型\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"整数\")]),_._v(\" \"),r(\"li\",[_._v(\"浮点数\")])]),_._v(\" \"),r(\"p\",[_._v(\"DECIMAL为浮点数，使用字符串存储，能精确到小数\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"日期\")])]),_._v(\" \"),r(\"p\",[_._v(\"常用的有year、time、date、datatime(1000年-9999年，秒，8位，时区无关)、timestamp（1970-2038年，秒，4位，时区相关）\\n应用场景：尽量使用timestamp,更高的空间效率\")]),_._v(\" \"),r(\"h2\",{attrs:{id:\"索引\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引\"}},[_._v(\"#\")]),_._v(\" 索引\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"定义-2\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#定义-2\"}},[_._v(\"#\")]),_._v(\" 定义：\")]),_._v(\" \"),r(\"p\",[_._v(\"对数据库表的一列或多列的值进行排序的一种结构\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引优缺点\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引优缺点\"}},[_._v(\"#\")]),_._v(\" 索引优缺点\")]),_._v(\" \"),r(\"p\",[_._v(\"优点：\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"加快数据的检索速度\")]),_._v(\" \"),r(\"li\",[_._v(\"将随机I/O变成顺序I/O（B+树的叶子节点连接在一起）\")]),_._v(\" \"),r(\"li\",[_._v(\"加速表与表之间的连接\")])]),_._v(\" \"),r(\"p\",[_._v(\"缺点：\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"索引占用物理空间(空间)\")]),_._v(\" \"),r(\"li\",[_._v(\"创建和维护索引都需要时间(时间)\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引的数据结构\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引的数据结构\"}},[_._v(\"#\")]),_._v(\" 索引的数据结构\")]),_._v(\" \"),r(\"p\",[_._v(\"索引的数据结构主要是B+树和哈希表，对应的索引分别为B+树索引(InnoDB引擎的默认索引类型)和哈希索引（InnoDB）\\nB+树：所有的记录节点都是按照键值的大小顺序放在叶子节点上（有序性，效率高，支持排序和范围查询）.\")]),_._v(\" \"),r(\"p\",[_._v(\"哈希：对每行数据的索引列哈希计算，哈希值为key，指向数据行的指针作为哈希表value,适合精确查找O(1)\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"b-hash索引区别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#b-hash索引区别\"}},[_._v(\"#\")]),_._v(\" B+,hash索引区别\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"哈希一般用精确的等值查找，B+树除了精确的等值查找外还有其他查找（大多数情况选用）\")]),_._v(\" \"),r(\"li\",[_._v(\"哈希不支持排序，哈希表无序\")]),_._v(\" \"),r(\"li\",[_._v(\"哈希不支持范围查找\")]),_._v(\" \"),r(\"li\",[_._v(\"哈希不支持模糊查询及多列索引的最左前缀匹配\")]),_._v(\" \"),r(\"li\",[_._v(\"哈希有冲突不稳定，B+树稳定（每次都从根节点到叶子节点）\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引种类-一个索引可有多个种类\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引种类-一个索引可有多个种类\"}},[_._v(\"#\")]),_._v(\" 索引种类（一个索引可有多个种类）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"主键索引：数据列不能重复和NULL，一个表只能有一个主键索引\")]),_._v(\" \"),r(\"li\",[_._v(\"组合索引：多个列值组成的索引\")]),_._v(\" \"),r(\"li\",[_._v(\"唯一索引：数据列不能重复，可以NULL，索引值唯一\")]),_._v(\" \"),r(\"li\",[_._v(\"全文索引：对文本内容搜索\")]),_._v(\" \"),r(\"li\",[_._v(\"普通索引：基本的索引类型，可为NULL\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"b树和b-树区别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#b树和b-树区别\"}},[_._v(\"#\")]),_._v(\" B树和B+树区别\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"B+树叶子节点相连，方便顺序检索\")]),_._v(\" \"),r(\"li\",[_._v(\"B树内部节点和叶子节点都放键值，B+树内部节点只有键没值，叶子节点放键和值\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"不选b树的原因\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#不选b树的原因\"}},[_._v(\"#\")]),_._v(\" 不选B树的原因\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"B+树空间利用率更高，B+树内部节点只存储键，树高度变低，减少I/O次数，检索更快\")]),_._v(\" \"),r(\"li\",[_._v(\"B+叶子节点连接在一起，范围查找，顺序查找方便\")]),_._v(\" \"),r(\"li\",[_._v(\"B+树更稳定，查询从根节点到叶子节点，B树适合随机检索，B+树适合随机检索和顺序检索\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"聚簇索引-非聚簇索引\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#聚簇索引-非聚簇索引\"}},[_._v(\"#\")]),_._v(\" 聚簇索引，非聚簇索引\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"聚簇索引：数据和结构一起存储，索引结构的叶子节点保留数据行\")]),_._v(\" \"),r(\"li\",[_._v(\"非聚簇索引：数据和索引分开存储，索引叶子检点存储的是指向数据行的地址\")])]),_._v(\" \"),r(\"p\",[_._v(\"InnoDB：主聚辅非聚\\nMyISAM：主非聚辅非聚\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"非聚簇索引不一定回表-涉及索引覆盖\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#非聚簇索引不一定回表-涉及索引覆盖\"}},[_._v(\"#\")]),_._v(\" 非聚簇索引不一定回表，涉及索引覆盖\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"当select 主键,xx where xx=,走辅助索引能查数据，这就是索引覆盖\")]),_._v(\" \"),r(\"li\",[_._v(\"select 主键，xx,xx1 where xx=，需要建立xx和xx1的联合索引\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引设计原则\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引设计原则\"}},[_._v(\"#\")]),_._v(\" 索引设计原则\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"适合索引列在where后出行的列或连接句子中指定的列，而不是select后的列\")]),_._v(\" \"),r(\"li\",[_._v(\"索引列基数大效果好，即区分度高的列\")]),_._v(\" \"),r(\"li\",[_._v(\"尽量用短索引(磁盘I/O少，缓存能存更多键值)\")]),_._v(\" \"),r(\"li\",[_._v(\"尽量使用最左前缀\")]),_._v(\" \"),r(\"li\",[_._v(\"不要过度索引，创建维护需要时间空间\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引的使用场景\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引的使用场景\"}},[_._v(\"#\")]),_._v(\" 索引的使用场景\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引优化\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引优化\"}},[_._v(\"#\")]),_._v(\" 索引优化\")]),_._v(\" \"),r(\"p\",[_._v(\"将不符合要求的索引优化成符合索引设计原则和应用场景的索引\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"索引的设计原则\")]),_._v(\" \"),r(\"li\",[_._v(\"索引不能是表达式一部分和函数的参数，如where a+1=2\")]),_._v(\" \"),r(\"li\",[_._v(\"将区分度高的索引放在前面\")]),_._v(\" \"),r(\"li\",[_._v(\"少使用select *\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"创建-删除索引\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#创建-删除索引\"}},[_._v(\"#\")]),_._v(\" 创建/删除索引\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"经典sql语句\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#经典sql语句\"}},[_._v(\"#\")]),_._v(\" 经典sql语句\")]),_._v(\" \"),r(\"p\",[_._v(\"Student(S#,Sname,Sage,Ssex) 学生表\")]),_._v(\" \"),r(\"p\",[_._v(\"Course(C#,Cname,T#) 课程表\")]),_._v(\" \"),r(\"p\",[_._v(\"SC(S#,C#,score) 成绩表\")]),_._v(\" \"),r(\"p\",[_._v(\"Teacher(T#,Tname) 教师表\")]),_._v(\" \"),r(\"h2\",{attrs:{id:\"mysql优化\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql优化\"}},[_._v(\"#\")]),_._v(\" Mysql优化\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"系统如何与mysql交互\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#系统如何与mysql交互\"}},[_._v(\"#\")]),_._v(\" 系统如何与Mysql交互\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"Java系统通过Mysql驱动(建立网络连接，执行sql语句)实现与数据库交互\\n注:不同语言驱动也不同\")]),_._v(\" \"),r(\"li\",[_._v(\"建立数据库连接池(供多线程使用，Tomcat和数据库服务器都有)访问数据库\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"mysql架构设计-执行sql\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql架构设计-执行sql\"}},[_._v(\"#\")]),_._v(\" MySQL架构设计（执行SQL）\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条SQL语句，那么大家先思考一个问题，\\n谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？  ---\\x3e线程获取sql语句，交予sql接口通过查询解析器解析sql，找查询优化器(选择最优的查询路径)，执行器调用存储引擎接口（执行sql语句，存储引擎和内存、磁盘交互）\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"innodb存储引擎架构设计\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#innodb存储引擎架构设计\"}},[_._v(\"#\")]),_._v(\" InnoDB存储引擎架构设计\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[_._v(\"缓冲池：缓存数据（加载磁盘数据时同时对数据加锁）\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"Redo Log Buffer:系统宕机，避免数据丢失（缓冲池中）\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"undo日志文件：可以使更新数据回滚(磁盘中的)\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"redo日志文件：提交事务的时候将redo日志写入磁盘，三种刷屏策略innodb_flush_log_at_trx_commit，0不刷、1刷  2延时刷（先放os cache）\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"binlog：重做日志（mysql server的日志文件，提交事务的时候，同时会写入binlog，sync_binlog参数，0延时刷（先放os cache），1刷）\\n当我们把binlog写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的binlog文件名称和这次\\n更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标\\n记。\\nMySQL有一个后台的IO线程，会在之后某个时间里，随机的把内存buffer pool中的修改后的脏数据给刷回到磁\\n盘上的数据文件里\")])])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"生产环境数据库机器配置\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产环境数据库机器配置\"}},[_._v(\"#\")]),_._v(\" 生产环境数据库机器配置\")]),_._v(\" \"),r(\"p\",[_._v(\"Java应用系统部署的时候常选用的机器配置大致是2核4G和4核8G的较多一些，数据库部\\n署的时候常选用的机器配置最低在8核16G以上，正常在16核32G\")]),_._v(\" \"),r(\"p\",[_._v(\"大量的高并发线上系统的生产经验观察下来而言，一般Java应用系统部署在4核8G的机器上，每秒钟抗下500左右\\n的并发访问量，差不多是比较合适的，当然这个也不一定。因为你得考虑一下，假设你每个请求花费1s可以处理完，那么你一\\n台机器每秒也许只可以处理100个请求，但是如果你每个请求只要花费100ms就可以处理完，那么你一台机器每秒也许就可以\\n处理几百个请求。一台机器能抗下每秒多少请求，往往是跟你每个请求处理耗费多长时间是关联的\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"高并发场景机器选择：通常推荐的数据库至少是选用8核16G以的机器，甚至是16核32G的机器更加合适一\\n些。主要耗费时间的是Java系统和数据库之间的网络通信。MySQL数据库需要对内存和磁盘文件进行大量的IO操作，所以数据库往往是负载最高的。因为数据库需要\\n执行大量的磁盘IO操作，他的每个请求都比较耗时一些，所以机器的配置自然需要高一些了。一般8核16G的机器部署的MySQL数据库，每秒抗个一两千并发请求是没问题的。对于16核32G的机器部署的MySQL数据库而言，每秒抗个两三千，甚至三四千的并发请求也都是可以的，那么数据库的CPU、磁盘、IO、内存的负载瞬间都会飙升到很高，数据库也是可能会扛不住宕机的。\\n内部资源禁止\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"生产环境数据如何性能测试\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产环境数据如何性能测试\"}},[_._v(\"#\")]),_._v(\" 生产环境数据如何性能测试\")]),_._v(\" \"),r(\"p\",[_._v(\"基于一些工具模拟一个系统每秒发出1000，2000，3000个请求到数据库上去，观察一下他的CPU负载、磁盘IO负载、网络\\nIO负载、内存复杂，然后数据库能否每秒处理掉这1000个请求，还是每秒只能处理500个请求。\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库的压测和他上面的Java系统的压测，其实是两回事儿，首先你得知道你的数\\n据库最大能抗多大压力，然后你再去看你的Java系统能抗多大压力。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"压测数据库，最终是想看看这个数据库在现有的机器配置之下，每秒可以抗下多\\n少个请求呢？这个每秒抗下多少个请求，其实是有专业术语的，分别是QPS和TPS。\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"QPS:一次请求\\n就是一条SQL语句，也就是说这个数据库每秒可以处理多少个SQL语句。\\n资源禁止\")]),_._v(\" \"),r(\"li\",[_._v(\"TPS：数据库每秒会处理多少次事务提交或者回滚。（多条SQL语句）\\n如：对于这个交易系统，他拆分为了很多服务，一笔交易的\\n完成需要多个服务协作完成，也就是说一次交易请求需要调用多个服务才能完成。\\n那么你觉得对于每个服务而言，他每秒处理的请求数量是QPS还是TPS呢？对于整个交易系统而言，他每秒钟处理的交易笔数是TPS。\")])]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"IO相关的压测性能指标\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"IOPS：这个指的是机器的随机IO并发处理的能力，比如机器可以达到200 IOPS，意思就是说每秒可以执行200个随机\\nIO读写请求。\")]),_._v(\" \"),r(\"li\",[_._v(\"吞吐量：这个指的是机器的磁盘存储每秒可以读写多少字节的数据量\")])]),_._v(\" \"),r(\"p\",[_._v(\"注：一台机器他的存储每秒可以读写多少字节的数据量，就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去。一\\n般来说我们写redo log之类的日志，都是对磁盘文件进行顺序写入的，也就是一行接着一行的写，不会说进行随机的读写，那\\n么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右。\\n内部资源禁止外传\")]),_._v(\" \"),r(\"ol\",{attrs:{start:\"3\"}},[r(\"li\",[r(\"p\",[_._v(\"latency：这个指标说的是往磁盘里写入一条数据的延迟。\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"CPU负载：与QPS相关\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"网路负载：与QPS相关\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"内存负载\\n数据库压测工具，就是sysbench，压测步骤\\nsysbench中不停的增加线程的数量，比如使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。\\n如：使用了10个线程去压测数据库，如果你的机器性能很\\n高，然后你觉得10个线程没法压测出来数据库真实的最高负载能力，你其实可以在sysbench中不停的增加线程的数量，比如\\n使用20个线程，甚至100个线程去并发的访问数据库，直到发现数据库的QPS和TPS上不去了。\")])])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"压测时常用linux常用指令\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#压测时常用linux常用指令\"}},[_._v(\"#\")]),_._v(\" 压测时常用Linux常用指令\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"执行top命令后\\ntop - 15:52:00 up 42:35, 1 user, load average: 0.15, 0.05, 0.01 （up运行时间，CPU在1分钟、5分钟、15分钟内的负载情况，指核数）\")])]),_._v(\" \"),r(\"p\",[_._v(\"Mem: 33554432k total, 20971520k used, 12268339 free, 307200k buffers（内存）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"dstat（IO读写数据量）\")]),_._v(\" \"),r(\"li\",[_._v(\"dstat -r（磁盘随机读取写入次数）\")]),_._v(\" \"),r(\"li\",[_._v(\"dstat -n(网卡流量)\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"数据库部署监控系统与为数据库的监控系统部署可视化报表系统\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#数据库部署监控系统与为数据库的监控系统部署可视化报表系统\"}},[_._v(\"#\")]),_._v(\" 数据库部署监控系统与为数据库的监控系统部署可视化报表系统\")]),_._v(\" \"),r(\"p\",[_._v(\"搭建一下生产环境数据库的可视化监控平台，我们会基于Prometheus+Grafana来搭建。\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"详细buffer-pool\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#详细buffer-pool\"}},[_._v(\"#\")]),_._v(\" 详细Buffer Pool\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/sql.PNG\",alt:\"sql执行\"}}),_._v(\"\\n对数据库执行增删改操作的时候，实际上主要都是针对内存里的Buffer Pool中的数据进行的，也\\n就是你实际上主要是对数据库的内存里的数据结构进行了增删改\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"redo log机制：解决内存更新，数据库崩溃，更新数据消失问题\")])]),_._v(\" \"),r(\"p\",[_._v(\"配置：\\n[server]\\ninnodb_buffer_pool_size = 2147483648\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库的核心数据模型就是表+字段+行\")]),_._v(\" \"),r(\"p\",[_._v(\"Buffer pool:内存数据结构（非一行一行数据放置，将很多行数据放在一个数据页中）默认128MB\")]),_._v(\" \"),r(\"p\",[_._v(\"磁盘数据页与Buffer Pool缓存页如何对应：Buffer Pool中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是16KB。\")]),_._v(\" \"),r(\"p\",[_._v(\"缓存页中的描述信息：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂\\n八的东西。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/bufferpool.PNG\",alt:\"buffer pool\"}})]),_._v(\" \"),r(\"p\",[_._v(\"注：Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字\\n节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130\\n多MB的样子，因为他里面还要存放每个缓存页的描述数据。Buffer Pool划分完全部的缓存页和描述数据块之后，还剩一点点的内存，这一点\\n点的内存放不下任何一个缓存页了，所以这点内存就只能放着不能用，这就是内存碎片。数据库在Buffer Pool中划分缓存页的时候，会让所有的缓存页和描述数据块都紧密的挨在一起，这样尽可能减\\n少内存浪费，就可以尽可能的减少内存碎片的产生了。\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"free链表-磁盘读取数据页到buffer-pool\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#free链表-磁盘读取数据页到buffer-pool\"}},[_._v(\"#\")]),_._v(\" free链表（磁盘读取数据页到Buffer Pool）\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区\\n域，作为Buffer Pool的内存区域。数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在\\nBuffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据（空页）。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"Buffer Pool中哪些缓存页是空闲的状态\\nfree链表：双向链表数据结构，每个节点就是一个空闲的缓存页的描述数据块的地址。只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个free链表中。\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/free.PNG\",alt:\"free\"}})])]),_._v(\" \"),r(\"p\",[_._v(\"free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面就存放了free链表的头节点\\n的地址，尾节点的地址，还有free链表里当前有多少个节点。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"如何看数据页是否被缓存\\n数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个key，然后缓存页的地址作为value。当你要使用一个数据页的时候，通过“表空间号+数据页号”作为key去这个哈希表里查一下，如果没有就读取数据页，如果\\n已经有了，就说明数据页已经被缓存了。\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"写sql的时候-只知道表-行的概念-但是在mysql内部操作的时候-是表空间-数据页的概念。区别与联系\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#写sql的时候-只知道表-行的概念-但是在mysql内部操作的时候-是表空间-数据页的概念。区别与联系\"}},[_._v(\"#\")]),_._v(\" 写SQL的时候，只知道表+行的概念，但是在MySQL内部操作的时候，是表空间+数据页的概念。区别与联系\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"flush链表-更新buffer-pool数据\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#flush链表-更新buffer-pool数据\"}},[_._v(\"#\")]),_._v(\" flush链表(更新Buffer Pool数据)\")]),_._v(\" \"),r(\"p\",[_._v(\"脏数据和脏页：缓存更新后未刷入硬盘的数据和数据页\")]),_._v(\" \"),r(\"p\",[_._v(\"不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到Buffer Pool里\\n去的，可能根本没修改过！\")]),_._v(\" \"),r(\"p\",[_._v(\"flush链表：通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/flush.PNG\",alt:\"flush\"}})]),_._v(\" \"),r(\"p\",[_._v(\"描述数据页结构：\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/node.PNG\",alt:\"node\"}})]),_._v(\" \"),r(\"h4\",{attrs:{id:\"lru算法-buffer-pool缓存页不够-淘汰缓存\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#lru算法-buffer-pool缓存页不够-淘汰缓存\"}},[_._v(\"#\")]),_._v(\" LRU算法(Buffer pool缓存页不够，淘汰缓存)\")]),_._v(\" \"),r(\"p\",[_._v(\"淘汰缓存页：把一个缓存页里被修改过的数据，给他刷到磁盘上的数据页里去，然后这个缓存页就可以清空了，让他重新变成一个空闲的缓存页。\")]),_._v(\" \"),r(\"p\",[_._v(\"LRU链表（Least Recently Used）：判断哪些缓存页不常用的\")]),_._v(\" \"),r(\"p\",[_._v(\"LRU链表机制：只要是刚从磁盘上加载数据到缓存页里去，这个缓存页就放入LRU链表的头部，后续如果\\n对任何一个缓存页访问了，也把缓存页从LRU链表中移动到头部去。当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此\\n时你就直接在LRU链表的尾部找到一个缓存页，他一定是最近最少被访问的那个缓存页！\")]),_._v(\" \"),r(\"p\",[_._v(\"注:表、列和行，都是逻辑概念，我们只知道数据库里有一个表，表里有几个字段，有多少行，但是这些表里的数据，在\\n数据库的磁盘上如何存储的，你知道吗？我们是不关注的，所以他们都是逻辑上的概念。\\n表空间、数据页，这些东西，都是物理上的概念，实际上在物理层面，你的表里的数据都放在一个表空间中，表空间\\n是由一堆磁盘上的数据文件组成的，这些数据文件里都存放了你表里的数据，这些数据是由一个一个的数据页组织起\\n来的，这些都是物理层面的概念，这就是他们之间的区别。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"存在问题：\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[r(\"p\",[_._v(\"MySQL的预读机制（参数innodb_random_read_ahead默认OFF）：从磁盘上加载一个数据页的时候，他可\\n能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去！相邻的数据页被放在LRU链表前列，若不访问，会把LRU尾部的那些被频繁访问的缓存页刷入磁盘中。\\n注：触发MySQL预读机制：innodb_read_ahead_threshold默认56，顺序的访问了一个区里的多个\\n数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制；Buffer Pool里缓存了一个区里的13个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会\\n直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"全表扫描，没加任何一个where条件，会导致他直接一下子把这个表里所有的数据页，都从磁盘加载到Buffer Pool里去。LRU链表中排在前面的一大\\n串缓存页，都是全表扫描加载进来的缓存页。\")])])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"优化lru算法-冷热数据分离方案\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#优化lru算法-冷热数据分离方案\"}},[_._v(\"#\")]),_._v(\" 优化LRU算法(冷热数据分离方案)\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由\\ninnodb_old_blocks_pct参数控制的，他默认是37，也就是说冷数据占比37%。\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/lru.PNG\",alt:\"LRU\"}})])]),_._v(\" \"),r(\"p\",[_._v(\"机制：数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部\\ninnodb_old_blocks_time参数，默认值1000，也就是1000毫秒，一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链\\n表头部去。\")]),_._v(\" \"),r(\"p\",[_._v(\"解决了预读机制和全表扫描加载进来的缓存页，都在冷数据区。（如全表扫描的查询，此时你肯定是在1s内就把一大堆缓存页加载进来，然后就访问了这些缓存页一\\n下，通常这些操作1s内就结束了。\")]),_._v(\" \"),r(\"p\",[_._v(\"思考：开发的Java系统，如果\\n在Redis里存放了很多缓存数据，那么此时会不会有类似冷热数据的问题？应该如何优化和解决呢？\")]),_._v(\" \"),r(\"p\",[_._v(\"故在设计缓存机制的时候，经常会考虑热数据的缓存预加载。（每天统计出来哪些商品被访问的次数最多，然后晚上的时候，系统启动一个定时作业，把这些热门商品的\\n数据，预加载到Redis里。）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"LRU链表热数据区极致优化（减少链表中的节点移动\\n部资）：只有在热数据区域的后3/4部分的缓存页被访问了，才\\n会给你移动到链表头部去。热数据区域的前面1/4的缓存页被访问，不会移动到链表头部去的。\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"lru链表淘汰刷盘\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#lru链表淘汰刷盘\"}},[_._v(\"#\")]),_._v(\" LRU链表淘汰刷盘\")]),_._v(\" \"),r(\"p\",[_._v(\"加载数据页，free链表移除，lru冷数据头部放入\\n修改缓存页，flush添加，lru冷数据移动热数据头部\\n查询数据页，lru冷数据移动热数据或热数据移动到头部或不移动（在1/4热数据）\\n数据页刷入硬盘，free添加，flush移除，lru移除\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"刷硬盘时机\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"冷数据尾部：后台线程定时刷，清空缓存页，加入free链表（不需要缓存页满）\")]),_._v(\" \"),r(\"li\",[_._v(\"flush链表：MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修\\n改过的数据，迟早都会刷入磁盘的，只要flush链表中的一波缓存页被刷入了磁盘，那么这些缓存页也会从flush链表和lru链表中移除，然后加入到free链表\\n中去！（lru链表的热数据区域里的很多缓存页可能也会被频繁的修改，难道他们永远都不刷入磁盘中了）\")]),_._v(\" \"),r(\"li\",[_._v(\"没空闲缓存页：即未到定时时间，如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页，刷入磁盘（如果频繁，crud是都要先刷一个缓存页到硬盘，再从\\n磁盘上读取一个数据页到空闲的缓存页里来？这样岂不是每次CRUD操作都要执行两次磁盘IO？那么性能岂不是会极差？）\")])]),_._v(\" \"),r(\"p\",[_._v(\"-如何避免刷盘时间第三种：你的MySQL的内核参数，应该如何优化，优化哪些地方的行为\\n部资源禁\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"生产经验-buffer-pool配置\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#生产经验-buffer-pool配置\"}},[_._v(\"#\")]),_._v(\" 生产经验：Buffer Pool配置\")]),_._v(\" \"),r(\"p\",[_._v(\"Buffer Pool其实本质就是一大块内存数据结构，由一大堆的缓存页和描述数\\n据块组成的，然后加上了各种链表（free、flush、lru）\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL同时接收到了多个请求，他自然会用多个线程来处理这多个请求，每个线程会负责处理\\n一个请求，多个线程是不是应该会同时去访问Buffer Pool呢？就是同时去操作里面的缓存页，同时操作一个free链表、\\nflush链表、lru链表，是吗？多线程并发访问一个Buffer Pool，必然是要加锁的，性能问题\")]),_._v(\" \"),r(\"p\",[_._v(\"注：MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个BufferPool。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"优化：MySQL设置多个Buffer Pool来优化他的并发能力。\")])]),_._v(\" \"),r(\"p\",[_._v(\"如：buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小\\n就是2GB\")]),_._v(\" \"),r(\"p\",[_._v(\"[server]\\ninnodb_buffer_pool_size = 8589934592\\ninnodb_buffer_pool_instances = 4\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"通过chunk动态调整buffer-pool大小\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#通过chunk动态调整buffer-pool大小\"}},[_._v(\"#\")]),_._v(\" 通过chunk动态调整Buffer Pool大小\")]),_._v(\" \"),r(\"p\",[_._v(\"如：向操作系统申请一块新的16GB的连续内存，然后把现在的buffer pool中的所有缓存页、描述数据\\n块、各种链表，都拷贝到新的16GB的内存中去。这个过程是极为耗时的，性能很低下，是不可以接受的\")]),_._v(\" \"),r(\"p\",[_._v(\"每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套\\nfree、flush、lru这些链表\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/chunk.PNG\",alt:\"chunk\"}})]),_._v(\" \"),r(\"p\",[_._v(\"如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就\\n可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了,即不需要额外申请16GB的连续空间，不需要复制已有数据。\")]),_._v(\" \"),r(\"p\",[_._v(\"多线程如何保证数据事务问题\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[_._v(\"高并发实际场景：Java系统访问数据库的并发程度来决定的，你高并发\\n访问数据库，缓存页必然使用的很快了！\\n然后你后台线程定时释放一批缓存页，这个过程也很难去优化，因为你要是释放的过于频繁了，那么后台线程执行磁\\n盘IO过于频繁，也会影响数据库的性能。\\n所以这里的关键点就在于，你的buffer pool有多大！如果你的数据库要抗高并发的访问，那么你的机器必然要配置很大的内存空间，起码是32GB以上的，甚至64GB或者\\n128GB。此时你就可以给你的buffer pool设置很大的内存空间，比如20GB，48GB，甚至80GB。buffer pool内存很大，所以空闲缓存页是很多很多的，即使你的空闲缓存页逐步的减少，也可能需要较长时\\n间才会发现缓存页用完了，此时才会出现一次crud操作执行的时候，先刷缓存页到磁盘，再读取数据页到缓存页来，\\n这种情况是不会出现的太频繁的！线上的MySQL在生产环境中，buffer pool的大小、buffer pool的数量，这都是要用心设置和优化的，因为多\\nMySQL的性能和并发能力，都会有较大的影响。\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"生产环境如何确定Buffer Pool大小：\")])])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"建议一个比较合理的、健康的比例，是给buffer pool设置你的机器内存的50%~60%左右，如内存32GB，Buffer Pool20GB\")]),_._v(\" \"),r(\"li\",[_._v(\"buffer pool总大小=(chunk大小 * buffer pool数量)的2倍数\")])]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"总结\\n我们再来做一点总结，就是说你的数据库在生产环境运行的时候，你必须根据机器的内存设置合理的buffer pool的大\\n小，然后设置buffer pool的数量，这样的话，可以尽可能的保证你的数据库的高性能和高并发能力。\\n然后在线上运行的时候，buffer pool是有多个的，每个buffer pool里多个chunk但是共用一套链表数据结构，然后执\\n行crud的时候，就会不停的加载磁盘上的数据页到缓存页里来，然后会查询和更新缓存页里的数据，同时维护一系列\\n的链表结构。\\n然后后台线程定时根据lru链表和flush链表，去把一批缓存页刷入磁盘释放掉这些缓存页，同时更新free链表。\\n如果执行crud的时候发现缓存页都满了，没法加载自己需要的数据页进缓存，此时就会把lru链表冷数据区域的缓存页\\n刷入磁盘，然后加载自己需要的数据页进来。\\n整个buffer pool的结构设计以及工作原理，就是上面我们总结的这套东西了，大家只要理解了这个，首先你对MySQL\\n执行crud的时候，是如何在内存里查询和更新数据的，你就彻底明白了。\\n接着我们后面继续探索undo log、redo log、事务机制、事务隔离、锁机制，这些东西，一点点就把MySQL他的数据\\n更新、事务、锁这些原理，全部搞清楚了，同时中间再配合穿插一些生产经验、实战案例。\\n4、SHOW ENGINE INNODB STATUS\\n当你的数据库启动之后，你随时可以通过上述命令，去查看当前innodb里的一些具体情况，执行SHOW ENGINE\\nINNODB STATUS就可以了。此时你可能会看到如下一系列的东西：\\nTotal memory allocated xxxx;\\nDictionary memory allocated xxx\\nBuffer pool size xxxx\\n内部资源禁止外传\\nFree buffers xxx\\nDatabase pages xxx\\nOld database pages xxxx\\nModified db pages xx\\nPending reads 0\\nPending writes: LRU 0, flush list 0, single page 0\\nPages made young xxxx, not young xxx\\nxx youngs/s, xx non-youngs/s\\nPages read xxxx, created xxx, written xxx\\nxx reads/s, xx creates/s, 1xx writes/s\\nBuffer pool hit rate xxx / 1000, young-making rate xxx / 1000 not xx / 1000\\nPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s\\nLRU len: xxxx, unzip_LRU len: xxx\\nI/O sum[xxx]:cur[xx], unzip sum[16xx:cur[0]\\n下面我们给大家解释一下这里的东西，主要讲解这里跟buffer pool相关的一些东西。\\n（1）Total memory allocated，这就是说buffer pool最终的总大小是多少\\n（2）Buffer pool size，这就是说buffer pool一共能容纳多少个缓存页\\n（3）Free buffers，这就是说free链表中一共有多少个空闲的缓存页是可用的\\n（4）Database pages和Old database pages，就是说lru链表中一共有多少个缓存页，以及冷数据区域里的缓存页\\n数量\\n（5）Modified db pages，这就是flush链表中的缓存页数量\\n（6）Pending reads和Pending writes，等待从磁盘上加载进缓存页的数量，还有就是即将从lru链表中刷入磁盘的数\\n量、即将从flush链表中刷入磁盘的数量\\n（7）Pages made young和not young，这就是说已经lru冷数据区域里访问之后转移到热数据区域的缓存页的数\\n量，以及在lru冷数据区域里1s内被访问了没进入热数据区域的缓存页的数量\\n（8）youngs/s和not youngs/s，这就是说每秒从冷数据区域进入热数据区域的缓存页的数量，以及每秒在冷数据区\\n域里被访问了但是不能进入热数据区域的缓存页的数量\\n内部资源禁止外传\\n（9）Pages read xxxx, created xxx, written xxx，xx reads/s, xx creates/s, 1xx writes/s，这里就是说已经读取、\\n创建和写入了多少个缓存页，以及每秒钟读取、创建和写入的缓存页数量\\n（10）Buffer pool hit rate xxx / 1000，这就是说每1000次访问，有多少次是直接命中了buffer pool里的缓存的\\n（11）young-making rate xxx / 1000 not xx / 1000，每1000次访问，有多少次访问让缓存页从冷数据区域移动到\\n了热数据区域，以及没移动的缓存页数量\\n（12）LRU len：这就是lru链表里的缓存页的数量\\n（13）I/O sum：最近50s读取磁盘页的总数\\n（14）I/O cur：现在正在读取磁盘页的数量\\n5、今日实践思考题\\n今天留给大家的作业，就是每个人都对自己线上在运行的数据库执行上述命令，然后分析一下数据库的buffer pool的\\n使用情况\\n这里要尤为关注的是free、lru、flush几个链表的数量的情况，然后就是lru链表的冷热数据转移的情况，然后你的缓存\\n页的读写情况，这些代表了你当前buffer pool的使用情况。\\n最关键的是两个东西，一个是你的buffer pool的千次访问缓存命中率，这个命中率越高，说明你大量的操作都是直接\\n基于缓存来执行的，性能越高。\\n第二个是你的磁盘IO的情况，这个磁盘IO越多，说明你数据库性能越差。\")])]),_._v(\" \"),r(\"h3\",{attrs:{id:\"探索undo-log、redo-log、事务机制、事务隔离、锁机制\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#探索undo-log、redo-log、事务机制、事务隔离、锁机制\"}},[_._v(\"#\")]),_._v(\" 探索undo log、redo log、事务机制、事务隔离、锁机制\")]),_._v(\" \"),r(\"p\",[_._v(\"部资源\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"写入数据库的一行数据在磁盘如何存储\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#写入数据库的一行数据在磁盘如何存储\"}},[_._v(\"#\")]),_._v(\" 写入数据库的一行数据在磁盘如何存储\")]),_._v(\" \"),r(\"p\",[_._v(\"为什么不能直接更新磁盘上的数据，因为来一个请求就直接对磁盘文件进行随机读写，然后\\n更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"一行数据在磁盘上是如何存储的：\\n其实这里涉及到一个概念，就是行格式。我们可以对一个表指定他的行存储的格式是什么样的，比如我们这里用一个\\nCOMPACT格式。\\nCREATE TABLE table_name (columns) ROW_FORMAT=COMPACT\\nALTER TABLE table_name ROW_FORMAT=COMPACT\")])]),_._v(\" \"),r(\"p\",[_._v(\"如：CREATE TABLE customer (\\nname VARCHAR(10) NOT NULL,\\naddress VARCHAR(20),\\ngender CHAR(1),\\njob VARCHAR(30),\\nschool VARCHAR(50)\\n) ROW_FORMAT=COMPACT;\")]),_._v(\" \"),r(\"p\",[_._v(\"你可以在建表的时候，就指定一个行存储的格式，也可以后续修改行存储的格式。这里指定了一个COMPACT行存储\\n格式，在这种格式下，每一行数据他实际存储的时候，大概格式类似下面这样：\\n变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......\\n对于每一行数据，他其实存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上他这一行数据每一列\\n的具体的值，这就是所谓的行格式。除了COMPACT以外，还有其他几种行存储格式，基本都大同小异。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[_._v(\"一行数据的存储格式大致如下所示。\\n变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值......\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"引入变长字段的长度列表，解决一行数据的读取问题\")])])]),_._v(\" \"),r(\"p\",[_._v(\"假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1)\\nCHAR(1)，hello是VARCHAR(10)类型的变长字段的值，那么这个“hello”字段值的长度到底是多少？\\n我们看到“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息，首先就是变\\n长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：0x05 null值列表 数据头\\nhello a a。\")]),_._v(\" \"),r(\"p\",[_._v(\"实际存放在变长字段长度列表、NULL值列表，是逆序放的。（多变长字段列表）\")]),_._v(\" \"),r(\"p\",[_._v(\"为什么MySQL不能用Java里面的序列化的那种方式？把很多行的数据做成一个大的对象，然后给他序列化一下写入到\\n磁盘文件里，从磁盘里读取的时候压根儿不用care什么行存储格式，直接反序列化一下，把数据就可以从磁盘文件里\\n拿回来了。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"一行数据多个NULL字段值磁盘存储（以二进制bit位逆序来存储,存储的是允许NULL的字段）\\n如：“jack NULL m NULL xx_school”,0x09 0x04 0101 头信息 column1=value1 column2=value2 ... columnN=valueN；实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位\\n就高位补0，所以实际存放看起来是如下的：0x09 0x04 00000101 头信息 column1=value1 column2=value2 ... columnN=valueN\")])]),_._v(\" \"),r(\"p\",[_._v(\"首先分析变长字段长度列表和NULL值列表读取出来，就可以完美的把你一行数据的值都读取出来了\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"40bit位的数据头及真实数据如何存储\\n数据头是用来描述这行数据的，一、二位预留位无意义，三delete_mask这行数据是否被删除（MYSQL删数据非立即磁盘删，先数据头置1），四min_rec_mask，五-八n_owned，九-二一heap_no当前这行数据在记录堆里的位置，二二=二四record_type这行数据的类型（0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据），二五-四十next_record指向他下一条数据的指针。\")])]),_._v(\" \"),r(\"p\",[_._v(\"= 实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示\\n的：\\n0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262\\n会在他的真实数据部分，加入一些隐藏字段，这个隐藏字段跟后续的一些内容是有关联的，大家先了解一下。\\n首先有一个DB_ROW_ID字段，这就是一个行的唯一标识，是他数据库内部给你搞的一个标识，不是你的主键ID字段。如果我\\n们没有指定主键和unique key唯一索引的时候，他就内部自动加一个ROW_ID作为主键。\\n部资源禁止外传\\n接着是一个DB_TRX_ID字段，这是跟事务相关的，他是说这是哪个事务更新的数据，这是事务ID，这个后续我们讲解到事务的\\n时候会跟大家说的。\\n最后是DB_ROLL_PTR字段，这是回滚指针，是用来进行事务回滚的，也是我们后续在讲解事务的时候再详细说。\")]),_._v(\" \"),r(\"p\",[_._v(\"0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）\\n00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR） 616161 636320 6262626262\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"行数据磁盘物理存储-行溢出-一个数据页放不下-把数据溢出放到其他数据页\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#行数据磁盘物理存储-行溢出-一个数据页放不下-把数据溢出放到其他数据页\"}},[_._v(\"#\")]),_._v(\" 行数据磁盘物理存储，行溢出(一个数据页放不下，把数据溢出放到其他数据页)\")]),_._v(\" \"),r(\"p\",[_._v(\"每一行数据都是放在一个数据页里的，这个数据页默认的大小是16KB，那么之前就有人在后台提过一个问题：万一 一行数据的大小超过了页的大小怎么办呢？\")]),_._v(\" \"),r(\"p\",[_._v(\"如：实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含他一部分数据，同时包含一个20个字节的指针，\\n指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/yichu.PNG\",alt:\"yichu\"}})]),_._v(\" \"),r(\"p\",[_._v(\"数据页的物理存储结构，然后是表空间的物理存储结构，最后是讲解这些数据以物理存储结构的方\\n式，在磁盘上存储的时候，是放在哪些磁盘文件里\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"磁盘数据页\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#磁盘数据页\"}},[_._v(\"#\")]),_._v(\" 磁盘数据页\")]),_._v(\" \"),r(\"p\",[_._v(\"一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多\\n个数据行、空闲空间、数据页目录、文件尾部，默认有16kb的大小\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/datapage.PNG\",alt:\"datapage\"}})]),_._v(\" \"),r(\"p\",[_._v(\"文件头占据了38个字节，数据页头占据了56个字节，最大记录和最小记录占据了26个字节，数据行区域的大小是\\n不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据8个字节。\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"表空间-物理概念\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#表空间-物理概念\"}},[_._v(\"#\")]),_._v(\" 表空间（物理概念）\")]),_._v(\" \"),r(\"p\",[_._v(\"平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件\\n，一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个数\\n据区的概念，英文就是extent，一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一\\n组。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"当我们需要执行crud\\n操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。\")])]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/tablespace.PNG\",alt:\"tablespace\"}})]),_._v(\" \"),r(\"p\",[_._v(\"注：第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比\\n如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。\\nIBUF_BITMAP数据页，里面存放的是这一组数据页的所有insert buffer的一些信息。\\nINODE数据页，这里也是存放了一些特殊的信息。\")]),_._v(\" \"),r(\"p\",[_._v(\"表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"总上介绍了MYSQL存储模型以及数据读写机制\")])]),_._v(\" \"),r(\"p\",[_._v(\"数据行里都有很多附加的信息，在数据页、数据区里，都\\n有很多附加的特殊信息。各种各样的特殊信息，就可以让我们在简简单单的磁盘文件里实现B+树索引、事务之类的非常复杂的机制。\")]),_._v(\" \"),r(\"p\",[_._v(\"思考：假设此时我们要插入一条数据，那么是选择磁盘文件里的哪个数据页加载到缓存页里去呢？\")]),_._v(\" \"),r(\"p\",[_._v(\"根据表找到表空间，定位到磁盘文件，从里面找一个extent组，找一个\\nextent，接着从里面找一个数据页出来！这个数据也可能是空的，也可能已经放了一些数据行了！\\n然后就可以把这个数据页从磁盘里完整加载出来，放入Buffer Pool的缓存页里了！\")]),_._v(\" \"),r(\"p\",[_._v(\"从磁盘文件里读取一个数据页，是怎么读取的啊？\\n其实这个很简单了，你可以想一下，磁盘文件里放的数据都是紧挨在一起的，类似于下面的那种样子。\\n0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds\\n0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds\")]),_._v(\" \"),r(\"p\",[_._v(\"么在读取一个数据页的时候，你就可以通过随机读写的方式来了，举个例子，我们下面有一个伪代码，大家看看。\\n就是设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。\\ndataFile.setStartPosition(25347)\\ndataFile.setEndPosition(28890)\\ndataPage = dataFile.read()\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"日志顺序读写以及数据文件随机读写的原理\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#日志顺序读写以及数据文件随机读写的原理\"}},[_._v(\"#\")]),_._v(\" 日志顺序读写以及数据文件随机读写的原理\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL数据库和底层的操作系统之间的交互原理\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL在实际工作时候的两种数据读写机制：\")]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"一种是对redo log、binlog这种日志进行的磁盘顺序读写\")]),_._v(\" \"),r(\"li\",[_._v(\"一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写（主要关注的性能指标是IOPS(底层存储系统每秒可以执行多少次磁盘读写操作)和响应延迟（磁盘每个读写操作耗时））\")])]),_._v(\" \"),r(\"p\",[_._v(\"生产环境的MySQL数据库每隔一两个月性能就会出现急剧抖动的案例\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"linux操作系统的存储系统原理剖析以及io调度优化原理\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#linux操作系统的存储系统原理剖析以及io调度优化原理\"}},[_._v(\"#\")]),_._v(\" Linux操作系统的存储系统原理剖析以及IO调度优化原理.\")]),_._v(\" \"),r(\"p\",[_._v(\"之所以需要操作系统，是因为我们不可能直接去操作CPU、内存、磁盘这些硬件，所以必须要用操作系统来管理CPU、内存、磁盘、网卡这些硬件设备。\")]),_._v(\" \"),r(\"p\",[_._v(\"我们只要打开windows操作系统的电脑，就可以随意编辑文件，上网，聊天，使用各种软件，这些软件运行的时候本\\n质底层都是在使用计算机的CPU、内存、磁盘和网卡，比如基于CPU执行你的文件编辑的操作，基于内存缓冲你对文\\n件的编辑，基于磁盘存储你在文件里输入的内容，基于网卡去进行网络通信，让你进行QQ聊天什么的。\\n至于说linux操作系统，其实也是类似的，只不过一般我们用linux操作系统，他是不给我们提供可视化界面的，只有命\\n令行的界面，我们需要输入各种各样的命令去执行文件编辑、系统部署和运行，本质linux操作系统在底层其实也是利\\n用CPU、内存、磁盘和网卡这些硬件在工作。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层\")])]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/linux.PNG\",alt:\"linux\"}})]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"原理：当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。\\n文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读\\n写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO\\n请求，，会把这个Block IO请求交给IO调度层(默认CFQ公平调度算法，建议调整为deadline IO调度算法，这也是一个生产环境的IO调度优化经验。)，IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层，硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终\\nMySQL可以得到本次IO读写操作的结果。\")])]),_._v(\" \"),r(\"p\",[_._v(\"deadline IO调度算法：任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。（数据库发起了多个SQL语句同时在执行IO操作,公平算法的话耗时少的sql在后面执行的话会等待耗时久的sql）\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"案例-数据库服务器使用的raid存储架构-存储硬件层面原理\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#案例-数据库服务器使用的raid存储架构-存储硬件层面原理\"}},[_._v(\"#\")]),_._v(\" 案例：数据库服务器使用的RAID存储架构（存储硬件层面原理）\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL数据库软件都是安装在一台linux服务器上的，然后启动MySQL的进程，就是启动了一个MySQL数据库\\nMySQL运行过程中，他需要使用CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供\\n的接口，依托于操作系统来使用和运行的，然后linux操作系统负责操作底层的硬件。\")]),_._v(\" \"),r(\"p\",[_._v(\"关系：\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/server.PNG\",alt:\"server\"}})]),_._v(\" \"),r(\"p\",[_._v(\"很多数据库部署在机器上的时候，存储都是搭建的RAID存储架构(磁盘冗余阵列)，解决问题：磁盘容量不够，多加几块，RAID用来管理机器\\n里的多块磁盘的一种磁盘阵列技术，往磁盘里读写数据的时候，他会告诉你应该在哪块磁盘上读写数据，还能实现数据冗余机制（可写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块\\n磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是RAID技术自动帮你管理的）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[_._v(\"服务器RAID存储架构的电池充放电原理：多块磁盘组成的RAID阵列有一个RAID卡（带缓存非使用主内存）把RAID的缓存模式设置为write back，所有写入到磁盘阵列的数据，先会缓存在RAID卡的缓\\n存里，后续慢慢再写入到磁盘阵列里去\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"RAID卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然掉电\\n了，无法接通电源了，RAID卡自己是基于锂电池（定时充放电）来供电运行的，然后他会赶紧把缓存里的数据写入到阵列中的磁盘上\")])])]),_._v(\" \"),r(\"p\",[_._v(\"问题：每隔30天~90天自动对锂电池充放电延长锂电池的寿命和校准电池容量,若不定时充放电则可能电量不够一次性把缓存中数据写回到磁盘中去，充放电时RAID的缓存级别会从write back变成write through直接写入磁盘，出现几十倍性能抖动\\n案例： 数据库是部署在高配置服务器上的，磁盘就是用的RAID\\n10的阵列技术，用了6块磁盘组成了RAID 10磁盘阵列架构（每2块磁盘组成一个RAID 1互为镜像的架构，存放的数据是冗余一样的，一共有3组RAID 1），\")]),_._v(\" \"),r(\"p\",[_._v(\"优化：\")]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"RAID卡把锂电池换成电容，电容是不用频繁充放电的，电容可以支持透明充放电，就是自动检查电量\")]),_._v(\" \"),r(\"li\",[_._v(\"写脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本手动触发充放电\")]),_._v(\" \"),r(\"li\",[_._v(\"锂电池充放电的时候不要把缓存级别从write back修改为write through（可以和策略2配合使用）\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"案例-too-many-connections\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#案例-too-many-connections\"}},[_._v(\"#\")]),_._v(\" 案例：Too many connections\")]),_._v(\" \"),r(\"p\",[_._v(\"数据库的连接池里已经有太多的连接了，不能再跟你建立新的连接\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/connection.PNG\",alt:\"connection\"}})]),_._v(\" \"),r(\"p\",[_._v(\"show variables like 'max_connections'\")]),_._v(\" \"),r(\"p\",[_._v(\"底层的linux操作系统把进程可以打开的文件句柄数限制为了1024了，导致MySQL最大连接数是214！linux的话是默认会限制你每个进程对机器资\\n源的使用的，包括可以打开的文件句柄的限制，可以打开的子进程数的限制，网络缓存的限制，最大可以锁定的内存\\n大小。linux操作系统设计的初衷，就是要尽量避免你某个进程一下子耗尽机器上的所有资源，所以他默认都是会做限制的。linux限制你一个进程的文件句柄太少的话，那么就会导致我们没办法创建大量的网络连接。\")]),_._v(\" \"),r(\"p\",[_._v(\"在生产环境部署了一个系统，比如数据库系统、消息中间件系统、存储系统、缓存系统之后，都需要\\n调整一下linux的一些内核参数，这个文件句柄的数量是一定要调整的，通常都得设置为65535。比如Kafka之类的消息中间件，在生产环境部署的时候，如果你不优化一些linux内核参数，会导致Kafka可能无法\\n创建足够的线程，此时也是无法运行的。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"解决：ulimit -HSn 65535\")])]),_._v(\" \"),r(\"p\",[_._v(\"检查最大文件句柄数是否被修改了\\ncat /etc/security/limits.conf\")]),_._v(\" \"),r(\"p\",[_._v(\"cat /etc/rc.local\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"redo日志对于事务提交后-数据绝对不会丢失的意义\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#redo日志对于事务提交后-数据绝对不会丢失的意义\"}},[_._v(\"#\")]),_._v(\" redo日志对于事务提交后，数据绝对不会丢失的意义\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"日志是事务相关\")])]),_._v(\" \"),r(\"p\",[_._v(\"更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。\\nredo log本质是保证事务提交之后，修改的数据绝对不会丢失的。\")]),_._v(\" \"),r(\"p\",[_._v(\"更新缓存页的时候，会更新free链表、flush链表、lru链\\n表，然后有专门的后台IO线程，不定时的根据flush链表、lru链表，会把你更新过的缓存页刷新回磁盘文件的数据页里\\n去\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/data.PNG\",alt:\"data\"}})]),_._v(\" \"),r(\"p\",[_._v(\"这个机制里最大的漏洞就在于，万一你一个事务里有增删改SQL更新了缓存页，然后事务提交了，结果万一你还没来得\\n及让IO线程把缓存页刷新到磁盘文件里，此时MySQL宕机了，然后内存数据丢失，你事务更新的数据就丢失了！也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里去，\\n缓存页刷新到磁盘文件里，是随机磁盘读写，性能是相当的差，故需要引入redo log机制\")]),_._v(\" \"),r(\"p\",[_._v(\"redo log:MySQL重启之后，把你之前事务更新过做的修改根据redo log在Buffer Pool里重做一遍就可以了，就可以恢复\\n出来当时你事务对缓存页做的修改，然后找时机再把缓存页刷入磁盘文件里去。\")]),_._v(\" \"),r(\"p\",[_._v(\"为什么要redo log日志：缓存页刷入磁盘是随机写磁盘，性能是很差的；redo log写日志，是顺序写入磁盘文件，每次都是追加到磁盘文件末尾去，速度也是很快的\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"redo log里本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了\\n几个字节的值，具体修改的值是什么，他里面需要记录的就是表空间号+数据页号+偏移量+修改几个字节的值+具体的值\")])]),_._v(\" \"),r(\"p\",[_._v(\"redo log看起来大致的结构如下所示：日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据\")]),_._v(\" \"),r(\"p\",[_._v(\"MLOG_1BYTE类型的日志指的就是修改了1个字节的值，以此类推，还有修改了4个字节的值的日\\n志类型，修改了8个字节的值的日志类型。如果你要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某\\n个偏移量的位置插入或者修改了一大串的值。\")]),_._v(\" \"),r(\"p\",[_._v(\"大致就是一条redo log中依次排列上述的一些东西，这条redo log表达的语义就很明确了，他的类型是什么，类型就\\n告诉了你他这次增删改操作修改了多少字节的数据；\\n然后在哪个表空间里操作的，这个就是跟你SQL在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里\\n执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些呢。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"redo log写入磁盘过程：非一条条redo log写入，MySQL内有另外一个数据结构，叫做redo log block（512字节）来存放多个单行日志的（类似数据与数据页）\")])]),_._v(\" \"),r(\"p\",[_._v(\"-redo log buffer里的redo log block\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/block.PNG\",alt:\"block\"}}),_._v(\"\\n12字节的header头又分为了4个部分。\\n部资源禁止外传\\n包括4个字节的block no，就是块唯一编号；\\n2个字节的data length，就是block里写入了多少字节数据；\\n2个字节的first record group。这个是说每个事务都会有多个redo log，是一个redo log group，即一组redo\\nlog。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的；\\n4个字节的checkpoint on\")]),_._v(\" \"),r(\"p\",[_._v(\"写文件的时候，可以按照字节，一个字节一个字节的写入的，文件里存放的东西\\n就是很多很多字节，依次排开，然后其中可能512个字节组合起来，就固定代表了一个redo log block。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/512block.PNG\",alt:\"512block\"}})]),_._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[_._v(\"通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认的值就是16MB，其实已经够大了，毕\\n竟一个redo log block才512自己而已，每一条redo log其实也就几个字节到几十个字节罢了。\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"其实在我们平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个redo\\nlog，这多个redo log就是一组redo log，其实每次一组redo log都是先在别的地方暂存，然后都执行完了，再把一组redo\\nlog给写入到redo log buffer的block里去的。一组redo log太多，放两个block,少则，多个redo log,放一个block\")])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"redo log buﬀer里的redo log block刷入磁盘的时机\")])])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"redo log buﬀer的日志已经占据了redo log buﬀer总容量的一半了，也就是超过了8MB的redo log在缓冲里\")]),_._v(\" \"),r(\"li\",[_._v(\"一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只\\n有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事\\n务做的修改（常见）\")]),_._v(\" \"),r(\"li\",[_._v(\"后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buﬀer里的redo log block刷到磁盘\\n文件里去\")]),_._v(\" \"),r(\"li\",[_._v(\"MySQL关闭的时候，redo log block都会刷入到磁盘里去\")])]),_._v(\" \"),r(\"p\",[_._v(\"注：但是不管怎么说，主要是保证一个事务执行的时候，redo log都进入redo log buﬀer，提交事务的时\\n候，事务对应的redo log必须是刷入磁盘文件，接着才算是事务提交成功，否则事务提交就是失败，保\\n证这一点，就能确保事务提交之后，数据不会丢，有redo log在磁盘里就行了。\\n当然，绝对保证数据不丢，还得配置一个参数，提交事务把redo log刷入磁盘文件的os cache之后，还\\n得强行从os cache刷入物理磁盘。\")]),_._v(\" \"),r(\"p\",[_._v(\"redo log是有多个的，写满了一个就会写下一个redo log，而且可以限制redo log文件的数量，通\\n过innodb_log_ﬁle_size可以指定每个redo log文件的大小，默认是48MB，通过\\ninnodb_log_ﬁles_in_group可以指定日志文件的数量，默认就2个。\\n所以默认情况下，目录里就两个日志文件，分别为ib_logﬁle0和ib_logﬁle1，每个48MB，最多就这2个\\n日志文件，就是先写第一个，写满了写第二个。那么如果第二个也写满了呢？别担心，继续写第一个，\\n覆盖第一个日志文件里原来的redo log就可以了。\")]),_._v(\" \"),r(\"p\",[_._v(\"![redolog](/img/mysql/redo log.PNG)\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"问题：redologbuffer到redolog日志宕机怎么办\")])]),_._v(\" \"),r(\"h4\",{attrs:{id:\"undo-log回滚日志-事务执行到一半回滚\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#undo-log回滚日志-事务执行到一半回滚\"}},[_._v(\"#\")]),_._v(\" undo log回滚日志（事务执行到一半回滚）\")]),_._v(\" \"),r(\"p\",[_._v(\"事务操作执行一半回滚事务，引入undo log\")]),_._v(\" \"),r(\"p\",[_._v(\"写undo log时机：1加载数据页 2事务提交后?????事务开启还是\"),r(\"strong\",[_._v(\"事务修改时\")]),_._v(\"？\\n从版本链来看，事务开启后只需修改当前数据行就能形成undo log版本链\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/undoredo.PNG\",alt:\"unre\"}})]),_._v(\" \"),r(\"p\",[_._v(\"insert语句（TRX_UNDO_INSERT_REC）undo log日志结构(没有主键，MySQL设置row_id作为隐藏字段，做主键)：\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/undo.PNG\",alt:\"undo\"}})]),_._v(\" \"),r(\"h4\",{attrs:{id:\"多个事务同时执行-mysql内核原理的角度\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#多个事务同时执行-mysql内核原理的角度\"}},[_._v(\"#\")]),_._v(\" 多个事务同时执行（MySQL内核原理的角度）\")]),_._v(\" \"),r(\"p\",[_._v(\"通常而言，我们都是在业务系统里会开启事务来执行增删改操作的，业务系统是执行一个一个的事务，每个事务里可能是一个或者多个增删改查的SQL语句\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/transactional.PNG\",alt:\"transcational\"}})]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"问题：\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"多个事务并发执行的时候，可能会同时对缓存页里的一行数据进行更新，这个冲突怎么处理？是否\\n要加锁？(脏写、脏读、不可重复读、幻读)\")]),_._v(\" \"),r(\"li\",[_._v(\"可能有的事务在对一行数据做更新，有的事务在查询这行数据，这里的冲突怎么处理？\")])]),_._v(\" \"),r(\"p\",[_._v(\"涉及机制：解决多个事务并发运行的时候，同时写和同时读写的一些并\\n发冲突的处理机制，包括了MySQL事务的隔离级别、MVCC多版本隔离、锁机制（用于解决脏读，脏写，不可重复读，幻读）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"问题1：\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"多个事务同时更新一条数据（脏写），事务A先写不提交，事务B后写提交，事务A回滚。事务B看到的场景，就是自己明明更新了，结果值却没了，这就是脏写\")]),_._v(\" \"),r(\"li\",[_._v(\"事务A更新未提交，事务B读，事务A回滚（脏读），事务B读到脏数据。\")]),_._v(\" \"),r(\"li\",[_._v(\"事务A查数据1未提交，事务B更新数据1提交事务，事务A读取不到原来值（一行数据）（不重复读）\")]),_._v(\" \"),r(\"li\",[_._v(\"查询到了之前查询没看到过的数据（数据行数增多或减少）（幻读）\")])]),_._v(\" \"),r(\"p\",[_._v(\"注：脏读脏写前提是能读到未提交事务数据，不可重读前提是读取不到未提交事务的数据\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"事务隔离级别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#事务隔离级别\"}},[_._v(\"#\")]),_._v(\" 事务隔离级别\")]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"read uncommitted（读未提交）,可读取到事务未提交时修改的值\")]),_._v(\" \"),r(\"li\",[_._v(\"read committed（读已提交），可读取到事务提交时修改的值\")]),_._v(\" \"),r(\"li\",[_._v(\"repeatable read（可重复读），自身事务开始后查询到值一直相同（默认）\")]),_._v(\" \"),r(\"li\",[_._v(\"serializable（串行化） ，多个事务串行，那数据库恨不能一秒并发就只有几十了，性能会极差的\")])]),_._v(\" \"),r(\"p\",[_._v(\"SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"MySQL如何支持隔离级别及Spring事务注解\")])]),_._v(\" \"),r(\"p\",[_._v(\"MySQL的RR级别的语义跟SQL标准的RR级别不同的，毕竟SQL标准里规定RR级别是可以发生幻读的，但是MySQL的RR级别避免了！\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL里执行的事务，默认情况下不会发生脏写、脏读、不可重复读和幻读的问题，总之，\"),r(\"strong\",[_._v(\"事务之间互相都完全不影响\")]),_._v(\"！\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"RR级别避免不可重复读和幻读(MySQL的MVCC机制(多版本并发控制隔离机制))\")])]),_._v(\" \"),r(\"p\",[_._v(\"@Transactional(isolation=Isolation.DEFAULT)，然后默认的就是DEFAULT值，这个就是MySQL默认支\\n持什么隔离级别就是什么隔离级别。spring的事务是对数据库的事务的封装,最后本质的实现还是在数据库\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"mvcc-基于undo-log多版本链条-readview机制\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mvcc-基于undo-log多版本链条-readview机制\"}},[_._v(\"#\")]),_._v(\" MVCC（基于undo log多版本链条+ReadView机制）\")]),_._v(\" \"),r(\"p\",[_._v(\"默认的RR隔离级别，就是基于这套机制来实现的，依托这套机制实现了RR级别，除了避免脏写、脏读、不可重复\\n读，还能避免幻读问题。\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"undo log多版本链条（事务开启只需要修改数据无需提交就能有undo log版本链???）\")])]),_._v(\" \"),r(\"p\",[_._v(\"每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer，这个trx_id就\\n是最近一次更新这条数据的事务id，roll_pointer就是指向你了你更新这个事务之前生成的undo log回滚日志\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/mvcc.PNG\",alt:\"mvcc\"}}),_._v(\"\\n先不管多个事务并发执行是如何执行的，起码先搞清楚一点，\\n就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段txr_id和roll_pointer，同时\\n之前多个数据快照对应的undo log，会通过roll_pinter指针串联起来，形成一个重要的版本链！\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"ReadView机制(基于undo log多版本链条实现)\\n执行一个事务的时候，就给你生成一个ReadView\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"一个是m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的；\")]),_._v(\" \"),r(\"li\",[_._v(\"一个是min_trx_id，就是m_ids里最小的值；\")]),_._v(\" \"),r(\"li\",[_._v(\"一个是max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id；（由mysql生成，如已有事务70，无论是否提交，max_trx_id都是71）\")]),_._v(\" \"),r(\"li\",[_._v(\"一个是creator_trx_id，就是你  这个事务的id\")])]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"生成readview时机\\nRC隔离级别：每次读取数据前，都生成一个readview；\\nRR隔离级别：在第一次读取数据前，生成一个readview；\")])]),_._v(\" \"),r(\"p\",[_._v(\"undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/readview.PNG\",alt:\"readview\"}})]),_._v(\" \"),r(\"p\",[_._v(\"多个事务并发执行的时候，事务B更新的值，通过这套\\nReadView+undo log日志链条的机制，就可以保证事务A不会读到并发执行的事务B更新的值，只会读\\n到之前最早的值。保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。\")]),_._v(\" \"),r(\"p\",[_._v(\"如事务A中readview中，判断当前数据undo log中数据行的\\ntxr_id小于readview中min_trx_id，事务A开启前，当前数据行已提交，事务A可操作此行数据，\\n事务B修改后，当前数据行已改变，\\n事务A再操作，txr_id大于readview中min_trx_id，小于max_trx_id，说明事务AB可能就同时开启，txr_id是否再事务AReadView的m_ids列表，如果有可是开启，事务A不能操作此数据行，需要找到txr_id小于readviewmin_trx_id的数据行，\\n若txr_id==事务readvie w中的creator_trx_id说明是当前事务修改的，\\ntxr_id大于事务readview中的creator_trx_id，说明事务A开启后有个事务更新了数据，自己不能看到，只能顺着版本链条看小于或等于的\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"rc隔离级别与rr隔离级别-基于readview机制实现\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#rc隔离级别与rr隔离级别-基于readview机制实现\"}},[_._v(\"#\")]),_._v(\" rc隔离级别与rr隔离级别（基于ReadView机制实现）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"生成readview时机\\nRC隔离级别：每次读取数据前，都生成一个readview；\\nRR隔离级别：在第一次读取数据前，生成一个readview；\")])]),_._v(\" \"),r(\"p\",[_._v(\"总结：\")]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"undo log中trx_id小于min_trx_id事务能查询\\n2.undo log中trx_id处于min_trx_id、max_trx_id之间，且ReadView的m_ids活跃事务列表中没有trx_id事务可查询\")])]),_._v(\" \"),r(\"p\",[_._v(\"当rc时，事务A每次读取用不同readview可能导致ims事务列表变化，读取不到原来同时开启的事务已提交的事务，情况2可以重复读\")]),_._v(\" \"),r(\"p\",[_._v(\"当RR时，readview不变，即使原来同时开启的事务已提交的事务，事务A中readview的Ims列表也不变，事务A还是读取不到已提交的事务B\")]),_._v(\" \"),r(\"p\",[_._v(\"MySQL的RR级别的语义跟SQL标准的RR级别不同的,RR隔离级别下也能避免幻读，也是readview机制\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"锁机制-解决的就是多个事务同时更新一行数据-此时必须要有一个加锁的机制\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#锁机制-解决的就是多个事务同时更新一行数据-此时必须要有一个加锁的机制\"}},[_._v(\"#\")]),_._v(\" 锁机制（解决的就是多个事务同时更新一行数据，此时必须要有一个加锁的机制）\")]),_._v(\" \"),r(\"p\",[_._v(\"在特定\\n\"),r(\"strong\",[_._v(\"脏读、不可重复读、幻读，都是别人在更新数据的时候，你怎么读的问题，基于undo log版本链条以及ReadView实现的mvcc机制（其他事务写，一个事务读的问题）\")]),_._v(\" \"),r(\"strong\",[_._v(\"脏写，锁机制（多个事务同时写）\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"一个事务来了要更新这行数据，这个时候他会先琢磨一下，看看这行数据此时有没有人加锁\")]),_._v(\" \"),r(\"li\",[_._v(\"数据没人加锁，事务就会创建一个锁，里面包含了自己的trx_id和等待状态，然后把锁跟这行数据关联在一起。\")]),_._v(\" \"),r(\"li\",[_._v(\"更新一行数据必须把他所在的数据页从磁盘文件里读取到缓存页里来才能更新的，所以说，此时这行数据和关联的锁数据结构，都是在内存里的\")]),_._v(\" \"),r(\"li\",[_._v(\"事务B要更新数据，也也会生成一个锁数据结构，里面有他的trx_id，还有自己的等待状态，再排队等待\")]),_._v(\" \"),r(\"li\",[_._v(\"事务A这个时候更新完了数据，就会把自己的锁给释放掉了。\"),r(\"strong\",[_._v(\"锁一旦释放了，他就会去找\")]),_._v(\"，此时还有没有别人也对这行数据加锁了呢？他会发现事务B也加锁了，事务B的锁里的等待状态修改为false，然后唤醒事务B继续执行，此时事务B就获\\n取到锁了\")])]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/synchronize1.PNG\",alt:\"synchronize1\"}}),_._v(\" \"),r(\"img\",{attrs:{src:\"/img/mysql/synchronize2.PNG\",alt:\"synchronize2\"}})]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"多个事务加什么锁\\nX锁，也就是Exclude独占锁，当有一个事务加了独占锁之后，此时其他事务再要更新这行数据，\\n都是要加独占锁的，但是只能生成独占锁在后面等待。\")])]),_._v(\" \"),r(\"p\",[_._v(\"默认情况下，有人在更新数据的时候，然后你要去读取这行数据，直接默认就是开启mvcc机制的。 读写不互斥，MySQL设计mvcc机制就是为了解决这个问题，避免频繁加锁互斥。\")]),_._v(\" \"),r(\"p\",[_._v(\"万一要是你在执行查询操作的时候，就是想要加锁呢，MySQL首先支持一种共享锁，就是S锁，这个共享锁的语法如下：select * from table\\nlock in share mode，你在一个查询语句后面加上lock in share mode，意思就是查询的时候对一行数\\n据加共享锁。如果此时有别的事务在更新这行数据，已经加了独占锁了，此时你的共享锁能加吗？\\n当然不行了，共享锁和独占锁是互斥的！此时你这个查询就只能等着了。\")]),_._v(\" \"),r(\"p\",[_._v(\"更新数据的时候必然加独占锁，独占锁和独占锁是互斥的，此时别\\n人不能更新；但是此时你要查询，默认是不加锁的，走mvcc机制读快照版本，但是你查询是可以手动\\n加共享锁的(少见)，共享锁和独占锁是互斥的，但是共享锁和共享锁是不互斥的，如下规律。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/synchronize.PNG\",alt:\"synchronize\"}})]),_._v(\" \"),r(\"p\",[_._v(\"不是太建议在数据库粒度去通过行锁实现复杂的业务锁机制，而\\n更加建议通过redis、zookeeper来用分布式锁实现复杂业务下的锁机制（如商城系统中的锁逻辑）\")]),_._v(\" \"),r(\"p\",[_._v(\"多个事务并发更新数据的时候，都是要在行级别加独占锁的，这就是行锁，独占锁都是互斥的，所以\\n不可能发生脏写问题，一个事务提交了才会释放自己的独占锁，唤醒下一个事务执行。此时去读取别的事务在更新的数据，有两种可能：\\n第一种可能是基于mvcc机制进行事务隔离，读取快照版本，这是比较常见的；\\n第二种可能是查询的同时基于特殊语法去加独占锁或者共享锁。\")]),_._v(\" \"),r(\"p\",[_._v(\"如果你查询的时候加独占锁，那么跟其他更新数据的事务加的独占锁都是互斥的；如果你查询的时候加\\n共享锁，那么跟其他查询加的共享锁是不互斥的，但是跟其他事务更新数据就加的独占锁是互斥的，跟\\n其他查询加的独占锁也是互斥的。\")]),_._v(\" \"),r(\"p\",[_._v(\"一个数据页在磁盘文件里就是一段数据，可能是二进制或者别的特殊格式的数据，然后数据页里包含两个指针，一个指针指向自己上一个数据页的物理地址，一个指针指向自己下一个数据页的物理地址\\n类似：DataPage: xx=xx, xx=xx, linked_list_pre_pointer=15367, linked_list_next_pointer=34126 ||\\nDataPage: xx=xx, xx=xx, linked_list_pre_pointer=23789, linked_list_next_pointer=46589 ||\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"没索引-数据库根据查询语句搜索数据\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#没索引-数据库根据查询语句搜索数据\"}},[_._v(\"#\")]),_._v(\" 没索引，数据库根据查询语句搜索数据\")]),_._v(\" \"),r(\"p\",[_._v(\"数据页之间是组成双向链表的，然后数据页内部的数据行是组成单向链表的，而且数据行是根据主键从小到大排序的。\")]),_._v(\" \"),r(\"ol\",[r(\"li\",[_._v(\"主键：每个数据页里都会有一个页目录，里面根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的，所以实际上每个数据页的目录里，就是这个页里每个主键跟所在槽位的映射关系\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/pagemain.PNG\",alt:\"pagemain\"}})]),_._v(\" \"),r(\"li\",[_._v(\"非主键：根据数据页内部的单向链表来遍历查找， 再数据页的双向链表去找下一个数据页，然后读取到buﬀer pool的缓存页里，往复\")])]),_._v(\" \"),r(\"p\",[_._v(\"其实上述操作过程，就是全表扫描\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"不断向表中插入数据-物理存储如何页分裂-表里是如何出现一个又一个的数据页\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#不断向表中插入数据-物理存储如何页分裂-表里是如何出现一个又一个的数据页\"}},[_._v(\"#\")]),_._v(\" 不断向表中插入数据，物理存储如何页分裂（表里是如何出现一个又一个的数据页）\")]),_._v(\" \"),r(\"p\",[_._v(\"刚开始第一行是个起始行，他的行类型是2，就是最小的一行，然后他有一个指针指向了下一行数据，每一行数据都有自己每个字段的值，然后每一行通过一个指针不停的指向下一行数据，普通的数据行的类型都是0，最后一行是一个类型为3的，就是代表最大的一行。\")]),_._v(\" \"),r(\"p\",[_._v(\"索引运作的一个核心基础就是要求你后一个数据页的主键值都大于前面一个数据页的主键值，但是如果你的主键是自增的，那还可以保证这一点，因为你新插入后一个数据页的主键值一定都大于前一个数据页的主键值。\")]),_._v(\" \"),r(\"p\",[_._v(\"若第一数据页某条数据主键10，第二数据页某条数据主键8，有问题，需要出现一个页分裂，在增加一个新\\n的数据页的时候，实际上会把前一个数据页里主键值较大的，挪动到新的数据页里来，然后把你新插入\\n的主键值较小的数据挪动到上一个数据页里去，保证新数据页里的主键值一定都比上一个数据页里的主\\n键值大。\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/pagesplit.PNG\",alt:\"pagesplit\"}})]),_._v(\" \"),r(\"h4\",{attrs:{id:\"基于主键索引设计及根据主键索引查询\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#基于主键索引设计及根据主键索引查询\"}},[_._v(\"#\")]),_._v(\" 基于主键索引设计及根据主键索引查询\")]),_._v(\" \"),r(\"p\",[_._v(\"阻止一些全表扫描情况发生\")]),_._v(\" \"),r(\"p\",[_._v(\"需要针对主键设计一个索引了，针对主键的索引实际上就是主键目录，这个主键目录\\n呢，就是把每个数据页的页号，还有数据页里最小的主键值放在一起，组成一个索引的目录\")]),_._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue.PNG\",alt:\"indexcatalogue\"}})]),_._v(\" \"),r(\"p\",[_._v(\"假设数据页在磁盘文件里的位置也就是oﬀset偏移量，你也是可以知道的，此时就可以直接通\\n过随机读的方式定位到磁盘文件的某个oﬀset偏移量的位置，然后就可以读取连续的 一大坨数据页了！\")]),_._v(\" \"),r(\"h4\",{attrs:{id:\"索引-主键目录-的页物理存储结构-b-树实现\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#索引-主键目录-的页物理存储结构-b-树实现\"}},[_._v(\"#\")]),_._v(\" 索引（主键目录）的页物理存储结构（B+树实现）\")]),_._v(\" \"),r(\"p\",[_._v(\"表里的数据可能很多很多，比如有几百万，几千万，甚至单表几亿条数据都是\\n有可能的，所以此时你可能有大量的数据页，然后你的主键目录里就要存储大量的数据页和最小主键\\n值，这怎么行呢？（实际上是采取了一种把\"),r(\"strong\",[_._v(\"索引数据\")]),_._v(\"存储在数据页里的方式来做的，即表的索引也是放在页里的，即有很多索引页）\")]),_._v(\" \"),r(\"ul\",[r(\"li\",[_._v(\"演化过程：\")])]),_._v(\" \"),r(\"ol\",[r(\"li\",[r(\"p\",[_._v(\"表里数据变多，通过索引将主键目录中的数据以索引的形式存储在索引页中\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue1.PNG\",alt:\"indexcatalogue1\"}})])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"通过索引页拆分，先定位数据所在索引页，再定位数据\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue2.PNG\",alt:\"indexcatalogue2\"}})])]),_._v(\" \"),r(\"li\",[r(\"p\",[_._v(\"若底层索引存放下层索引页号太多，再次分裂\\n\"),r(\"img\",{attrs:{src:\"/img/mysql/indexcatalogue3.PNG\",alt:\"indexcatalogue3\"}})])])]),_._v(\" \"),r(\"p\",[_._v(\"最终变成一棵索引B+树，属于数据结构里的一种树形数据结构\")]),_._v(\" \"),r(\"p\",[_._v(\"以最简单最基础的主键索引来举例，当你为一个表的主键建立起来索引之后，其实这个主键的索\\n引就是一颗B+树，然后当你要根据主键来查数据的时候，直接就是从B+树的顶层开始二分查找，一层\\n一层往下定位，最终一直定位到一个数据页里，在数据页内部的目录里二分查找，找到那条数据。\\n这就是索引最真实的物理存储结构，采用跟数据页一样的页结构来存储，一个索引就是很多页组成的一\\n颗B+树。\")])])}),[],!1,null,null,null);v.default=l.exports}}]);","extractedComments":[]}